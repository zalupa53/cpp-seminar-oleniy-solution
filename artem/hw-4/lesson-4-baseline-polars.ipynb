{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T11:56:57.487729Z",
     "iopub.status.busy": "2025-02-09T11:56:57.487327Z",
     "iopub.status.idle": "2025-02-09T11:56:57.493015Z",
     "shell.execute_reply": "2025-02-09T11:56:57.491690Z",
     "shell.execute_reply.started": "2025-02-09T11:56:57.487690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pl.read_csv('data/train.csv')\n",
    "sub = pl.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort([\"id_house\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub = sub.with_columns([\n",
    "    pl.col(\"id\").str.split(\"_\").list.get(0).alias(\"date\"),\n",
    "    pl.col(\"id\").str.split(\"_\").list.get(1).cast(pl.Int64).alias(\"id_house\")\n",
    "])\n",
    "\n",
    "sub = sub.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Date, format=\"%Y-%m-%d\")\n",
    ")\n",
    "\n",
    "train = train.with_columns(\n",
    "    pl.col(\"date\").str.strptime(pl.Date, format=\"%Y-%m-%d\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th></tr><tr><td>date</td></tr></thead><tbody><tr><td>2022-06-01</td></tr><tr><td>2022-07-01</td></tr><tr><td>2022-08-01</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌────────────┐\n",
       "│ date       │\n",
       "│ ---        │\n",
       "│ date       │\n",
       "╞════════════╡\n",
       "│ 2022-06-01 │\n",
       "│ 2022-07-01 │\n",
       "│ 2022-08-01 │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.select(pl.col(\"date\")).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_date = train.select(pl.col(\"date\").min()).to_series()[0]\n",
    "end_date   = sub.select(pl.col(\"date\").max()).to_series()[0]\n",
    "\n",
    "dates_list = []\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    dates_list.append(current)\n",
    "    current += relativedelta(months=1)\n",
    "\n",
    "unique_cities = sub.select(\"id_house\").unique()\n",
    "\n",
    "dates_df = pl.DataFrame({\"date\": dates_list})\n",
    "\n",
    "data = unique_cities.join(dates_df, how=\"cross\")\n",
    "\n",
    "data = data.join(train, on=[\"id_house\", \"date\"], how=\"left\")\n",
    "\n",
    "data_other_columns = [col for col in data.columns if col not in [\"id_house\", \"date\"]]\n",
    "\n",
    "for col_name in data_other_columns:\n",
    "    data = data.with_columns(\n",
    "        pl.col(col_name)\n",
    "          .fill_null(strategy=\"backward\")\n",
    "          .fill_null(strategy=\"forward\")\n",
    "          .over(\"id_house\")\n",
    "          .alias(col_name)\n",
    "    )\n",
    "\n",
    "data = data.with_columns(pl.lit(-1.).alias(\"preds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3748189/2027218394.py:29: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  data = data.with_columns(\n"
     ]
    }
   ],
   "source": [
    "unique_houses_df = data.unique(subset=\"id_house\")\n",
    "coords_data = unique_houses_df.select([\"lat\", \"lng\"])\n",
    "unique_ids = unique_houses_df.select(\"id_house\")[\"id_house\"].to_list()\n",
    "dict_ind_house = {i: k for i, k in enumerate(unique_ids)}\n",
    "\n",
    "coords_np = coords_data.to_numpy()\n",
    "nn = NearestNeighbors(n_neighbors=10)\n",
    "nn.fit(coords_np)\n",
    "\n",
    "grouped = data.group_by([\"id_house\", \"date\"]).agg(\n",
    "    pl.col(\"med_price\").mean().alias(\"med_price_mean\")\n",
    ")\n",
    "dict_vals = { (row[0], row[1]) : row[2] for row in grouped.iter_rows() }\n",
    "\n",
    "list_month = data.select(\"date\").unique()[\"date\"].to_list()\n",
    "\n",
    "dict_mean = {}\n",
    "neighbors_arr = nn.kneighbors(coords_np)[1]\n",
    "for neighbors in neighbors_arr:\n",
    "    for month in list_month:\n",
    "        vals = []\n",
    "        for neighbor in neighbors:\n",
    "            key = (dict_ind_house[neighbor], month)\n",
    "            if key in dict_vals:\n",
    "                vals.append(dict_vals[key])\n",
    "        if vals:\n",
    "            dict_mean[(dict_ind_house[neighbors[0]], month)] = np.mean(vals)\n",
    "\n",
    "data = data.with_columns(\n",
    "    pl.struct([\"id_house\", \"date\"]).map_elements(\n",
    "        lambda row: dict_mean.get((row[\"id_house\"], row[\"date\"]), None)\n",
    "    ).alias(\"med_price_mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def catboost_train(train, target, split_list, param):\n",
    "    bst_list = []\n",
    "    \n",
    "    for i, (train_index, val_index, test_index) in enumerate(split_list):\n",
    "        tr = catboost.Pool(train[train_index], label=target[train_index])\n",
    "        te = catboost.Pool(train[val_index], label=target[val_index])\n",
    "        \n",
    "        bst = catboost.train(\n",
    "            tr, param, eval_set=te, \n",
    "            iterations=1000, early_stopping_rounds=200, verbose=300\n",
    "        )\n",
    "        \n",
    "        bst_list.append(bst)\n",
    "        \n",
    "        gc.collect()\n",
    "        del tr, te\n",
    "    \n",
    "    return bst_list\n",
    "\n",
    "params_cat = {\n",
    "    'loss_function': 'MAE', \n",
    "    'max_depth': 6, \n",
    "    'eval_metric': 'MAPE', \n",
    "    'learning_rate': 0.04, \n",
    "    'l2_leaf_reg': 20, \n",
    "    'random_state': 42, \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def lgb_train(train, target, split_list, param):\n",
    "    bst_list = []дрессировка собак\n",
    "        te = lgb.Dataset(train[val_index], target[val_index], reference=tr)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "            param, tr, num_boost_round=1000, valid_sets=te,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(5000)]\n",
    "        )\n",
    "        \n",
    "        bst_list.append(bst)\n",
    "        \n",
    "        gc.collect()\n",
    "        del tr, te\n",
    "    \n",
    "    return bst_list\n",
    "\n",
    "params_lgb = {\n",
    "    'objective': 'mae', \n",
    "    'verbosity': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'metric': 'mape', \n",
    "    'lambda_l1': 5, \n",
    "    'learning_rate': 0.01, \n",
    "    'num_leaves': 64\n",
    "}\n",
    "\n",
    "def xgb_train(train, target, split_list, param):\n",
    "    bst_list = []    \n",
    "    for i, (train_index, val_index, test_index) in enumerate(split_list):\n",
    "        dtrain = xgb.DMatrix(train[train_index], label=target[train_index])\n",
    "        dval = xgb.DMatrix(train[val_index], label=target[val_index])\n",
    "        watchlist = [(dtrain, 'train'), (dval, 'eval')]\n",
    "        bst = xgb.train(\n",
    "            param, dtrain, num_boost_round=1000, evals=watchlist,\n",
    "            early_stopping_rounds=100, verbose_eval=300\n",
    "        )\n",
    "        bst_list.append(bst)        \n",
    "        gc.collect()\n",
    "        del dtrain, dval    \n",
    "    return bst_list\n",
    "\n",
    "params_xgb = {\n",
    "    'objective': 'reg:squarederror', \n",
    "    'eval_metric': 'mae',\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 16,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3748189/4226476899.py:39: PolarsInefficientMapWarning: \n",
      "Expr.map_elements is significantly slower than the native expressions API.\n",
      "Only use if you absolutely CANNOT implement your logic otherwise.\n",
      "Replace this expression...\n",
      "  - pl.col(\"month\").map_elements(lambda m: ...)\n",
      "with this one instead:\n",
      "  + pl.col(\"month\").replace_strict(month_to_cluster)\n",
      "\n",
      "  pl.col(\"month\").map_elements(lambda m: month_to_cluster[m]).alias(\"date_cluster\")\n",
      "/tmp/ipykernel_3748189/4226476899.py:38: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  data = data.with_columns(\n",
      "/tmp/ipykernel_3748189/4226476899.py:45: DeprecationWarning: The argument `min_periods` for `Expr.rolling_std` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_std(window_size=4, min_periods=1)\n",
      "/tmp/ipykernel_3748189/4226476899.py:61: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_mean(window_size=3, min_periods=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.9258194925423877\n",
      "0:\tlearn: 0.0170445\ttest: 0.0161071\tbest: 0.0161071 (0)\ttotal: 90.6ms\tremaining: 1m 30s\n",
      "300:\tlearn: 0.0168737\ttest: 0.0159861\tbest: 0.0159859 (162)\ttotal: 1.83s\tremaining: 4.25s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.01598482247\n",
      "bestIteration = 324\n",
      "\n",
      "Shrink model to first 325 iterations.\n",
      "0:\tlearn: 0.0170239\ttest: 0.0174780\tbest: 0.0174780 (0)\ttotal: 7.92ms\tremaining: 7.91s\n",
      "300:\tlearn: 0.0168509\ttest: 0.0173541\tbest: 0.0173526 (291)\ttotal: 1.63s\tremaining: 3.77s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.017352632\n",
      "bestIteration = 291\n",
      "\n",
      "Shrink model to first 292 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 2230.8501571891734\n",
      "VAL SCORE CATBOOST MONTH 1: 2396.6000770342803\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's mape: 0.015975\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[400]\tvalid_0's mape: 0.017353\n",
      "VAL SCORE LIGHTGBM MONTH 0: 2228.38908453815\n",
      "VAL SCORE LIGHTGBM MONTH 1: 2395.7737851007173\n",
      "[0]\ttrain-mae:0.01942\teval-mae:0.01796\n",
      "[119]\ttrain-mae:0.01933\teval-mae:0.01805\n",
      "[0]\ttrain-mae:0.01940\teval-mae:0.01948\n",
      "[118]\ttrain-mae:0.01932\teval-mae:0.01961\n",
      "VAL SCORE XGBOOST MONTH 0: 2325.259763637552\n",
      "VAL SCORE XGBOOST MONTH 1: 2514.9904543223747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3748189/4226476899.py:39: PolarsInefficientMapWarning: \n",
      "Expr.map_elements is significantly slower than the native expressions API.\n",
      "Only use if you absolutely CANNOT implement your logic otherwise.\n",
      "Replace this expression...\n",
      "  - pl.col(\"month\").map_elements(lambda m: ...)\n",
      "with this one instead:\n",
      "  + pl.col(\"month\").replace_strict(month_to_cluster)\n",
      "\n",
      "  pl.col(\"month\").map_elements(lambda m: month_to_cluster[m]).alias(\"date_cluster\")\n",
      "/tmp/ipykernel_3748189/4226476899.py:38: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  data = data.with_columns(\n",
      "/tmp/ipykernel_3748189/4226476899.py:45: DeprecationWarning: The argument `min_periods` for `Expr.rolling_std` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_std(window_size=4, min_periods=1)\n",
      "/tmp/ipykernel_3748189/4226476899.py:61: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_mean(window_size=3, min_periods=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.9255215609513816\n",
      "0:\tlearn: 0.0272357\ttest: 0.0268333\tbest: 0.0268333 (0)\ttotal: 7.12ms\tremaining: 7.11s\n",
      "300:\tlearn: 0.0267603\ttest: 0.0263728\tbest: 0.0263659 (287)\ttotal: 1.79s\tremaining: 4.15s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.02636586239\n",
      "bestIteration = 287\n",
      "\n",
      "Shrink model to first 288 iterations.\n",
      "0:\tlearn: 0.0271595\ttest: 0.0288435\tbest: 0.0288435 (0)\ttotal: 6.85ms\tremaining: 6.84s\n",
      "300:\tlearn: 0.0266711\ttest: 0.0282086\tbest: 0.0282086 (300)\ttotal: 1.57s\tremaining: 3.64s\n",
      "600:\tlearn: 0.0266262\ttest: 0.0282088\tbest: 0.0282016 (555)\ttotal: 3.08s\tremaining: 2.04s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.0282015561\n",
      "bestIteration = 555\n",
      "\n",
      "Shrink model to first 556 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 3601.1675761829597\n",
      "VAL SCORE CATBOOST MONTH 1: 3863.935429934298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's mape: 0.0263041\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's mape: 0.028217\n",
      "VAL SCORE LIGHTGBM MONTH 0: 3589.787132035629\n",
      "VAL SCORE LIGHTGBM MONTH 1: 3862.8976581355955\n",
      "[0]\ttrain-mae:0.03126\teval-mae:0.02995\n",
      "[140]\ttrain-mae:0.03087\teval-mae:0.02994\n",
      "[0]\ttrain-mae:0.03117\teval-mae:0.03211\n",
      "[141]\ttrain-mae:0.03077\teval-mae:0.03203\n",
      "VAL SCORE XGBOOST MONTH 0: 3719.779420153686\n",
      "VAL SCORE XGBOOST MONTH 1: 4068.5203666083084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3748189/4226476899.py:39: PolarsInefficientMapWarning: \n",
      "Expr.map_elements is significantly slower than the native expressions API.\n",
      "Only use if you absolutely CANNOT implement your logic otherwise.\n",
      "Replace this expression...\n",
      "  - pl.col(\"month\").map_elements(lambda m: ...)\n",
      "with this one instead:\n",
      "  + pl.col(\"month\").replace_strict(month_to_cluster)\n",
      "\n",
      "  pl.col(\"month\").map_elements(lambda m: month_to_cluster[m]).alias(\"date_cluster\")\n",
      "/tmp/ipykernel_3748189/4226476899.py:38: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  data = data.with_columns(\n",
      "/tmp/ipykernel_3748189/4226476899.py:45: DeprecationWarning: The argument `min_periods` for `Expr.rolling_std` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_std(window_size=4, min_periods=1)\n",
      "/tmp/ipykernel_3748189/4226476899.py:61: DeprecationWarning: The argument `min_periods` for `Expr.rolling_mean` is deprecated. It has been renamed to `min_samples`.\n",
      "  .rolling_mean(window_size=3, min_periods=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.9252123488043936\n",
      "0:\tlearn: 0.0339889\ttest: 0.0353043\tbest: 0.0353043 (0)\ttotal: 6.92ms\tremaining: 6.91s\n",
      "300:\tlearn: 0.0331041\ttest: 0.0341710\tbest: 0.0341710 (300)\ttotal: 1.58s\tremaining: 3.67s\n",
      "600:\tlearn: 0.0329678\ttest: 0.0341235\tbest: 0.0341222 (589)\ttotal: 3.2s\tremaining: 2.12s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.03412034114\n",
      "bestIteration = 637\n",
      "\n",
      "Shrink model to first 638 iterations.\n",
      "0:\tlearn: 0.0338511\ttest: 0.0369089\tbest: 0.0369089 (0)\ttotal: 7.42ms\tremaining: 7.41s\n",
      "300:\tlearn: 0.0329922\ttest: 0.0356298\tbest: 0.0356147 (219)\ttotal: 1.49s\tremaining: 3.47s\n",
      "600:\tlearn: 0.0328507\ttest: 0.0356595\tbest: 0.0355896 (418)\ttotal: 2.94s\tremaining: 1.95s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.03558957083\n",
      "bestIteration = 418\n",
      "\n",
      "Shrink model to first 419 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 4630.329157343291\n",
      "VAL SCORE CATBOOST MONTH 1: 4979.110390750926\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[701]\tvalid_0's mape: 0.0341569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[535]\tvalid_0's mape: 0.0356815\n",
      "VAL SCORE LIGHTGBM MONTH 0: 4649.405376527841\n",
      "VAL SCORE LIGHTGBM MONTH 1: 4939.410874596823\n",
      "[0]\ttrain-mae:0.03911\teval-mae:0.03935\n",
      "[187]\ttrain-mae:0.03840\teval-mae:0.03914\n",
      "[0]\ttrain-mae:0.03897\teval-mae:0.04054\n",
      "[195]\ttrain-mae:0.03826\teval-mae:0.04022\n",
      "VAL SCORE XGBOOST MONTH 0: 4949.5864750727915\n",
      "VAL SCORE XGBOOST MONTH 1: 5234.384214363919\n"
     ]
    }
   ],
   "source": [
    "data = data.sort([\"id_house\", \"date\"])\n",
    "\n",
    "feature_cols = [\n",
    "    'build_year_median', 'vc_city_quadkey', 'number_total', 'new_target', 'mean_price',\n",
    "    'num_builds_live', 'room_one', 'med_price_mean'\n",
    "]\n",
    "\n",
    "cbstats = []\n",
    "lgbstats = []\n",
    "xgbstats = []\n",
    "corrs = []\n",
    "\n",
    "for m_predict in [1, 2, 3]:\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"mean_price\").shift(m_predict).over(\"id_house\").alias(f\"mean_price_shift_{m_predict}\")\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        (pl.col(\"mean_price\") / pl.col(f\"mean_price_shift_{m_predict}\")).alias(\"new_target\")\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"date\").dt.month().alias(\"month\")\n",
    "    )\n",
    "\n",
    "    monthstats = data.group_by(\"month\").agg(\n",
    "        pl.col(\"new_target\").mean().alias(\"new_target_mean\")\n",
    "    )\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    month_cluster = kmeans.fit_predict(\n",
    "        monthstats.select(\"new_target_mean\").to_numpy().ravel().reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "    month_to_cluster = { row[0]: cluster for row, cluster in zip(monthstats.iter_rows(), month_cluster) }\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"month\").map_elements(lambda m: month_to_cluster[m]).alias(\"date_cluster\")\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"mean_price\")\n",
    "          .diff()\n",
    "          .rolling_std(window_size=4, min_periods=1)\n",
    "          .shift(m_predict)\n",
    "          .over(\"id_house\")\n",
    "          .alias(\"diff_rw_std\")\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "        pl.col(\"new_target\").mean().over(\"id_house\").alias(\"house_mean\")\n",
    "    )\n",
    "\n",
    "    train_cols = ['date_cluster', 'diff_rw_std']\n",
    "\n",
    "    for col in feature_cols:\n",
    "        new_col = f\"{col}_shift_rm_{m_predict}\"\n",
    "        data = data.with_columns(\n",
    "            pl.col(col)\n",
    "              .rolling_mean(window_size=3, min_periods=1)\n",
    "              .shift(m_predict)\n",
    "              .over(\"id_house\")\n",
    "              .alias(new_col)\n",
    "        )\n",
    "        train_cols.append(new_col)\n",
    "\n",
    "    data_pd = data.to_pandas()\n",
    "    train_pd = train.to_pandas()\n",
    "    sub_pd = sub.to_pandas()\n",
    "\n",
    "    train_month = sorted(train_pd['date'].unique())\n",
    "    test_month = sorted(sub_pd['date'].unique())\n",
    "\n",
    "    split_list = []\n",
    "    list_val_months = [-1, -2]\n",
    "    for val_month in list_val_months:\n",
    "        train_index = data_pd[(data_pd['date'] > train_month[5]) & (data_pd['date'] <= train_month[val_month - 1])].index\n",
    "        val_index = data_pd[data_pd['date'] == train_month[val_month]].index\n",
    "        test_index = data_pd[data_pd['date'] == test_month[m_predict - 1]].index\n",
    "        split_list.append((train_index, val_index, test_index))\n",
    "\n",
    "    vals = data_pd[train_cols].corr().abs().values\n",
    "    max_corr = vals[~np.eye(vals.shape[0], dtype=bool)].max()\n",
    "    print('CHECK CORR COLS:', max_corr < 0.95, 'MAX CORR:', max_corr)\n",
    "    corrs.append(max_corr)\n",
    "\n",
    "    bst_list_catboost = catboost_train(data_pd[train_cols].values, data_pd['new_target'].values, split_list, params_cat)\n",
    "    catboost_preds = []\n",
    "    for num_, bst in enumerate(bst_list_catboost):\n",
    "        val_index = split_list[num_][-2]\n",
    "        val_pred = bst.predict(data_pd[train_cols].values[val_index]) * data_pd[f'mean_price_shift_{m_predict}'][val_index]\n",
    "        score = (data_pd['mean_price'][val_index] - val_pred).abs().mean()\n",
    "        print(f'VAL SCORE CATBOOST MONTH {num_}:', score)\n",
    "        cbstats.append(score)\n",
    "        test_index = split_list[num_][-1]\n",
    "        catboost_preds.append(\n",
    "            bst.predict(data_pd[train_cols].values[test_index]) * data_pd[f'mean_price_shift_{m_predict}'][test_index]\n",
    "        )\n",
    "    catboost_preds = np.mean(catboost_preds, axis=0)\n",
    "\n",
    "    bst_list_lgb = lgb_train(data_pd[train_cols].values, data_pd['new_target'].values, split_list, params_lgb)\n",
    "    lgb_preds = []\n",
    "    for num_, bst in enumerate(bst_list_lgb):\n",
    "        val_index = split_list[num_][-2]\n",
    "        val_pred = bst.predict(data_pd[train_cols].values[val_index]) * data_pd[f'mean_price_shift_{m_predict}'][val_index]\n",
    "        score = (data_pd['mean_price'][val_index] - val_pred).abs().mean()\n",
    "        print(f'VAL SCORE LIGHTGBM MONTH {num_}:', score)\n",
    "        lgbstats.append(score)\n",
    "        test_index = split_list[num_][-1]\n",
    "        lgb_preds.append(\n",
    "            bst.predict(data_pd[train_cols].values[test_index]) * data_pd[f'mean_price_shift_{m_predict}'][test_index]\n",
    "        )\n",
    "    lgb_preds = np.mean(lgb_preds, axis=0)\n",
    "\n",
    "    bst_list_xgb = xgb_train(data_pd[train_cols].values, data_pd['new_target'].values, split_list, params_xgb)\n",
    "    xgb_preds = []\n",
    "    for num_, bst in enumerate(bst_list_xgb):\n",
    "        val_index = split_list[num_][-2]\n",
    "        dval = xgb.DMatrix(data_pd[train_cols].values[val_index])\n",
    "        val_pred = bst.predict(dval) * data_pd[f'mean_price_shift_{m_predict}'][val_index]\n",
    "        score = (data_pd['mean_price'][val_index] - val_pred).abs().mean()\n",
    "        print(f'VAL SCORE XGBOOST MONTH {num_}:', score)\n",
    "        xgbstats.append(score)\n",
    "        test_index = split_list[num_][-1]\n",
    "        dtest = xgb.DMatrix(data_pd[train_cols].values[test_index])\n",
    "        xgb_preds.append(\n",
    "            bst.predict(dtest) * data_pd[f'mean_price_shift_{m_predict}'][test_index]\n",
    "        )\n",
    "    xgb_preds = np.mean(xgb_preds, axis=0)\n",
    "\n",
    "    data_pd.loc[test_index, 'preds'] = (catboost_preds * 0.4995 + lgb_preds * 0.4995 + xgb_preds * 0.001) / (0.4995 + 0.4995 + 0.001)\n",
    "\n",
    "    data = pl.from_pandas(data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report\n",
      "\n",
      "CB Mean:     3617.0\n",
      "LGB Mean:    3610.94\n",
      "XGB Mean:    3802.09\n",
      "\n",
      "CB Mean by model:     [2313.73 3732.55 4804.72]\n",
      "LGB Mean by model:    [2312.08 3726.34 4794.41]\n",
      "XGB Mean by model:    [2420.13 3894.15 5091.99]\n",
      "\n",
      "Max col corr: 0.926\n",
      "Columns: 10\n",
      "\n",
      "CatBoost\n",
      "[[2230.85 2396.6 ]\n",
      " [3601.17 3863.94]\n",
      " [4630.33 4979.11]]\n",
      "\n",
      "LightGBM\n",
      "[[2228.39 2395.77]\n",
      " [3589.79 3862.9 ]\n",
      " [4649.41 4939.41]]\n",
      "\n",
      "XGBoost\n",
      "[[2325.26 2514.99]\n",
      " [3719.78 4068.52]\n",
      " [4949.59 5234.38]]\n"
     ]
    }
   ],
   "source": [
    "print('Validation Report')\n",
    "print()\n",
    "print('CB Mean:    ', np.array(cbstats).mean().round(2))\n",
    "print('LGB Mean:   ', np.array(lgbstats).mean().round(2))\n",
    "print('XGB Mean:   ', np.array(xgbstats).mean().round(2))\n",
    "print()\n",
    "print('CB Mean by model:    ', np.array(cbstats).reshape(-1, 2).mean(axis=1).round(2))\n",
    "print('LGB Mean by model:   ', np.array(lgbstats).reshape(-1, 2).mean(axis=1).round(2))\n",
    "print('XGB Mean by model:   ', np.array(xgbstats).reshape(-1, 2).mean(axis=1).round(2))\n",
    "print()\n",
    "print('Max col corr:', '{:.3f}'.format(max(corrs)))\n",
    "print(f'Columns: {len(train_cols)}')\n",
    "print()\n",
    "print('CatBoost')\n",
    "print(np.array(cbstats).round(2).reshape(-1, 2))\n",
    "print()\n",
    "print('LightGBM')\n",
    "print(np.array(lgbstats).round(2).reshape(-1, 2))\n",
    "print()\n",
    "print('XGBoost')\n",
    "print(np.array(xgbstats).round(2).reshape(-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min target: 12400.056688078163\n",
      "null count in target: 0\n"
     ]
    }
   ],
   "source": [
    "sub = sub.with_columns(pl.col(\"date\").cast(pl.Date))\n",
    "data = data.with_columns(pl.col(\"date\").cast(pl.Date))\n",
    "\n",
    "sub = sub.join(data.select([\"date\", \"id_house\", \"preds\"]), on=[\"date\", \"id_house\"], how=\"left\")\n",
    "\n",
    "sub = sub.with_columns(pl.col(\"preds\").alias(\"target\"))\n",
    "\n",
    "!rm -rf /kaggle/working/\n",
    "\n",
    "sub.select([\"id\", \"target\"]).write_csv(\"submission.csv\")\n",
    "\n",
    "min_target = sub.select(pl.col(\"target\").min()).to_series()[0]\n",
    "null_count = sub.select(pl.col(\"target\").is_null().sum()).to_series()[0]\n",
    "print(\"min target:\", min_target)\n",
    "print(\"null count in target:\", null_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
