{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-09T11:56:57.487729Z",
     "iopub.status.busy": "2025-02-09T11:56:57.487327Z",
     "iopub.status.idle": "2025-02-09T11:56:57.493015Z",
     "shell.execute_reply": "2025-02-09T11:56:57.491690Z",
     "shell.execute_reply.started": "2025-02-09T11:56:57.487690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import catboost\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "sub = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(by=['id_house', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub['date'] = sub['id'].apply(lambda x:x.split('_')[0])\n",
    "sub['id_house'] = sub['id'].apply(lambda x:int(x.split('_')[1]))\n",
    "sub['date'] = pd.to_datetime(sub['date'])\n",
    "train['date'] = pd.to_datetime(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2022-06-01 00:00:00', '2022-07-01 00:00:00', '2022-08-01 00:00:00']\n",
       "Length: 3, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['date'].unique()\n",
    "# 3 month to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a7359f9e914602babd76d55a5cdb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3668655/1708781698.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data[col] = data.groupby('id_house', group_keys = False)[col].apply(lambda x:x.fillna(method = 'bfill').fillna(method = 'ffill'))\n"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(train['date'].min(), sub['date'].max(), freq = 'MS').tolist()\n",
    "city_list = []\n",
    "time_list = []\n",
    "for city in sub['id_house'].unique():\n",
    "    time_list += date_range\n",
    "    city_list += [city] * len(date_range)\n",
    "data = pd.DataFrame()\n",
    "data['id_house'] = city_list\n",
    "data['date'] = time_list\n",
    "data = data.merge(train, on = ['id_house', 'date'], how = 'left')\n",
    "data_other_columns = [x for x in data.columns if x not in ['id_house', 'date']]\n",
    "#fill issing data\n",
    "for col in tqdm(data_other_columns):\n",
    "    data[col] = data.groupby('id_house', group_keys = False)[col].apply(lambda x:x.fillna(method = 'bfill').fillna(method = 'ffill'))\n",
    "\n",
    "data['preds'] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "coords_data = data.drop_duplicates('id_house')[['lat', 'lng']]\n",
    "nn = NearestNeighbors(n_neighbors=10)\n",
    "nn.fit(coords_data.values)\n",
    "\n",
    "col = 'med_price'\n",
    "dict_vals = data.groupby(['id_house', 'date'])[col].mean().to_dict()\n",
    "dict_ind_house = {i: k for i, k in enumerate(data['id_house'].unique())}\n",
    "list_month = data['date'].unique()\n",
    "\n",
    "dict_mean = {}\n",
    "dict_std = {}\n",
    "for neighbors in nn.kneighbors(coords_data.values)[1]:\n",
    "    for month in list_month:\n",
    "        vals = []\n",
    "        for neighbor in neighbors:\n",
    "            if (dict_ind_house[neighbor], month) in dict_vals:\n",
    "                vals += [dict_vals[(dict_ind_house[neighbor], month)]]\n",
    "        if len(vals) > 0:\n",
    "            dict_mean[(dict_ind_house[neighbors[0]], month)] = np.mean(vals)\n",
    "\n",
    "data['med_price_mean'] = [dict_mean.get((c, m), None) for c, m in data[['id_house', 'date']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def catboost_train(train, target, split_list, param):\n",
    "    bst_list = []\n",
    "    \n",
    "    for i, (train_index, val_index, test_index) in enumerate(split_list):\n",
    "        tr = catboost.Pool(train[train_index], label=target[train_index])\n",
    "        te = catboost.Pool(train[val_index], label=target[val_index])\n",
    "        \n",
    "        bst = catboost.train(\n",
    "            tr, param, eval_set=te, \n",
    "            iterations=1000, early_stopping_rounds=200, verbose=300\n",
    "        )\n",
    "        \n",
    "        bst_list.append(bst)\n",
    "        \n",
    "        gc.collect()\n",
    "        del tr, te\n",
    "    \n",
    "    return bst_list\n",
    "\n",
    "params_cat = {\n",
    "    'loss_function': 'MAE', \n",
    "    'max_depth': 6, \n",
    "    'eval_metric': 'MAPE', \n",
    "    'learning_rate': 0.04, \n",
    "    'l2_leaf_reg': 20, \n",
    "    'random_state': 42, \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def lgb_train(train, target, split_list, param):\n",
    "    bst_list = []\n",
    "    \n",
    "    for i, (train_index, val_index, test_index) in enumerate(split_list):\n",
    "        tr = lgb.Dataset(train[train_index], target[train_index])\n",
    "        te = lgb.Dataset(train[val_index], target[val_index], reference=tr)\n",
    "        \n",
    "        bst = lgb.train(\n",
    "            param, tr, num_boost_round=1000, valid_sets=te,\n",
    "            callbacks=[lgb.early_stopping(100), lgb.log_evaluation(5000)]\n",
    "        )\n",
    "        \n",
    "        bst_list.append(bst)\n",
    "        \n",
    "        gc.collect()\n",
    "        del tr, te\n",
    "    \n",
    "    return bst_list\n",
    "\n",
    "params_lgb = {\n",
    "    'objective': 'mae', \n",
    "    'verbosity': -1, \n",
    "    'boosting_type': 'gbdt', \n",
    "    'metric': 'mape', \n",
    "    'lambda_l1': 5, \n",
    "    'learning_rate': 0.01, \n",
    "    'num_leaves': 64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec06f17b29a14d818b587d17178f545c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.9260504972238871\n",
      "0:\tlearn: 0.0170445\ttest: 0.0161071\tbest: 0.0161071 (0)\ttotal: 8.02ms\tremaining: 8.01s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.01598873209\n",
      "bestIteration = 83\n",
      "\n",
      "Shrink model to first 84 iterations.\n",
      "0:\tlearn: 0.0170237\ttest: 0.0174779\tbest: 0.0174779 (0)\ttotal: 9.67ms\tremaining: 9.66s\n",
      "300:\tlearn: 0.0168531\ttest: 0.0173554\tbest: 0.0173480 (241)\ttotal: 1.7s\tremaining: 3.96s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.01734796948\n",
      "bestIteration = 241\n",
      "\n",
      "Shrink model to first 242 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 2230.7901454635717\n",
      "VAL SCORE CATBOOST MONTH 1: 2395.4546648447777\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's mape: 0.0159722\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's mape: 0.0173502\n",
      "VAL SCORE LIGHTGBM MONTH 0: 2228.5927130331056\n",
      "VAL SCORE LIGHTGBM MONTH 1: 2395.136915207563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4e2c27aa4c4812ab8cc731c218b461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.925757773518557\n",
      "0:\tlearn: 0.0272367\ttest: 0.0268349\tbest: 0.0268349 (0)\ttotal: 6.83ms\tremaining: 6.82s\n",
      "300:\tlearn: 0.0267349\ttest: 0.0263432\tbest: 0.0263432 (300)\ttotal: 1.69s\tremaining: 3.93s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.02634215864\n",
      "bestIteration = 308\n",
      "\n",
      "Shrink model to first 309 iterations.\n",
      "0:\tlearn: 0.0271601\ttest: 0.0288440\tbest: 0.0288440 (0)\ttotal: 6.93ms\tremaining: 6.93s\n",
      "300:\tlearn: 0.0266462\ttest: 0.0282009\tbest: 0.0282009 (300)\ttotal: 1.5s\tremaining: 3.49s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.02819994548\n",
      "bestIteration = 302\n",
      "\n",
      "Shrink model to first 303 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 3597.12825741342\n",
      "VAL SCORE CATBOOST MONTH 1: 3861.932857781824\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's mape: 0.0263161\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's mape: 0.0282303\n",
      "VAL SCORE LIGHTGBM MONTH 0: 3590.2484021266237\n",
      "VAL SCORE LIGHTGBM MONTH 1: 3864.3537590416486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a63e07dd1674050a05da8c37db30c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK CORR COLS: True MAX CORR: 0.9254555242956002\n",
      "0:\tlearn: 0.0339889\ttest: 0.0353041\tbest: 0.0353041 (0)\ttotal: 6.6ms\tremaining: 6.59s\n",
      "300:\tlearn: 0.0331163\ttest: 0.0341692\tbest: 0.0341680 (297)\ttotal: 1.51s\tremaining: 3.5s\n",
      "600:\tlearn: 0.0329528\ttest: 0.0340891\tbest: 0.0340866 (587)\ttotal: 3.06s\tremaining: 2.03s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.03408475748\n",
      "bestIteration = 670\n",
      "\n",
      "Shrink model to first 671 iterations.\n",
      "0:\tlearn: 0.0338516\ttest: 0.0369101\tbest: 0.0369101 (0)\ttotal: 6.7ms\tremaining: 6.69s\n",
      "300:\tlearn: 0.0329509\ttest: 0.0355863\tbest: 0.0355667 (295)\ttotal: 1.45s\tremaining: 3.37s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.03556669686\n",
      "bestIteration = 295\n",
      "\n",
      "Shrink model to first 296 iterations.\n",
      "VAL SCORE CATBOOST MONTH 0: 4629.086999275065\n",
      "VAL SCORE CATBOOST MONTH 1: 4916.871360292706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\tvalid_0's mape: 0.0341497\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[877]\tvalid_0's mape: 0.0356044\n",
      "VAL SCORE LIGHTGBM MONTH 0: 4647.814785854884\n",
      "VAL SCORE LIGHTGBM MONTH 1: 4926.571974283038\n"
     ]
    }
   ],
   "source": [
    "train_month = sorted(train['date'].unique())\n",
    "test_month = sorted(sub['date'].unique())\n",
    "\n",
    "cbstats = []\n",
    "lgbstats = []\n",
    "corrs = []\n",
    "\n",
    "for m_predict in [1, 2, 3]:\n",
    "    data[f'mean_price_shift_{m_predict}'] = (\n",
    "        data.groupby('id_house', group_keys=False)['mean_price']\n",
    "        .apply(lambda x: x.shift(m_predict))\n",
    "    )\n",
    "    \n",
    "    data['new_target'] = data['mean_price'] / data[f'mean_price_shift_{m_predict}']\n",
    "\n",
    "    monthstats = data.groupby(data['date'].dt.month)[['new_target']].mean()\n",
    "    data['date_cluster'] = data['date'].dt.month.map(pd.Series(KMeans(n_clusters=2, random_state=42).fit_predict(monthstats), \n",
    "                                                       index=monthstats.index))\n",
    "\n",
    "    data['diff_rw_std'] = (data.groupby('id_house', group_keys=False)['mean_price']\n",
    "                           .apply(lambda x: x.diff().rolling(4, min_periods=1).std().shift(m_predict)))\n",
    "    \n",
    "    data['house_mean'] = data.groupby('id_house', group_keys=False)['new_target'].transform('mean')\n",
    "    \n",
    "    train_cols = ['date_cluster', 'diff_rw_std']#\n",
    "    feature_cols = [\n",
    "        'build_year_median', 'vc_city_quadkey', 'number_total', 'new_target', 'mean_price',\n",
    "        'num_builds_live', 'room_one', 'med_price_mean'\n",
    "    ]\n",
    "    \n",
    "    for col in tqdm(feature_cols):\n",
    "        data[f'{col}_shift_rm_{m_predict}'] = (\n",
    "            data.groupby('id_house', group_keys=False)[col]\n",
    "            .apply(lambda x: x.rolling(3, min_periods=1).mean().shift(m_predict))\n",
    "        )\n",
    "        train_cols.append(f'{col}_shift_rm_{m_predict}')\n",
    "    \n",
    "    split_list = []    \n",
    "    list_val_months = [-1, -2]\n",
    "    \n",
    "    for val_month in list_val_months:\n",
    "        train_index = data[(data['date'] > train_month[5]) & (data['date'] <= train_month[val_month - 1])].index\n",
    "        val_index = data[data['date'] == train_month[val_month]].index\n",
    "        test_index = data[data['date'] == test_month[m_predict - 1]].index\n",
    "        split_list.append((train_index, val_index, test_index))\n",
    "    \n",
    "    # Checking correlations\n",
    "    vals = data[train_cols].corr().abs().values\n",
    "    max_corr = vals[~np.eye(vals.shape[0], dtype=bool)].max()\n",
    "    print('CHECK CORR COLS:', max_corr < 0.95, 'MAX CORR:', max_corr)\n",
    "    corrs.append(max_corr)\n",
    "    \n",
    "    # Train CatBoost\n",
    "    bst_list_catboost = catboost_train(data[train_cols].values, data['new_target'].values, split_list, params_cat)\n",
    "    catboost_preds = []\n",
    "    \n",
    "    for num_, bst in enumerate(bst_list_catboost):\n",
    "        val_index = split_list[num_][-2]\n",
    "        val_pred = bst.predict(data[train_cols].values[val_index]) * data[f'mean_price_shift_{m_predict}'][val_index]\n",
    "        score = (data['mean_price'][val_index] - val_pred).abs().mean()\n",
    "        print(f'VAL SCORE CATBOOST MONTH {num_}:', score)\n",
    "        cbstats.append(score)\n",
    "        \n",
    "        test_index = split_list[num_][-1]\n",
    "        catboost_preds.append(\n",
    "            bst.predict(data[train_cols].values[test_index]) * data[f'mean_price_shift_{m_predict}'][test_index]\n",
    "        )\n",
    "    \n",
    "    catboost_preds = np.mean(catboost_preds, axis=0)\n",
    "    \n",
    "    # Train LightGBM\n",
    "    bst_list_lgb = lgb_train(data[train_cols].values, data['new_target'].values, split_list, params_lgb)\n",
    "    lgb_preds = []\n",
    "    \n",
    "    for num_, bst in enumerate(bst_list_lgb):\n",
    "        val_index = split_list[num_][-2]\n",
    "        val_pred = bst.predict(data[train_cols].values[val_index]) * data[f'mean_price_shift_{m_predict}'][val_index]\n",
    "        score = (data['mean_price'][val_index] - val_pred).abs().mean()\n",
    "        print(f'VAL SCORE LIGHTGBM MONTH {num_}:', score)\n",
    "        lgbstats.append(score)\n",
    "        \n",
    "        test_index = split_list[num_][-1]\n",
    "        lgb_preds.append(\n",
    "            bst.predict(data[train_cols].values[test_index]) * data[f'mean_price_shift_{m_predict}'][test_index]\n",
    "        )\n",
    "    \n",
    "    lgb_preds = np.mean(lgb_preds, axis=0)\n",
    "    \n",
    "    # Store predictions\n",
    "    data.loc[test_index, 'preds'] = (catboost_preds * 0.5 + lgb_preds * 0.5) / (0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report\n",
      "\n",
      "CB Mean:     3605.21\n",
      "LGB Mean:    3608.79\n",
      "\n",
      "CB Mean by model:     [2313.12 3729.53 4772.98]\n",
      "LGB Mean by model:    [2311.86 3727.3  4787.19]\n",
      "\n",
      "Max col corr: 0.926\n",
      "Columns (10):\n",
      "0                    date_cluster\n",
      "1                     diff_rw_std\n",
      "2    build_year_median_shift_rm_3\n",
      "3      vc_city_quadkey_shift_rm_3\n",
      "4         number_total_shift_rm_3\n",
      "5           new_target_shift_rm_3\n",
      "6           mean_price_shift_rm_3\n",
      "7      num_builds_live_shift_rm_3\n",
      "8             room_one_shift_rm_3\n",
      "9       med_price_mean_shift_rm_3\n",
      "dtype: object\n",
      "\n",
      "CatBoost\n",
      "[[2230.79 2395.45]\n",
      " [3597.13 3861.93]\n",
      " [4629.09 4916.87]]\n",
      "\n",
      "LightGBM\n",
      "[[2228.59 2395.14]\n",
      " [3590.25 3864.35]\n",
      " [4647.81 4926.57]]\n"
     ]
    }
   ],
   "source": [
    "print('Validation Report')\n",
    "print()\n",
    "print('CB Mean:    ', np.array(cbstats).mean().round(2))\n",
    "print('LGB Mean:   ', np.array(lgbstats).mean().round(2))\n",
    "print()\n",
    "print('CB Mean by model:    ', np.array(cbstats).reshape(-1, 2).mean(axis=1).round(2))\n",
    "print('LGB Mean by model:   ', np.array(lgbstats).reshape(-1, 2).mean(axis=1).round(2))\n",
    "print()\n",
    "print('Max col corr:', '{:.3f}'.format(max(corrs)))\n",
    "print(f'Columns ({len(train_cols)}):')\n",
    "print(pd.Series(train_cols))\n",
    "print()\n",
    "print('CatBoost')\n",
    "print(np.array(cbstats).round(2).reshape(-1, 2))\n",
    "print()\n",
    "print('LightGBM')\n",
    "print(np.array(lgbstats).round(2).reshape(-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12399.999799832483, 0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sub.merge(data[['date', 'id_house', 'preds']], on = ['date', 'id_house'], how = 'left')\n",
    "sub['target'] = sub['preds']\n",
    "# delete temp files of catboost from working folder\n",
    "!rm -rf /kaggle/working/\n",
    "sub[['id', 'target']].to_csv('solution.csv', index = None)\n",
    "sub['target'].min(), sub['target'].isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
