{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws1FXPusI0Bh"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArO8b4cQImY2"
      },
      "source": [
        "Alice continues her journey and now she is in 2015. Now it has become easier, as you can use word2vec! This time Alice needs help to solve the problem of summarizing news texts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MVKm9UMe7XQ"
      },
      "source": [
        "The task of summarization is to obtain a shorter text from the original text, which will contain all (or almost all) the information that was in the original text. Thus, from the text you need to obtain its summary in such a way as to lose as little information as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjvxmiYAe7XQ"
      },
      "source": [
        "Methods for solving this problem are usually divided into two categories:\n",
        "- Extractive Summarization $-$ algorithms based on identifying the most informative parts of the source text (sentences, paragraphs, etc.) and compiling a summary from them.\n",
        "- Abstractive Summarization $-$ algorithms that generate new text based on the source.\n",
        "\n",
        "We will work with Extractive Summarization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw_H8eHYe7XQ"
      },
      "source": [
        "## 0. Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1QtEzk0qe7XR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from scipy import sparse\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO9i_hsle7XR"
      },
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryDe-hb-e7XR"
      },
      "source": [
        "We will use data from the CNN/DailyMail news corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PxRpTtI4e7XR"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = './cnn_stories_short/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOa572LMe7XR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!wget https://www.dropbox.com/s/kofxrgod7kl720m/cnn_stories_short.zip\n",
        "!mkdir cnn_data\n",
        "!unzip cnn_stories_short.zip -d $DATA_DIR\n",
        "!rm -r ./cnn_stories_short/__MACOSX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf5xfzHpe7XS"
      },
      "source": [
        "### Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2VYb528e7XS"
      },
      "source": [
        "The dataset consists of source texts and already written summaries for them. We will save original texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J4vWoH6je7XS"
      },
      "outputs": [],
      "source": [
        "texts = []\n",
        "for filename in os.listdir(DATA_DIR):\n",
        "    with open(os.path.join(DATA_DIR,filename),'r') as input_file:\n",
        "        all_texts = input_file.read().split('@highlight')\n",
        "        texts.append(all_texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJpPwu7e7XS"
      },
      "source": [
        "#### We will need:\n",
        "* texts broken into sentences\n",
        "* sentences broken into tokens\n",
        "* texts, broken sentences that are broken into tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khBgQs8jhSpd",
        "outputId": "19bf61fa-8807-4b4e-a2da-adfe65b58dcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /home/gotheartem/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pF7-yhxZe7XS"
      },
      "outputs": [],
      "source": [
        "sent_tokenized_texts = [sent_tokenize(text) for text in texts]\n",
        "tokenized_sentences = [word_tokenize(sent) for text in texts for sent in sent_tokenize(text)]\n",
        "tokenized_texts = [[word_tokenize(sent) for sent in text] for text in sent_tokenized_texts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6YEJa8Je7XS"
      },
      "source": [
        "### Loading Word Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijvn-De8e7XS"
      },
      "source": [
        "For the TextRank algorithm, we need to obtain a vector representation for each sentence in the text.\n",
        "\n",
        "We will use pre-trained Glove vectors. **GloVe** (Global Vectors for Word Representation) is an unsupervised learning algorithm for obtaining vector representations for words, developed by Stanford University. It leverages global word-word co-occurrence statistics from a corpus to create dense vector embeddings that capture semantic meanings. GloVe vectors enable improved performance in various natural language processing tasks by representing words in a continuous vector space, where similar words are located closer together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0KFmssIe7XS"
      },
      "source": [
        "Let's load models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubihkQGDe7XS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss4NBNf4BWXX"
      },
      "source": [
        "The downloaded archive contains a set of files with vectors of different lengths. Each file stores a word on each line, followed by a space, the values ​​of the vector representation of this word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EIxU3lDte7XS"
      },
      "outputs": [],
      "source": [
        "word_embeddings = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f.readlines():\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        word_embeddings[word] = np.asarray(values[1:], dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0K0SK7Brc5"
      },
      "source": [
        "We stored vectors to word_embeddings value. Thus, word_embeddings is a dictionary, where key is a word and value is a vector of this word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxVuWQpyCJ5E"
      },
      "source": [
        "## Task 1: Word2Vec text representation\n",
        "\n",
        "*   For each text obtaint it's vector representation by averaging word2vec representation of each word. Just sum it component by component and divide on number of words in sentence. If word embedding model do not contain word initialize it with zeros. Use word representations saved in word_embeddings values.\n",
        "*   Count cosine similarity between each sentences and obtain matrix of cosine similarity **G**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wNGnN6UTe7XS"
      },
      "outputs": [],
      "source": [
        "# TODO complete transform function. You can add additional values in class constructor if neccesary.\n",
        "\n",
        "class TfidfEmbeddingVectorizer:\n",
        "    def __init__(self, embedding_model, dim=100):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.dim = dim\n",
        "    \n",
        "    def transform(self, X):\n",
        "        sentence_vectors = []\n",
        "        for sentence in X:\n",
        "            if len(sentence) != 0:\n",
        "                v = sum([self.embedding_model.get(word, np.zeros((self.dim,))) for word in sentence]) / len(sentence)\n",
        "            else:\n",
        "                v = np.zeros((self.dim,))\n",
        "            sentence_vectors.append(v)\n",
        "        return np.array(sentence_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ssKKoVgCe7XS"
      },
      "outputs": [],
      "source": [
        "sentence_vectorizer = TfidfEmbeddingVectorizer(word_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIcz-AJge7XS"
      },
      "source": [
        "### Building the Cosine Similarity Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBPW-s9Qe7XS"
      },
      "source": [
        "For the *TextRank* algorithm, we need to build a weighted graph from the text. The graph will be represented as a matrix of cosine similarity between sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt-LVd1je7XS"
      },
      "source": [
        "For example, let's build a graph in the form of a distance matrix for one of the texts.\n",
        "Let's choose one text and build a distance matrix for it. We'll use the cosine distance as a metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZGcPZ5OIe7XS"
      },
      "outputs": [],
      "source": [
        "TEXT_NUM = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OMJlptQ-e7XS"
      },
      "outputs": [],
      "source": [
        "sentences = tokenized_texts[TEXT_NUM]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO-WdWRIe7XS"
      },
      "source": [
        "Using the vectorizer, we will obtain vectors for all sentences of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CtLXZkxKe7XS"
      },
      "outputs": [],
      "source": [
        "vectorized_sentences = sentence_vectorizer.transform(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R21iKMMNe7XS"
      },
      "source": [
        "Let's calculate the matrix with cosine distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XXGTMo30e7XS"
      },
      "outputs": [],
      "source": [
        "## TODO calculate the matrix of cosine similarity and assign it to G value.\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def get_cosine_similarity_matrix(sentences):\n",
        "    return cosine_similarity(sentences)\n",
        "\n",
        "G = get_cosine_similarity_matrix(vectorized_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ET-m3hqe7XS"
      },
      "source": [
        "## Extractive Summarization $-$ TextRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp-VMj13e7XS"
      },
      "source": [
        "Now we will implement the text summarization method itself. It will be based on the *PageRank* algorithm.\n",
        "\n",
        "*PageRank* $-$ is a recursive algorithm that evaluates the importance of each node in the graph based on its connections with other nodes. Initially, the algorithm was used to evaluate the importance of Internet pages for search engines.\n",
        "\n",
        "The adaptation of this algorithm for text summarization is called *TextRank*.\n",
        "\n",
        "The algorithm sequentially goes through all the nodes in the graph and recalculates the PageRank values ​​for each of them using the formula below.\n",
        "\n",
        "This happens until the process stabilizes, that is, the *PageRank* values ​​for all nodes stop changing significantly with each new iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71IpX-eJe7XS"
      },
      "source": [
        "$$ G = (V,E) - граф $$\n",
        "$$$$\n",
        "$$ PageRank(v) = \\frac{(1-d)}{N} +  d \\sum_{u} \\frac {PageRank(u) * W_{(u, v)}} {C(u)}$$\n",
        "\n",
        "$$v\\ -\\ вершина\\ графа, v \\in V $$\n",
        "\n",
        "$$u\\ -\\ вершины\\ графа,\\ такие\\ что\\ (u,v) \\in E$$\n",
        "\n",
        "$$C(u) - количество \\ вершин, \\ таких \\ что (u,v) \\in E$$\n",
        "\n",
        "$$W_{(u, v)} - вес\\ ребра\\ (u, v) \\in E $$\n",
        "\n",
        "$$d = 0,85\\ -\\ коэффициент\\ затухания$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmy85qpwe7XT"
      },
      "source": [
        "Let's use NetworkX library to Page Rank algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D8etYKWUe7XT"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "nx_graph = nx.from_numpy_array(G)\n",
        "nx_scores = nx.pagerank(nx_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DHfzMgS4e7XT"
      },
      "outputs": [],
      "source": [
        "ranked_sentences = sorted(((nx_scores[i], s, i) for i,s in enumerate(sentences)), reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igrhq5s8e7XT"
      },
      "source": [
        "Let's output 5 sentences with the highest TextRank. This will be our final text summation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAEpPUaRe7XT",
        "outputId": "811efc82-5269-4bad-ef8f-5d6f1dd0d495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last year 's Hero of the Year was Pushpa Basnet , a Nepalese woman who supports children so they do n't have to live behind bars with their incarcerated parents .\n",
            "Click here to see all the extraordinary Heroes who have been featured this year .\n",
            "( CNN ) -- Ten everyday people will be recognized Thursday for their remarkable efforts to make the world a better place .\n",
            "`` We want to work with the government to bring them all out of prison .\n",
            "One of the top 10 will receive an additional $ 250,000 for their cause if the public chooses them as the CNN Hero of the Year .\n"
          ]
        }
      ],
      "source": [
        "SUMMARY_LEN = 5\n",
        "\n",
        "for i in range(SUMMARY_LEN):\n",
        "    print(' '.join(ranked_sentences[i][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4fkiVnue7XT"
      },
      "source": [
        "Now let's combine everything into one summarize function, which will receive text divided into sentences as input and output 5 sentences with the highest *TextRank*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "czbHL1xQe7XT"
      },
      "outputs": [],
      "source": [
        "def summarize(sentences,summary_len=5):\n",
        "    vectorized_sentences = sentence_vectorizer.transform(sentences)\n",
        "    G = get_cosine_similarity_matrix(vectorized_sentences)\n",
        "    nx_graph = nx.from_numpy_array(G)\n",
        "    nx_scores = nx.pagerank(nx_graph)\n",
        "    ranked_sentences = sorted(((nx_scores[i],s,i) for i,s in enumerate(sentences)), reverse=True)\n",
        "    summary = []\n",
        "    for i in range(summary_len):\n",
        "        summary.append(' '.join(ranked_sentences[i][1]))\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x90bwnQJe7XT",
        "outputId": "4aef9a79-89b0-466b-ec90-9372e9f5bace"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Last year 's Hero of the Year was Pushpa Basnet , a Nepalese woman who supports children so they do n't have to live behind bars with their incarcerated parents .\",\n",
              " 'Click here to see all the extraordinary Heroes who have been featured this year .',\n",
              " '( CNN ) -- Ten everyday people will be recognized Thursday for their remarkable efforts to make the world a better place .',\n",
              " '`` We want to work with the government to bring them all out of prison .',\n",
              " 'One of the top 10 will receive an additional $ 250,000 for their cause if the public chooses them as the CNN Hero of the Year .']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarize(tokenized_texts[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8OXOauTe7XT"
      },
      "source": [
        "Let's get summaries for all our texts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "340867e4d484439f93b2b35eedb9180a",
            "ee9dc90877ae4b50b0f0ece0d139aba8",
            "4b788a514e954e1c874fc0da68b9a40a",
            "79f1356f3a4f49368afb2f55773ea3d6",
            "ef729559d6d048059c300ee62e2992f6",
            "b7b96bff8e734db4b91172321635461f",
            "ca5baabab9c64ae49f7d2617d2b26fcd",
            "170368bdde0543dfbb92b9479a299e9f",
            "0892a613d87e4b0a83d4aebb3fb4ca7d",
            "42358745ad5149bfa4a2fedbe9827496",
            "2e1f9f18f01e4b75879170264826f98e"
          ]
        },
        "id": "W6-QvjoPe7XT",
        "outputId": "e95191bd-d521-40fc-ded5-9b5fcca0dd88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1668032/557689583.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37e12d117b0f4cdab6f57d4e7c12a8cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_c_0DtTW9tX"
      },
      "source": [
        "Let's look on the 10th sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LQ5FFoIOW6Qp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`` As a club , we had the honor of his services , albeit for a very short time , in the 1987-88 season , when we won the Spanish Cup .\n",
            "`` I wish to express our sorrow at the loss of one of football 's greatest men and one of the most charismatic and likeable managers we remember , '' Barca president Josep Maria Bartomeu said before his side 's 3-2 defeat by Valencia -- its first at home in the league since April 2012 .\n",
            "But his heart lay in the nation 's capital , where he was on the books of Atletico 's big rival Real Madrid from 1958-60 as a player -- though he spent most of that time out on loan to other clubs .\n",
            "`` Always with us , Luis , '' led the website tribute of Atletico Madrid , the club where Aragones played for a decade between 1964-74 and was head coach on four occasions , most recently 2001-03 .\n",
            "`` Today is a day of mourning for this sport , but it should also be a day of recognition for a legendary figure who was vital in giving us a glorious period with our Spanish national team .\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\".join(system_summaries[10][:5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDN4nVJYGu4i"
      },
      "source": [
        "## Task 2 IDF word2vec modification\n",
        "\n",
        "Modify your previous solution. For each text obtaint it's vector representation by averaging word2vec representation of each word multiplied by the IDF value of this word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2cHehImhHF2r"
      },
      "outputs": [],
      "source": [
        "# TODO complete transform function. You can add additional values in class constructor if neccesary.\n",
        "\n",
        "class TfidfEmbeddingVectorizer:\n",
        "    def __init__(self, embedding_model, dim=100):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.dim = dim\n",
        "        self.word_idf = {}\n",
        "    \n",
        "    def fit(self, X):\n",
        "        # Преобразуем тексты в строки\n",
        "        texts = [' '.join(sentence) for sentence in X]\n",
        "        \n",
        "        # Используем TF-IDF для оценки важности слов\n",
        "        tfidf = TfidfVectorizer()\n",
        "        tfidf.fit(texts)\n",
        "        \n",
        "        # Получаем IDF-значения\n",
        "        self.word_idf = {word: tfidf.idf_[i] for word, i in tfidf.vocabulary_.items()}\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        sentence_vectors = []\n",
        "        for sentence in X:\n",
        "            if len(sentence) != 0:\n",
        "                v = sum([self.embedding_model.get(word, np.zeros((self.dim,))) * self.word_idf.get(word, 1.0) for word in sentence]) / len(sentence)\n",
        "            else:\n",
        "                v = np.zeros((self.dim,))\n",
        "            sentence_vectors.append(v)\n",
        "        return np.array(sentence_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Upsu9v71azGa"
      },
      "outputs": [],
      "source": [
        "sentence_vectorizer = TfidfEmbeddingVectorizer(word_embeddings)\n",
        "sentence_vectorizer = sentence_vectorizer.fit(tokenized_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Qe3BCk5BHqE_"
      },
      "outputs": [],
      "source": [
        "# TODO copy your function for cosine similarity here\n",
        "\n",
        "def get_cosine_similarity_matrix(sentences):\n",
        "    return cosine_similarity(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VnT8wwh3HkHC"
      },
      "outputs": [],
      "source": [
        "def summarize(sentences,summary_len=5):\n",
        "    vectorized_sentences = sentence_vectorizer.transform(sentences)\n",
        "    G = get_cosine_similarity_matrix(vectorized_sentences)\n",
        "    nx_graph = nx.from_numpy_array(G)\n",
        "    nx_scores = nx.pagerank(nx_graph)\n",
        "    ranked_sentences = sorted(((nx_scores[i],s,i) for i,s in enumerate(sentences)), reverse=True)\n",
        "    summary = []\n",
        "    for i in range(summary_len):\n",
        "        summary.append(' '.join(ranked_sentences[i][1]))\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLjw16jUH1Q5"
      },
      "source": [
        " Summarize your texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ztVXsYR-HzAx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1668032/557689583.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef76010a237848549edf695f45ebd3d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBNC5pqTICgz"
      },
      "source": [
        "Print summary for 7-th sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Kqz8SPF1H_n2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"`` It should be noted that over many years , Jack Cafferty has expressed critical comments on many governments , including the U.S. government and its leaders . ''\",\n",
              " \"Cafferty , who appears daily on CNN 's `` The Situation Room , '' made the remarks as host Wolf Blitzer was comparing today 's China to that of 20 or 30 years ago .\",\n",
              " '`` On this occasion Jack was offering his strongly held opinion of the Chinese government , not the Chinese people -- - a point he subsequently clarified on The Situation Room on April 14 .',\n",
              " \"He issued a clarification of his remarks on Monday 's `` Situation Room , '' saying that by `` goons and thugs , '' he meant the Chinese government , not the Chinese people .\",\n",
              " \"CNN issued a statement Tuesday saying : `` We are aware of concerns about Jack Cafferty 's comments related to China in the context of the upcoming Olympics , which were broadcast on The Situation Room on April 9 , 2008 .\"]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system_summaries[7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0892a613d87e4b0a83d4aebb3fb4ca7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "170368bdde0543dfbb92b9479a299e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1f9f18f01e4b75879170264826f98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "340867e4d484439f93b2b35eedb9180a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee9dc90877ae4b50b0f0ece0d139aba8",
              "IPY_MODEL_4b788a514e954e1c874fc0da68b9a40a",
              "IPY_MODEL_79f1356f3a4f49368afb2f55773ea3d6"
            ],
            "layout": "IPY_MODEL_ef729559d6d048059c300ee62e2992f6"
          }
        },
        "42358745ad5149bfa4a2fedbe9827496": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b788a514e954e1c874fc0da68b9a40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170368bdde0543dfbb92b9479a299e9f",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0892a613d87e4b0a83d4aebb3fb4ca7d",
            "value": 300
          }
        },
        "79f1356f3a4f49368afb2f55773ea3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42358745ad5149bfa4a2fedbe9827496",
            "placeholder": "​",
            "style": "IPY_MODEL_2e1f9f18f01e4b75879170264826f98e",
            "value": " 300/300 [00:07&lt;00:00, 62.18it/s]"
          }
        },
        "b7b96bff8e734db4b91172321635461f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca5baabab9c64ae49f7d2617d2b26fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9dc90877ae4b50b0f0ece0d139aba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b96bff8e734db4b91172321635461f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5baabab9c64ae49f7d2617d2b26fcd",
            "value": "100%"
          }
        },
        "ef729559d6d048059c300ee62e2992f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
