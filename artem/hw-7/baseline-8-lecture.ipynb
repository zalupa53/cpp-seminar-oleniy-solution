{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f1b17f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-27T14:32:43.353734Z",
     "iopub.status.busy": "2025-02-27T14:32:43.353081Z",
     "iopub.status.idle": "2025-02-27T14:33:17.460802Z",
     "shell.execute_reply": "2025-02-27T14:33:17.459332Z"
    },
    "papermill": {
     "duration": 34.115753,
     "end_time": "2025-02-27T14:33:17.463265",
     "exception": false,
     "start_time": "2025-02-27T14:32:43.347512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models_pytorch\r\n",
      "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Collecting efficientnet-pytorch>=0.6.1 (from segmentation_models_pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.29.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (11.0.0)\r\n",
      "Collecting pretrainedmodels>=0.7.1 (from segmentation_models_pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (1.17.0)\r\n",
      "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (1.0.12)\r\n",
      "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.17.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2024.12.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.12.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.3->segmentation_models_pytorch) (2.4.1)\r\n",
      "Collecting munch (from pretrainedmodels>=0.7.1->segmentation_models_pytorch)\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9->segmentation_models_pytorch) (0.4.5)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.4)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.3->segmentation_models_pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.3->segmentation_models_pytorch) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation_models_pytorch) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation_models_pytorch) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.3->segmentation_models_pytorch) (2024.2.0)\r\n",
      "Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=4445a9066af2dc9aee12aa56f2642aecde790e1aa9b16091dcc28576fca5fda8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=5b52c827c151fa180a22f21102169f1b25e2a0c3e5f2f90dbcc764142c2c6ca0\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, efficientnet-pytorch, pretrainedmodels, segmentation_models_pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation_models_pytorch-0.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install segmentation_models_pytorch\n",
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import timm\n",
    "import pandas as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.amp import GradScaler\n",
    "import cv2\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f74929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:33:17.475560Z",
     "iopub.status.busy": "2025-02-27T14:33:17.474893Z",
     "iopub.status.idle": "2025-02-27T14:33:17.491722Z",
     "shell.execute_reply": "2025-02-27T14:33:17.490386Z"
    },
    "papermill": {
     "duration": 0.025199,
     "end_time": "2025-02-27T14:33:17.493870",
     "exception": false,
     "start_time": "2025-02-27T14:33:17.468671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6150e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:33:17.505546Z",
     "iopub.status.busy": "2025-02-27T14:33:17.505015Z",
     "iopub.status.idle": "2025-02-27T14:33:17.704733Z",
     "shell.execute_reply": "2025-02-27T14:33:17.701883Z"
    },
    "papermill": {
     "duration": 0.209194,
     "end_time": "2025-02-27T14:33:17.708475",
     "exception": true,
     "start_time": "2025-02-27T14:33:17.499281",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/msk_array.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d428b10c2406>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_msk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/msk_array.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_msk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_msk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/msk_array.npy'"
     ]
    }
   ],
   "source": [
    "train_msk = np.load('data/msk_array.npy')\n",
    "train_images = sorted(os.listdir('data/data/train'))\n",
    "test_images = sorted(os.listdir('data/data/test'))\n",
    "test_msk = np.zeros((len(test_images), train_msk.shape[1], train_msk.shape[2]))\n",
    "\n",
    "train_images = [f'data/data/train/{path}' for path in train_images]\n",
    "test_images = [f'data/data/test/{path}' for path in test_images]\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e312188",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_image, msks):\n",
    "\n",
    "        self.path_image = path_image\n",
    "        self.msks = msks\n",
    "        # Resize input image\n",
    "        self.image_size = 512\n",
    "\n",
    "    def resize(self, img, interp):\n",
    "        return  cv2.resize(\n",
    "            img, (self.image_size, self.image_size), interpolation=interp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_image)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        img = cv2.imread(self.path_image[i])\n",
    "        msk = self.msks[i]\n",
    "        msk = msk[:, :, None]\n",
    "\n",
    "        # img = cv2.resize(\n",
    "        #     img, (self.image_size, self.image_size), interpolation= cv2.INTER_LINEAR)\n",
    "        # msk = cv2.resize(\n",
    "        #     msk, (self.image_size, self.image_size), interpolation= cv2.INTER_LINEAR)\n",
    "\n",
    "        img = (img / 255.) - 0.5\n",
    "        img = np.transpose(img,(2,0,1)).astype(np.float32)\n",
    "        img = torch.from_numpy(img)\n",
    "        msk = torch.from_numpy(msk)\n",
    "\n",
    "        return img, msk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb37bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = smp.Unet('efficientnet-b2',\n",
    "                             encoder_weights='imagenet',\n",
    "                             classes=1,\n",
    "                             decoder_channels=[256, 128, 64, 32, 16],\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.unet(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd1fd9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 4\n",
    "valid_batch_size = 4\n",
    "epochs = 7\n",
    "lr = 3.22e-4\n",
    "clip_grad_norm = 15.28\n",
    "DEVICE = 'cuda'\n",
    "params_train = {'batch_size': batch_size, 'shuffle': True, 'drop_last': True, 'num_workers': 2}\n",
    "params_val = {'batch_size': batch_size, 'shuffle': False, 'drop_last': False, 'num_workers': 2}\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(train_images[:-70], train_msk[:-70]), **params_train)\n",
    "val_loader = torch.utils.data.DataLoader(Dataset(train_images[-70:], train_msk[-70:]), **params_val)\n",
    "\n",
    "model = Model().cuda()\n",
    "num_train_steps = int(len(train_loader) / batch_size  * epochs)\n",
    "loss_func= smp.losses.DiceLoss(mode=\"binary\", smooth=1.)\n",
    "\n",
    "scaler = GradScaler('cuda')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs, 1e-6)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    average_loss = 0\n",
    "    tk0 = tqdm(enumerate(train_loader), total = len(train_loader))\n",
    "    for batch_number,  (img, target)  in tk0:\n",
    "        optimizer.zero_grad()\n",
    "        img = img.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        # continue\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(img)\n",
    "            loss = loss_func(outputs, target)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        average_loss += loss.cpu().detach().numpy()\n",
    "        tk0.set_postfix(loss=average_loss / (batch_number + 1),lr = scheduler.get_last_lr()[0], stage=\"train\", epoch = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092920e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_val = {'batch_size': batch_size, 'shuffle': False, 'drop_last': False, 'num_workers': 2}\n",
    "test_loader = torch.utils.data.DataLoader(Dataset(test_images, test_msk), **params_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3149d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "imgs_list = []\n",
    "target_list = []\n",
    "model.eval()\n",
    "average_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_number,  (img, target)  in enumerate(test_loader):\n",
    "        img = img.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(img)\n",
    "\n",
    "        preds += [outputs.sigmoid().to('cpu').numpy()]\n",
    "\n",
    "preds = np.concatenate(preds)[:, 0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92b0c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e771c17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns: run length encoding as list\n",
    "    \"\"\"\n",
    "\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    Converts list to a string representation\n",
    "    Empty list returns '-'\n",
    "    \"\"\"\n",
    "    if x: # non-empty list\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf54b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_list = [list_to_string(rle_encode(ans)) for ans in preds]\n",
    "\n",
    "predict_df = pd.DataFrame()\n",
    "predict_df['Id'] = [f'{x:03d}.jpg' for x in range(150)]\n",
    "predict_df['Target'] = true_list\n",
    "predict_df.to_csv('submission.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.257841,
   "end_time": "2025-02-27T14:33:20.739027",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-27T14:32:39.481186",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
