{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5db35d05",
      "metadata": {
        "id": "5db35d05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cMV0vTRfAN0I",
      "metadata": {
        "id": "cMV0vTRfAN0I"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "iAtJ_d5W5T7Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAtJ_d5W5T7Y",
        "outputId": "15623f72-b00c-42db-abfc-58a8e5e907f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: https://drive.google.com/file/d/1k1quangHHsq25rJOTLShK3H0hN1mVqp9/view?usp=sharing\n",
            "zsh:1: no matches found: https://drive.google.com/file/d/1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g/view?usp=drive_link\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1k1quangHHsq25rJOTLShK3H0hN1mVqp9/view?usp=sharing -O train.csv\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g/view?usp=drive_link -O test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c4bc7518",
      "metadata": {
        "id": "c4bc7518"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_dataset = pd.read_csv('train.csv').values\n",
        "test_dataset = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76a5c735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a5c735",
        "outputId": "2083b5f5-3fba-4ee3-ecc4-102ff4aaeea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(lambda x: len(x[0]), train_dataset)) + 1\n",
        "\n",
        "MAX_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "556ae6af",
      "metadata": {
        "id": "556ae6af"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\n",
        "            'SOS': 0,\n",
        "            'EOS': 1\n",
        "        }\n",
        "        self.index2word = {\n",
        "            0: 'SOS',\n",
        "            1: 'EOS'\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def n_words(self) -> int:\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in list(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "74410a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74410a56",
        "outputId": "a84b06f1-37ea-4152-da4d-6346b5d36ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human 82\n",
            "iso 13\n"
          ]
        }
      ],
      "source": [
        "input_lang = Lang('human')\n",
        "output_lang = Lang('iso')\n",
        "\n",
        "for pair in train_dataset:\n",
        "    input_lang.add_sentence(pair[0])\n",
        "    output_lang.add_sentence(pair[1])\n",
        "\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b5e4f21a",
      "metadata": {
        "id": "b5e4f21a"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "22d4bfbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe0f376",
      "metadata": {
        "id": "8fe0f376"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.batchnorm_out = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional=True)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return (\n",
        "            torch.zeros(2, batch_size, self.hidden_size, device=device),\n",
        "            torch.zeros(2, batch_size, self.hidden_size, device=device)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # x: (seq_len, batch)\n",
        "        embedded = self.embedding(x)                  # (seq_len, batch, hidden)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # LSTM\n",
        "        packed = pack_padded_sequence(embedded, lengths, enforce_sorted=False)\n",
        "        outputs, hidden = self.lstm(packed, self.init_hidden(batch_size=x.size(1)))\n",
        "        outputs, _ = pad_packed_sequence(outputs)     # (seq_len, batch, hidden*2)\n",
        "\n",
        "        # Apply BatchNorm to LSTM outputs\n",
        "        seq_len, batch, feat = outputs.shape\n",
        "        outputs = self.batchnorm_out(outputs.view(-1, feat))\n",
        "        outputs = outputs.view(seq_len, batch, feat)\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 3, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: (1, batch, hidden_size)\n",
        "        # encoder_outputs: (seq_len, batch, hidden_size * 2)\n",
        "        seq_len, batch_size, _ = encoder_outputs.size()\n",
        "\n",
        "        hidden = hidden.repeat(seq_len, 1, 1)  # (seq_len, batch, hidden)\n",
        "        energy = torch.cat((hidden, encoder_outputs), dim=2)  # (seq_len, batch, hidden*3)\n",
        "        energy = torch.tanh(self.attn(energy))  # (seq_len, batch, hidden)\n",
        "        energy = self.dropout(energy)\n",
        "        attention = self.v(energy).squeeze(2)  # (seq_len, batch)\n",
        "\n",
        "        return F.softmax(attention, dim=0)  # (seq_len, batch)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attention = Attention(hidden_size, dropout)\n",
        "        self.lstm = nn.LSTM(hidden_size + hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs):\n",
        "        if x.dim() == 0:\n",
        "            x = x.unsqueeze(0)  # защита от скаляра\n",
        "\n",
        "        embedded = self.embedding(x).unsqueeze(0)  # (1, batch, hidden_size)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = self.attention(hidden[0], encoder_outputs)  # (seq_len, batch)\n",
        "        attn_weights = attn_weights.transpose(0, 1).unsqueeze(1)   # (batch, 1, seq_len)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.transpose(0, 1)          # (batch, seq_len, hidden*2)\n",
        "        context = torch.bmm(attn_weights, encoder_outputs)         # (batch, 1, hidden*2)\n",
        "        context = context.transpose(0, 1)                          # (1, batch, hidden*2)\n",
        "\n",
        "        lstm_input = torch.cat((embedded, context), dim=2)         # (1, batch, hidden*3)\n",
        "        output, hidden = self.lstm(lstm_input, hidden)\n",
        "\n",
        "        output = output.squeeze(0)             # (batch, hidden)\n",
        "        output = self.out(output)              # (batch, vocab_size)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "\n",
        "        return output, hidden, attn_weights.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d3308116",
      "metadata": {
        "id": "d3308116"
      },
      "outputs": [],
      "source": [
        "def sentence2idx(lang, sentence):\n",
        "    return [lang.word2index[word] for word in list(sentence)]\n",
        "\n",
        "\n",
        "def sentence2tensor(lang, sentence):\n",
        "    indexes = sentence2idx(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def pair2tensor(x):\n",
        "    input_tensor = sentence2tensor(input_lang, x[0])\n",
        "    target_tensor = sentence2tensor(output_lang, x[1])\n",
        "    return input_tensor, target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2ff20461",
      "metadata": {
        "id": "2ff20461"
      },
      "outputs": [],
      "source": [
        "def train_single(inputs, input_lengths, targets, target_lengths,\n",
        "                 encoder, decoder, encoder_opt, decoder_opt, criterion,\n",
        "                 teacher_forcing_ratio=0.5):\n",
        "    encoder_opt.zero_grad()\n",
        "    decoder_opt.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    batch_size = inputs.size(1)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(inputs, input_lengths)\n",
        "\n",
        "    # Decoder init\n",
        "    decoder_input = torch.tensor([SOS_token] * batch_size, device=device)\n",
        "    decoder_hidden = (encoder_hidden[0][:1], encoder_hidden[1][:1])  # только forward\n",
        "\n",
        "    max_target_len = targets.size(0)\n",
        "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "\n",
        "    for t in range(max_target_len):\n",
        "        decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "        # print(decoder_output)\n",
        "\n",
        "        # ⛑️ ВАЖНО: правильная форма для NLLLoss\n",
        "        loss += criterion(decoder_output, targets[t].view(-1))\n",
        "\n",
        "        if use_teacher_forcing:\n",
        "            decoder_input = targets[t].view(-1)\n",
        "        else:\n",
        "            decoder_input = decoder_output.argmax(1).detach()\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_opt.step()\n",
        "    decoder_opt.step()\n",
        "    return loss.item() / max_target_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "99270fd7",
      "metadata": {
        "id": "99270fd7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate_fn(pairs):\n",
        "    input_seqs, target_seqs = zip(*[pair2tensor(pair) for pair in pairs])\n",
        "\n",
        "    input_seqs = [seq.squeeze(1).long() for seq in input_seqs]\n",
        "    target_seqs = [seq.squeeze(1).long() for seq in target_seqs]\n",
        "\n",
        "    input_lengths = [len(seq) for seq in input_seqs]\n",
        "    target_lengths = [len(seq) for seq in target_seqs]\n",
        "\n",
        "    padded_inputs = pad_sequence(input_seqs, padding_value=EOS_token)\n",
        "    padded_targets = pad_sequence(target_seqs, padding_value=EOS_token)\n",
        "\n",
        "    return padded_inputs, input_lengths, padded_targets, target_lengths\n",
        "\n",
        "def train(encoder, decoder, n_epochs=5, batch_size=32, print_every=8):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    encoder_opt = AdamW(encoder.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "    decoder_opt = AdamW(decoder.parameters(), lr=1e-3, weight_decay=0.01)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    train_data = train_dataset\n",
        "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    scheduler_enc = torch.optim.lr_scheduler.CosineAnnealingLR(encoder_opt, len(dataloader) * n_epochs, 1e-7)\n",
        "    scheduler_dec = torch.optim.lr_scheduler.CosineAnnealingLR(decoder_opt, len(dataloader) * n_epochs, 1e-7)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        print(f\"\\nEpoch [{epoch + 1}/{n_epochs}]\")\n",
        "\n",
        "        for i, (inputs, input_lengths, targets, target_lengths) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            loss = train_single(\n",
        "                inputs, input_lengths, targets, target_lengths,\n",
        "                encoder, decoder, encoder_opt, decoder_opt, criterion\n",
        "            )\n",
        "\n",
        "            total_loss += loss\n",
        "\n",
        "            scheduler_enc.step()\n",
        "            scheduler_dec.step()\n",
        "\n",
        "            if (i + 1) % print_every == 0:\n",
        "                avg_loss = total_loss / print_every\n",
        "                print(f\"[{i + 1}/{len(dataloader)}] Loss: {avg_loss:.4f}\")\n",
        "                total_loss = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "15c1037b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/256]\n",
            "[8/35] Loss: 2.3436\n",
            "[16/35] Loss: 2.0273\n",
            "[24/35] Loss: 1.8642\n",
            "[32/35] Loss: 1.6397\n",
            "\n",
            "Epoch [2/256]\n",
            "[8/35] Loss: 1.4867\n",
            "[16/35] Loss: 1.3741\n",
            "[24/35] Loss: 1.3759\n",
            "[32/35] Loss: 1.3447\n",
            "\n",
            "Epoch [3/256]\n",
            "[8/35] Loss: 1.0168\n",
            "[16/35] Loss: 0.8429\n",
            "[24/35] Loss: 0.7430\n",
            "[32/35] Loss: 0.6715\n",
            "\n",
            "Epoch [4/256]\n",
            "[8/35] Loss: 0.6064\n",
            "[16/35] Loss: 0.5774\n",
            "[24/35] Loss: 0.5537\n",
            "[32/35] Loss: 0.5244\n",
            "\n",
            "Epoch [5/256]\n",
            "[8/35] Loss: 0.4863\n",
            "[16/35] Loss: 0.4578\n",
            "[24/35] Loss: 0.4383\n",
            "[32/35] Loss: 0.4010\n",
            "\n",
            "Epoch [6/256]\n",
            "[8/35] Loss: 0.3359\n",
            "[16/35] Loss: 0.2930\n",
            "[24/35] Loss: 0.2616\n",
            "[32/35] Loss: 0.2355\n",
            "\n",
            "Epoch [7/256]\n",
            "[8/35] Loss: 0.1907\n",
            "[16/35] Loss: 0.1728\n",
            "[24/35] Loss: 0.1298\n",
            "[32/35] Loss: 0.1134\n",
            "\n",
            "Epoch [8/256]\n",
            "[8/35] Loss: 0.0962\n",
            "[16/35] Loss: 0.1001\n",
            "[24/35] Loss: 0.0762\n",
            "[32/35] Loss: 0.0842\n",
            "\n",
            "Epoch [9/256]\n",
            "[8/35] Loss: 0.0753\n",
            "[16/35] Loss: 0.0724\n",
            "[24/35] Loss: 0.0588\n",
            "[32/35] Loss: 0.0418\n",
            "\n",
            "Epoch [10/256]\n",
            "[8/35] Loss: 0.0379\n",
            "[16/35] Loss: 0.0313\n",
            "[24/35] Loss: 0.0358\n",
            "[32/35] Loss: 0.0537\n",
            "\n",
            "Epoch [11/256]\n",
            "[8/35] Loss: 0.0328\n",
            "[16/35] Loss: 0.0366\n",
            "[24/35] Loss: 0.0374\n",
            "[32/35] Loss: 0.0295\n",
            "\n",
            "Epoch [12/256]\n",
            "[8/35] Loss: 0.0286\n",
            "[16/35] Loss: 0.0244\n",
            "[24/35] Loss: 0.0235\n",
            "[32/35] Loss: 0.0189\n",
            "\n",
            "Epoch [13/256]\n",
            "[8/35] Loss: 0.0148\n",
            "[16/35] Loss: 0.0129\n",
            "[24/35] Loss: 0.0145\n",
            "[32/35] Loss: 0.0140\n",
            "\n",
            "Epoch [14/256]\n",
            "[8/35] Loss: 0.0095\n",
            "[16/35] Loss: 0.0108\n",
            "[24/35] Loss: 0.0085\n",
            "[32/35] Loss: 0.0124\n",
            "\n",
            "Epoch [15/256]\n",
            "[8/35] Loss: 0.0078\n",
            "[16/35] Loss: 0.0098\n",
            "[24/35] Loss: 0.0085\n",
            "[32/35] Loss: 0.0084\n",
            "\n",
            "Epoch [16/256]\n",
            "[8/35] Loss: 0.0077\n",
            "[16/35] Loss: 0.0066\n",
            "[24/35] Loss: 0.0065\n",
            "[32/35] Loss: 0.0061\n",
            "\n",
            "Epoch [17/256]\n",
            "[8/35] Loss: 0.0089\n",
            "[16/35] Loss: 0.0090\n",
            "[24/35] Loss: 0.0060\n",
            "[32/35] Loss: 0.0052\n",
            "\n",
            "Epoch [18/256]\n",
            "[8/35] Loss: 0.0064\n",
            "[16/35] Loss: 0.0049\n",
            "[24/35] Loss: 0.0052\n",
            "[32/35] Loss: 0.0057\n",
            "\n",
            "Epoch [19/256]\n",
            "[8/35] Loss: 0.0047\n",
            "[16/35] Loss: 0.0042\n",
            "[24/35] Loss: 0.0050\n",
            "[32/35] Loss: 0.0049\n",
            "\n",
            "Epoch [20/256]\n",
            "[8/35] Loss: 0.0047\n",
            "[16/35] Loss: 0.0046\n",
            "[24/35] Loss: 0.0040\n",
            "[32/35] Loss: 0.0035\n",
            "\n",
            "Epoch [21/256]\n",
            "[8/35] Loss: 0.0040\n",
            "[16/35] Loss: 0.0031\n",
            "[24/35] Loss: 0.0029\n",
            "[32/35] Loss: 0.0031\n",
            "\n",
            "Epoch [22/256]\n",
            "[8/35] Loss: 0.0030\n",
            "[16/35] Loss: 0.0033\n",
            "[24/35] Loss: 0.0030\n",
            "[32/35] Loss: 0.0031\n",
            "\n",
            "Epoch [23/256]\n",
            "[8/35] Loss: 0.0028\n",
            "[16/35] Loss: 0.0025\n",
            "[24/35] Loss: 0.0044\n",
            "[32/35] Loss: 0.0026\n",
            "\n",
            "Epoch [24/256]\n",
            "[8/35] Loss: 0.0030\n",
            "[16/35] Loss: 0.0025\n",
            "[24/35] Loss: 0.0027\n",
            "[32/35] Loss: 0.0023\n",
            "\n",
            "Epoch [25/256]\n",
            "[8/35] Loss: 0.0045\n",
            "[16/35] Loss: 0.0022\n",
            "[24/35] Loss: 0.0022\n",
            "[32/35] Loss: 0.0024\n",
            "\n",
            "Epoch [26/256]\n",
            "[8/35] Loss: 0.0025\n",
            "[16/35] Loss: 0.0019\n",
            "[24/35] Loss: 0.0019\n",
            "[32/35] Loss: 0.0022\n",
            "\n",
            "Epoch [27/256]\n",
            "[8/35] Loss: 0.0022\n",
            "[16/35] Loss: 0.0020\n",
            "[24/35] Loss: 0.0021\n",
            "[32/35] Loss: 0.0018\n",
            "\n",
            "Epoch [28/256]\n",
            "[8/35] Loss: 0.0018\n",
            "[16/35] Loss: 0.0016\n",
            "[24/35] Loss: 0.0018\n",
            "[32/35] Loss: 0.0017\n",
            "\n",
            "Epoch [29/256]\n",
            "[8/35] Loss: 0.0023\n",
            "[16/35] Loss: 0.0018\n",
            "[24/35] Loss: 0.0017\n",
            "[32/35] Loss: 0.0021\n",
            "\n",
            "Epoch [30/256]\n",
            "[8/35] Loss: 0.0016\n",
            "[16/35] Loss: 0.0015\n",
            "[24/35] Loss: 0.0016\n",
            "[32/35] Loss: 0.0014\n",
            "\n",
            "Epoch [31/256]\n",
            "[8/35] Loss: 0.0016\n",
            "[16/35] Loss: 0.0023\n",
            "[24/35] Loss: 0.0017\n",
            "[32/35] Loss: 0.0015\n",
            "\n",
            "Epoch [32/256]\n",
            "[8/35] Loss: 0.0029\n",
            "[16/35] Loss: 0.0048\n",
            "[24/35] Loss: 0.0090\n",
            "[32/35] Loss: 0.0061\n",
            "\n",
            "Epoch [33/256]\n",
            "[8/35] Loss: 0.0038\n",
            "[16/35] Loss: 0.0031\n",
            "[24/35] Loss: 0.0028\n",
            "[32/35] Loss: 0.0026\n",
            "\n",
            "Epoch [34/256]\n",
            "[8/35] Loss: 0.0078\n",
            "[16/35] Loss: 0.0046\n",
            "[24/35] Loss: 0.0109\n",
            "[32/35] Loss: 0.0543\n",
            "\n",
            "Epoch [35/256]\n",
            "[8/35] Loss: 0.0189\n",
            "[16/35] Loss: 0.0212\n",
            "[24/35] Loss: 0.0161\n",
            "[32/35] Loss: 0.0117\n",
            "\n",
            "Epoch [36/256]\n",
            "[8/35] Loss: 0.0092\n",
            "[16/35] Loss: 0.0062\n",
            "[24/35] Loss: 0.0044\n",
            "[32/35] Loss: 0.0034\n",
            "\n",
            "Epoch [37/256]\n",
            "[8/35] Loss: 0.0026\n",
            "[16/35] Loss: 0.0024\n",
            "[24/35] Loss: 0.0023\n",
            "[32/35] Loss: 0.0021\n",
            "\n",
            "Epoch [38/256]\n",
            "[8/35] Loss: 0.0022\n",
            "[16/35] Loss: 0.0020\n",
            "[24/35] Loss: 0.0017\n",
            "[32/35] Loss: 0.0019\n",
            "\n",
            "Epoch [39/256]\n",
            "[8/35] Loss: 0.0014\n",
            "[16/35] Loss: 0.0015\n",
            "[24/35] Loss: 0.0014\n",
            "[32/35] Loss: 0.0013\n",
            "\n",
            "Epoch [40/256]\n",
            "[8/35] Loss: 0.0012\n",
            "[16/35] Loss: 0.0022\n",
            "[24/35] Loss: 0.0017\n",
            "[32/35] Loss: 0.0014\n",
            "\n",
            "Epoch [41/256]\n",
            "[8/35] Loss: 0.0018\n",
            "[16/35] Loss: 0.0015\n",
            "[24/35] Loss: 0.0013\n",
            "[32/35] Loss: 0.0023\n",
            "\n",
            "Epoch [42/256]\n",
            "[8/35] Loss: 0.0018\n",
            "[16/35] Loss: 0.0020\n",
            "[24/35] Loss: 0.0052\n",
            "[32/35] Loss: 0.0084\n",
            "\n",
            "Epoch [43/256]\n",
            "[8/35] Loss: 0.0105\n",
            "[16/35] Loss: 0.0099\n",
            "[24/35] Loss: 0.0082\n",
            "[32/35] Loss: 0.0052\n",
            "\n",
            "Epoch [44/256]\n",
            "[8/35] Loss: 0.0036\n",
            "[16/35] Loss: 0.0023\n",
            "[24/35] Loss: 0.0019\n",
            "[32/35] Loss: 0.0019\n",
            "\n",
            "Epoch [45/256]\n",
            "[8/35] Loss: 0.0015\n",
            "[16/35] Loss: 0.0018\n",
            "[24/35] Loss: 0.0012\n",
            "[32/35] Loss: 0.0012\n",
            "\n",
            "Epoch [46/256]\n",
            "[8/35] Loss: 0.0012\n",
            "[16/35] Loss: 0.0011\n",
            "[24/35] Loss: 0.0011\n",
            "[32/35] Loss: 0.0011\n",
            "\n",
            "Epoch [47/256]\n",
            "[8/35] Loss: 0.0009\n",
            "[16/35] Loss: 0.0010\n",
            "[24/35] Loss: 0.0009\n",
            "[32/35] Loss: 0.0009\n",
            "\n",
            "Epoch [48/256]\n",
            "[8/35] Loss: 0.0008\n",
            "[16/35] Loss: 0.0010\n",
            "[24/35] Loss: 0.0007\n",
            "[32/35] Loss: 0.0008\n",
            "\n",
            "Epoch [49/256]\n",
            "[8/35] Loss: 0.0008\n",
            "[16/35] Loss: 0.0008\n",
            "[24/35] Loss: 0.0007\n",
            "[32/35] Loss: 0.0007\n",
            "\n",
            "Epoch [50/256]\n",
            "[8/35] Loss: 0.0008\n",
            "[16/35] Loss: 0.0007\n",
            "[24/35] Loss: 0.0007\n",
            "[32/35] Loss: 0.0007\n",
            "\n",
            "Epoch [51/256]\n",
            "[8/35] Loss: 0.0007\n",
            "[16/35] Loss: 0.0007\n",
            "[24/35] Loss: 0.0007\n",
            "[32/35] Loss: 0.0007\n",
            "\n",
            "Epoch [52/256]\n",
            "[8/35] Loss: 0.0006\n",
            "[16/35] Loss: 0.0008\n",
            "[24/35] Loss: 0.0006\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [53/256]\n",
            "[8/35] Loss: 0.0006\n",
            "[16/35] Loss: 0.0007\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [54/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [55/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [56/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [57/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [58/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [59/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [60/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [61/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [62/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [63/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [64/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [65/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [66/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [67/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [68/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [69/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [70/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [71/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [72/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [73/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [74/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [75/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [76/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [77/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [78/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [79/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [80/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [81/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [82/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [83/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [84/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [85/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [86/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [87/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [88/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [89/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [90/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [91/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [92/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [93/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [94/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [95/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [96/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [97/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [98/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [99/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [100/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [101/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [102/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [103/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [104/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [105/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [106/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [107/256]\n",
            "[8/35] Loss: 0.0009\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [108/256]\n",
            "[8/35] Loss: 0.0996\n",
            "[16/35] Loss: 0.0623\n",
            "[24/35] Loss: 0.0717\n",
            "[32/35] Loss: 0.0547\n",
            "\n",
            "Epoch [109/256]\n",
            "[8/35] Loss: 0.0166\n",
            "[16/35] Loss: 0.0145\n",
            "[24/35] Loss: 0.0145\n",
            "[32/35] Loss: 0.0082\n",
            "\n",
            "Epoch [110/256]\n",
            "[8/35] Loss: 0.0027\n",
            "[16/35] Loss: 0.0026\n",
            "[24/35] Loss: 0.0031\n",
            "[32/35] Loss: 0.0027\n",
            "\n",
            "Epoch [111/256]\n",
            "[8/35] Loss: 0.0014\n",
            "[16/35] Loss: 0.0012\n",
            "[24/35] Loss: 0.0010\n",
            "[32/35] Loss: 0.0010\n",
            "\n",
            "Epoch [112/256]\n",
            "[8/35] Loss: 0.0009\n",
            "[16/35] Loss: 0.0009\n",
            "[24/35] Loss: 0.0009\n",
            "[32/35] Loss: 0.0008\n",
            "\n",
            "Epoch [113/256]\n",
            "[8/35] Loss: 0.0007\n",
            "[16/35] Loss: 0.0008\n",
            "[24/35] Loss: 0.0008\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [114/256]\n",
            "[8/35] Loss: 0.0006\n",
            "[16/35] Loss: 0.0007\n",
            "[24/35] Loss: 0.0007\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [115/256]\n",
            "[8/35] Loss: 0.0006\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0006\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [116/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0006\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0006\n",
            "\n",
            "Epoch [117/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0005\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [118/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0005\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [119/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [120/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0004\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0004\n",
            "\n",
            "Epoch [121/256]\n",
            "[8/35] Loss: 0.0004\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [122/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [123/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [124/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [125/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0003\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [126/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0004\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [127/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0003\n",
            "\n",
            "Epoch [128/256]\n",
            "[8/35] Loss: 0.0003\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [129/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [130/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [131/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [132/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [133/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [134/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [135/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [136/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [137/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [138/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [139/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [140/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [141/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [142/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [143/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0005\n",
            "\n",
            "Epoch [144/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0002\n",
            "\n",
            "Epoch [145/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0002\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [146/256]\n",
            "[8/35] Loss: 0.0002\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [147/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [148/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [149/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [150/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [151/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [152/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [153/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [154/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [155/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [156/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [157/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [158/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [159/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [160/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [161/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [162/256]\n",
            "[8/35] Loss: 0.0005\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0002\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [163/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [164/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [165/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [166/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [167/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [168/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [169/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [170/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [171/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [172/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [173/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [174/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [175/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [176/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [177/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [178/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [179/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [180/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [181/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [182/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [183/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [184/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [185/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [186/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [187/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [188/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0003\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [189/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [190/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [191/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [192/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [193/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [194/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [195/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [196/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [197/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [198/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [199/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [200/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [201/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [202/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [203/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [204/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [205/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [206/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [207/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [208/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [209/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [210/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [211/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [212/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [213/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [214/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [215/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [216/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [217/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [218/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [219/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [220/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [221/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [222/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [223/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [224/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [225/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [226/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [227/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [228/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [229/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [230/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [231/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [232/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [233/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [234/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [235/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [236/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [237/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [238/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [239/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [240/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [241/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [242/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [243/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [244/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [245/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [246/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [247/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [248/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [249/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [250/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [251/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [252/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [253/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [254/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [255/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n",
            "\n",
            "Epoch [256/256]\n",
            "[8/35] Loss: 0.0001\n",
            "[16/35] Loss: 0.0001\n",
            "[24/35] Loss: 0.0001\n",
            "[32/35] Loss: 0.0001\n"
          ]
        }
      ],
      "source": [
        "encoder_model = Encoder(input_lang.n_words, 128).to(device)\n",
        "decoder_model = Decoder(128, output_lang.n_words).to(device)\n",
        "\n",
        "train(encoder_model, decoder_model, n_epochs=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8e2c44d0",
      "metadata": {
        "id": "8e2c44d0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    # Подготовка входа\n",
        "    input_tensor = sentence2tensor(input_lang, sentence).squeeze(1)  # (seq_len,)\n",
        "    input_length = [input_tensor.size(0)]\n",
        "\n",
        "    input_tensor = input_tensor.unsqueeze(1)  # (seq_len, 1) — батч из 1\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor, input_length)\n",
        "\n",
        "    # Начало декодирования\n",
        "    decoder_input = torch.tensor([SOS_token], device=device)  # (1,)\n",
        "    decoder_hidden = (encoder_hidden[0][:1], encoder_hidden[1][:1])  # только forward слой\n",
        "    decoded_indices = []\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        topv, topi = decoder_output.topk(1)  # topi: (1,)\n",
        "        predicted_index = topi.item()\n",
        "        if predicted_index == EOS_token:\n",
        "            break\n",
        "        decoded_indices.append(predicted_index)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    # Преобразуем индексы в символы\n",
        "    decoded_words = [output_lang.index2word[i] for i in decoded_indices]\n",
        "    return decoded_words\n",
        "\n",
        "def predict_(encoder, decoder, dataset):\n",
        "    result = []\n",
        "    for sentence in dataset:\n",
        "        output = evaluate(encoder, decoder, sentence)\n",
        "        result.append(output[:10])  # ограничим 10 символами\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "C2euTKsiW7O9",
      "metadata": {
        "id": "C2euTKsiW7O9"
      },
      "outputs": [],
      "source": [
        "test_dataset = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b5e06197",
      "metadata": {
        "id": "b5e06197"
      },
      "outputs": [],
      "source": [
        "test_prediction = predict_(encoder_model, decoder_model, test_dataset['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "936f704c",
      "metadata": {
        "id": "936f704c"
      },
      "outputs": [],
      "source": [
        "test_prediction = [''.join(x) for x in test_prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "BtI9Xj947bUL",
      "metadata": {
        "id": "BtI9Xj947bUL"
      },
      "outputs": [],
      "source": [
        "test_dataset['label'] = test_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7467be43",
      "metadata": {
        "id": "7467be43"
      },
      "outputs": [],
      "source": [
        "test_dataset[['id', 'label']].to_csv('submission.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229db2c9",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
