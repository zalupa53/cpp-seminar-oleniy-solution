{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db35d05",
      "metadata": {
        "id": "5db35d05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cMV0vTRfAN0I",
      "metadata": {
        "id": "cMV0vTRfAN0I"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAtJ_d5W5T7Y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAtJ_d5W5T7Y",
        "outputId": "15623f72-b00c-42db-abfc-58a8e5e907f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k1quangHHsq25rJOTLShK3H0hN1mVqp9\n",
            "To: /content/train.csv\n",
            "100% 38.0k/38.0k [00:00<00:00, 106MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g\n",
            "To: /content/test.csv\n",
            "100% 134k/134k [00:00<00:00, 43.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1k1quangHHsq25rJOTLShK3H0hN1mVqp9/view?usp=sharing -O train.csv\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1NsJXT6eBrXDKXKggfWjwcYuoU84CII3g/view?usp=drive_link -O test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4bc7518",
      "metadata": {
        "id": "c4bc7518"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_dataset = pd.read_csv('train.csv').values\n",
        "test_dataset = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a5c735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a5c735",
        "outputId": "2083b5f5-3fba-4ee3-ecc4-102ff4aaeea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(lambda x: len(x[0]), train_dataset)) + 1\n",
        "\n",
        "MAX_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "556ae6af",
      "metadata": {
        "id": "556ae6af"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\n",
        "            'SOS': 0,\n",
        "            'EOS': 1\n",
        "        }\n",
        "        self.index2word = {\n",
        "            0: 'SOS',\n",
        "            1: 'EOS'\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def n_words(self) -> int:\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in list(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74410a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74410a56",
        "outputId": "a84b06f1-37ea-4152-da4d-6346b5d36ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human 82\n",
            "iso 13\n"
          ]
        }
      ],
      "source": [
        "input_lang = Lang('human')\n",
        "output_lang = Lang('iso')\n",
        "\n",
        "for pair in train_dataset:\n",
        "    input_lang.add_sentence(pair[0])\n",
        "    output_lang.add_sentence(pair[1])\n",
        "\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e4f21a",
      "metadata": {
        "id": "b5e4f21a"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe0f376",
      "metadata": {
        "id": "8fe0f376"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42832f9b",
      "metadata": {
        "id": "42832f9b"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        output = self.embedding(x).view(1, 1, -1)\n",
        "        output = self.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3308116",
      "metadata": {
        "id": "d3308116"
      },
      "outputs": [],
      "source": [
        "def sentence2idx(lang, sentence):\n",
        "    return [lang.word2index[word] for word in list(sentence)]\n",
        "\n",
        "\n",
        "def sentence2tensor(lang, sentence):\n",
        "    indexes = sentence2idx(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def pair2tensor(x):\n",
        "    input_tensor = sentence2tensor(input_lang, x[0])\n",
        "    target_tensor = sentence2tensor(output_lang, x[1])\n",
        "    return input_tensor, target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff20461",
      "metadata": {
        "id": "2ff20461"
      },
      "outputs": [],
      "source": [
        "def train_single(\n",
        "        input_tensor, target_tensor,\n",
        "        encoder, decoder,\n",
        "        encoder_optimizer, decoder_optimizer,\n",
        "        criterion\n",
        "):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    for elem in input_tensor:\n",
        "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for elem in target_tensor:\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, elem)\n",
        "            decoder_input = elem\n",
        "    else:\n",
        "        for elem in target_tensor:\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            _, topi = decoder_output.data.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, elem)\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / len(target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99270fd7",
      "metadata": {
        "id": "99270fd7"
      },
      "outputs": [],
      "source": [
        "def train(encoder, decoder, n_epochs=5, print_every=100):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    encoder_optimizer = Adam(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizer = Adam(decoder.parameters(), lr=1e-3)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print_loss_total = 0\n",
        "\n",
        "        print(f'Epoch [{epoch + 1:02d}/{n_epochs:02d}]')\n",
        "        training_pairs = [\n",
        "            pair2tensor(x) for x in train_dataset\n",
        "        ]\n",
        "\n",
        "        for i, training_pair in enumerate(training_pairs):\n",
        "            input_tensor = training_pair[0]\n",
        "            target_tensor = training_pair[1]\n",
        "\n",
        "            loss = train_single(\n",
        "                input_tensor, target_tensor,\n",
        "                encoder, decoder,\n",
        "                encoder_optimizer, decoder_optimizer,\n",
        "                criterion\n",
        "            )\n",
        "            print_loss_total += loss\n",
        "\n",
        "            if (i + 1) % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                print(f'Training ({i / len(training_pairs) * 100:.1f}%) loss: {print_loss_avg:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3f5df8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3f5df8",
        "outputId": "a2a19cc9-bea8-453d-abc9-38c57e7dc5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [01/05]\n",
            "Training (9.0%) loss: 1.8857\n",
            "Training (18.2%) loss: 1.3371\n",
            "Training (27.3%) loss: 0.7938\n",
            "Training (36.4%) loss: 0.6853\n",
            "Training (45.6%) loss: 0.6303\n",
            "Training (54.7%) loss: 0.6166\n",
            "Training (63.8%) loss: 0.5897\n",
            "Training (73.0%) loss: 0.5801\n",
            "Training (82.1%) loss: 0.5567\n",
            "Training (91.2%) loss: 0.5281\n",
            "Epoch [02/05]\n",
            "Training (9.0%) loss: 0.5171\n",
            "Training (18.2%) loss: 0.5142\n",
            "Training (27.3%) loss: 0.5084\n",
            "Training (36.4%) loss: 0.4830\n",
            "Training (45.6%) loss: 0.4673\n",
            "Training (54.7%) loss: 0.4715\n",
            "Training (63.8%) loss: 0.4440\n",
            "Training (73.0%) loss: 0.4389\n",
            "Training (82.1%) loss: 0.4135\n",
            "Training (91.2%) loss: 0.3978\n",
            "Epoch [03/05]\n",
            "Training (9.0%) loss: 0.3883\n",
            "Training (18.2%) loss: 0.3977\n",
            "Training (27.3%) loss: 0.3787\n",
            "Training (36.4%) loss: 0.3604\n",
            "Training (45.6%) loss: 0.3322\n",
            "Training (54.7%) loss: 0.3425\n",
            "Training (63.8%) loss: 0.3195\n",
            "Training (73.0%) loss: 0.2974\n",
            "Training (82.1%) loss: 0.2920\n",
            "Training (91.2%) loss: 0.2986\n",
            "Epoch [04/05]\n",
            "Training (9.0%) loss: 0.2889\n",
            "Training (18.2%) loss: 0.2651\n",
            "Training (27.3%) loss: 0.2588\n",
            "Training (36.4%) loss: 0.2510\n",
            "Training (45.6%) loss: 0.2277\n",
            "Training (54.7%) loss: 0.2215\n",
            "Training (63.8%) loss: 0.2185\n",
            "Training (73.0%) loss: 0.1834\n",
            "Training (82.1%) loss: 0.1787\n",
            "Training (91.2%) loss: 0.2003\n",
            "Epoch [05/05]\n",
            "Training (9.0%) loss: 0.2048\n",
            "Training (18.2%) loss: 0.1642\n",
            "Training (27.3%) loss: 0.1717\n",
            "Training (36.4%) loss: 0.1523\n",
            "Training (45.6%) loss: 0.1312\n",
            "Training (54.7%) loss: 0.1265\n",
            "Training (63.8%) loss: 0.1206\n",
            "Training (73.0%) loss: 0.1007\n",
            "Training (82.1%) loss: 0.1042\n",
            "Training (91.2%) loss: 0.1224\n"
          ]
        }
      ],
      "source": [
        "encoder_model = Encoder(input_lang.n_words, 128).to(device)\n",
        "decoder_model = Decoder(128, output_lang.n_words).to(device)\n",
        "\n",
        "train(encoder_model, decoder_model, n_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2c44d0",
      "metadata": {
        "id": "8e2c44d0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    input_tensor = sentence2tensor(input_lang, sentence)\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    for elem in input_tensor:\n",
        "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "\n",
        "    for di in range(max_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        _, topi = decoder_output.data.topk(1)\n",
        "\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "        if topi.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def predict_(encoder, decoder, dataset):\n",
        "    result = []\n",
        "\n",
        "    for _ in dataset:\n",
        "        result.append(evaluate(encoder, decoder, _)[:10])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C2euTKsiW7O9",
      "metadata": {
        "id": "C2euTKsiW7O9"
      },
      "outputs": [],
      "source": [
        "test_dataset = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e06197",
      "metadata": {
        "id": "b5e06197"
      },
      "outputs": [],
      "source": [
        "test_prediction = predict_(encoder_model, decoder_model, test_dataset['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936f704c",
      "metadata": {
        "id": "936f704c"
      },
      "outputs": [],
      "source": [
        "test_prediction = [''.join(x) for x in test_prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BtI9Xj947bUL",
      "metadata": {
        "id": "BtI9Xj947bUL"
      },
      "outputs": [],
      "source": [
        "test_dataset['label'] = test_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7467be43",
      "metadata": {
        "id": "7467be43"
      },
      "outputs": [],
      "source": [
        "test_dataset[['id', 'label']].to_csv('submission.csv', index=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7",
      "language": "python",
      "name": "3.7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
