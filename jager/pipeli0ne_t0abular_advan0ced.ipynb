{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eae13cc",
   "metadata": {},
   "source": [
    "# Tabular Advanced Pipeline - Продвинутая работа с табличными данными\n",
    "\n",
    "Пайплайны для:\n",
    "- Feature Engineering\n",
    "- CatBoost, XGBoost, LightGBM\n",
    "- Обработка пропусков и выбросов\n",
    "- Feature Selection\n",
    "- Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn catboost xgboost lightgbm category_encoders optuna -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from category_encoders import TargetEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Библиотеки загружены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b32cd",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c872b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "TARGET_COL = 'target'\n",
    "ID_COL = 'id'\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nИнформация о данных:\")\n",
    "print(train_df.info())\n",
    "print(f\"\\nПервые строки:\\n{train_df.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e7bd3",
   "metadata": {},
   "source": [
    "## 2. EDA и визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропущенные значения\n",
    "missing = train_df.isnull().sum()\n",
    "missing_percent = (missing / len(train_df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Percentage', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Пропущенные значения:\")\n",
    "    print(missing_df)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=missing_df.index, y=missing_df['Percentage'])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Процент пропусков по колонкам')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✓ Пропущенных значений нет!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa69820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по целевой переменной\n",
    "if TARGET_COL in train_df.columns:\n",
    "    print(f\"\\nРаспределение целевой переменной '{TARGET_COL}':\")\n",
    "    print(train_df[TARGET_COL].value_counts())\n",
    "    print(f\"\\nПропорции:\")\n",
    "    print(train_df[TARGET_COL].value_counts(normalize=True))\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    train_df[TARGET_COL].value_counts().plot(kind='bar')\n",
    "    plt.title(f'Распределение {TARGET_COL}')\n",
    "    plt.xlabel(TARGET_COL)\n",
    "    plt.ylabel('Количество')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461aef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционная матрица для числовых признаков\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if ID_COL in numeric_cols:\n",
    "    numeric_cols.remove(ID_COL)\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation = train_df[numeric_cols].corr()\n",
    "    sns.heatmap(correlation, annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title('Корреляционная матрица')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Корреляция с таргетом\n",
    "    if TARGET_COL in correlation.columns:\n",
    "        target_corr = correlation[TARGET_COL].sort_values(ascending=False)\n",
    "        print(f\"\\nТоп-10 признаков по корреляции с {TARGET_COL}:\")\n",
    "        print(target_corr.head(11))  # 11 т.к. включая сам таргет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefec01",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_engineering(df, is_train=True):\n",
    "    \"\"\"Продвинутый feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Взаимодействия числовых признаков\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if ID_COL in numeric_features:\n",
    "        numeric_features.remove(ID_COL)\n",
    "    if TARGET_COL in numeric_features and is_train:\n",
    "        numeric_features.remove(TARGET_COL)\n",
    "    \n",
    "    # Создаем произведения и суммы важных пар признаков\n",
    "    # (для примера берем первые 3 числовых признака)\n",
    "    if len(numeric_features) >= 2:\n",
    "        for i in range(min(3, len(numeric_features))):\n",
    "            for j in range(i+1, min(3, len(numeric_features))):\n",
    "                col1, col2 = numeric_features[i], numeric_features[j]\n",
    "                df[f'{col1}_{col2}_mul'] = df[col1] * df[col2]\n",
    "                df[f'{col1}_{col2}_add'] = df[col1] + df[col2]\n",
    "                df[f'{col1}_{col2}_diff'] = df[col1] - df[col2]\n",
    "                # Избегаем деления на 0\n",
    "                df[f'{col1}_{col2}_div'] = df[col1] / (df[col2] + 1e-5)\n",
    "    \n",
    "    # 2. Статистические признаки по строкам\n",
    "    if len(numeric_features) > 0:\n",
    "        df['numeric_mean'] = df[numeric_features].mean(axis=1)\n",
    "        df['numeric_std'] = df[numeric_features].std(axis=1)\n",
    "        df['numeric_max'] = df[numeric_features].max(axis=1)\n",
    "        df['numeric_min'] = df[numeric_features].min(axis=1)\n",
    "        df['numeric_median'] = df[numeric_features].median(axis=1)\n",
    "        df['numeric_range'] = df['numeric_max'] - df['numeric_min']\n",
    "    \n",
    "    # 3. Полиномиальные признаки для важных колонок\n",
    "    for col in numeric_features[:3]:  # Берем первые 3 для примера\n",
    "        df[f'{col}_squared'] = df[col] ** 2\n",
    "        df[f'{col}_cubed'] = df[col] ** 3\n",
    "        df[f'{col}_sqrt'] = np.sqrt(np.abs(df[col]))\n",
    "        df[f'{col}_log'] = np.log1p(np.abs(df[col]))\n",
    "    \n",
    "    # 4. Категориальные признаки - количество уникальных комбинаций\n",
    "    cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    if len(cat_features) >= 2:\n",
    "        for i in range(min(2, len(cat_features))):\n",
    "            for j in range(i+1, min(2, len(cat_features))):\n",
    "                df[f'{cat_features[i]}_{cat_features[j]}_combo'] = \\\n",
    "                    df[cat_features[i]].astype(str) + '_' + df[cat_features[j]].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Применение\n",
    "train_fe = advanced_feature_engineering(train_df, is_train=True)\n",
    "test_fe = advanced_feature_engineering(test_df, is_train=False)\n",
    "\n",
    "print(f\"\\nПризнаков до FE: {len(train_df.columns)}\")\n",
    "print(f\"Признаков после FE: {len(train_fe.columns)}\")\n",
    "print(f\"Создано новых признаков: {len(train_fe.columns) - len(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d0fde",
   "metadata": {},
   "source": [
    "## 4. Обработка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8cee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(train, test, target_col, id_col):\n",
    "    \"\"\"Обработка пропущенных значений\"\"\"\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    # Числовые признаки - медиана\n",
    "    numeric_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if id_col in numeric_cols:\n",
    "        numeric_cols.remove(id_col)\n",
    "    if target_col in numeric_cols:\n",
    "        numeric_cols.remove(target_col)\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if train[col].isnull().sum() > 0:\n",
    "            median_value = train[col].median()\n",
    "            train[col].fillna(median_value, inplace=True)\n",
    "            test[col].fillna(median_value, inplace=True)\n",
    "            # Создаем индикатор пропуска\n",
    "            train[f'{col}_is_missing'] = train[col].isnull().astype(int)\n",
    "            test[f'{col}_is_missing'] = test[col].isnull().astype(int)\n",
    "    \n",
    "    # Категориальные признаки - режим или 'missing'\n",
    "    cat_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        if train[col].isnull().sum() > 0:\n",
    "            train[col].fillna('missing', inplace=True)\n",
    "            test[col].fillna('missing', inplace=True)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train_fe, test_fe = handle_missing_values(train_fe, test_fe, TARGET_COL, ID_COL)\n",
    "print(\"✓ Пропуски обработаны!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee7155",
   "metadata": {},
   "source": [
    "## 5. Encoding категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90858644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем категориальные признаки\n",
    "cat_features = train_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Label Encoding для признаков с низкой кардинальностью\n",
    "low_card_features = [col for col in cat_features if train_fe[col].nunique() < 10]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in low_card_features:\n",
    "    le = LabelEncoder()\n",
    "    train_fe[col] = le.fit_transform(train_fe[col].astype(str))\n",
    "    test_fe[col] = le.transform(test_fe[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"Label Encoding применен к {len(low_card_features)} признакам\")\n",
    "\n",
    "# Target Encoding для признаков с высокой кардинальностью\n",
    "high_card_features = [col for col in cat_features if col not in low_card_features]\n",
    "\n",
    "if len(high_card_features) > 0 and TARGET_COL in train_fe.columns:\n",
    "    target_encoder = TargetEncoder(cols=high_card_features)\n",
    "    train_fe[high_card_features] = target_encoder.fit_transform(\n",
    "        train_fe[high_card_features], \n",
    "        train_fe[TARGET_COL]\n",
    "    )\n",
    "    test_fe[high_card_features] = target_encoder.transform(test_fe[high_card_features])\n",
    "    print(f\"Target Encoding применен к {len(high_card_features)} признакам\")\n",
    "\n",
    "print(\"✓ Encoding завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d5d2e",
   "metadata": {},
   "source": [
    "## 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c784eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для feature selection\n",
    "feature_cols = [col for col in train_fe.columns if col not in [TARGET_COL, ID_COL]]\n",
    "X = train_fe[feature_cols]\n",
    "y = train_fe[TARGET_COL]\n",
    "\n",
    "# Feature importance с Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-20 важных признаков:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(20), x='importance', y='feature')\n",
    "plt.title('Топ-20 важных признаков')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выбираем топ-N признаков\n",
    "TOP_N_FEATURES = 50\n",
    "selected_features = feature_importance.head(TOP_N_FEATURES)['feature'].tolist()\n",
    "print(f\"\\nВыбрано признаков: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497b934",
   "metadata": {},
   "source": [
    "## 7. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем выбранные признаки или все\n",
    "USE_SELECTED = False  # Переключите на True для использования отобранных признаков\n",
    "final_features = selected_features if USE_SELECTED else feature_cols\n",
    "\n",
    "X_train = train_fe[final_features]\n",
    "y_train = train_fe[TARGET_COL]\n",
    "X_test = test_fe[final_features]\n",
    "\n",
    "# Train/Val split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train  # Для классификации\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_tr.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b48fa0",
   "metadata": {},
   "source": [
    "### 7.1 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'Logloss',  # или 'RMSE' для регрессии\n",
    "    'eval_metric': 'AUC',\n",
    "    'random_seed': 42,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 50\n",
    "}\n",
    "\n",
    "cat_model = cb.CatBoostClassifier(**catboost_params)\n",
    "cat_model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Предсказания\n",
    "cat_val_pred = cat_model.predict_proba(X_val)[:, 1]\n",
    "cat_test_pred = cat_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cat_score = roc_auc_score(y_val, cat_val_pred)\n",
    "print(f\"\\nCatBoost Validation AUC: {cat_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23ac021",
   "metadata": {},
   "source": [
    "### 7.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 1000,\n",
    "    'objective': 'binary:logistic',  # или 'reg:squarederror' для регрессии\n",
    "    'eval_metric': 'auc',\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "xgb_val_pred = xgb_model.predict_proba(X_val)[:, 1]\n",
    "xgb_test_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_score = roc_auc_score(y_val, xgb_val_pred)\n",
    "print(f\"\\nXGBoost Validation AUC: {xgb_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2fd21",
   "metadata": {},
   "source": [
    "### 7.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_tr, y_tr)\n",
    "lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    lgb_train,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[lgb_train, lgb_val],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "lgb_val_pred = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "lgb_test_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "lgb_score = roc_auc_score(y_val, lgb_val_pred)\n",
    "print(f\"\\nLightGBM Validation AUC: {lgb_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d8c41",
   "metadata": {},
   "source": [
    "## 8. Ансамблирование (Averaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffa524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Простое усреднение предсказаний\n",
    "ensemble_val_pred = (cat_val_pred + xgb_val_pred + lgb_val_pred) / 3\n",
    "ensemble_test_pred = (cat_test_pred + xgb_test_pred + lgb_test_pred) / 3\n",
    "\n",
    "ensemble_score = roc_auc_score(y_val, ensemble_val_pred)\n",
    "\n",
    "# Сравнение\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['CatBoost', 'XGBoost', 'LightGBM', 'Ensemble'],\n",
    "    'Validation AUC': [cat_score, xgb_score, lgb_score, ensemble_score]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"СРАВНЕНИЕ МОДЕЛЕЙ\")\n",
    "print(\"=\"*50)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd7b22",
   "metadata": {},
   "source": [
    "## 9. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc165b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем лучшую модель или ансамбль\n",
    "final_predictions = ensemble_test_pred  # или cat_test_pred, xgb_test_pred и т.д.\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    ID_COL: test_df[ID_COL],\n",
    "    'prediction': final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('tabular_submission.csv', index=False)\n",
    "print(\"\\n✓ Submission сохранен!\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
