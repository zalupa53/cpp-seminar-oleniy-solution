{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0a1a4c",
   "metadata": {},
   "source": [
    "# Question Answering Pipeline - Вопросно-ответные системы\n",
    "\n",
    "Пайплайны для:\n",
    "- Extractive QA (BERT, RoBERTa)\n",
    "- Open-domain QA\n",
    "- Closed-book QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    pipeline,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DefaultDataCollator\n",
    ")\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b320fc4",
   "metadata": {},
   "source": [
    "## 1. Extractive QA (готовая модель)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка pre-trained модели для QA\n",
    "MODEL_NAME = \"deepset/roberta-base-squad2\"\n",
    "# Альтернативы: \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=MODEL_NAME,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "print(\"✓ QA модель загружена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ПРИМЕР ИСПОЛЬЗОВАНИЯ ===\n",
    "context = \"\"\"\n",
    "Python is a high-level, interpreted programming language. \n",
    "It was created by Guido van Rossum and first released in 1991.\n",
    "Python is known for its simple syntax and readability.\n",
    "\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"Who created Python?\",\n",
    "    \"When was Python released?\",\n",
    "    \"What is Python known for?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {result['answer']} (score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65431ef2",
   "metadata": {},
   "source": [
    "## 2. Загрузка данных для fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "# Формат SQuAD:\n",
    "# {\n",
    "#   \"context\": \"текст с информацией\",\n",
    "#   \"question\": \"вопрос\",\n",
    "#   \"answers\": {\n",
    "#     \"text\": [\"ответ\"],\n",
    "#     \"answer_start\": [позиция_начала]\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# train_df = pd.read_json('train_qa.json')\n",
    "\n",
    "# Пример данных\n",
    "data = {\n",
    "    'context': [\n",
    "        \"Python was created by Guido van Rossum in 1991.\",\n",
    "        \"Machine Learning is a subset of AI.\"\n",
    "    ],\n",
    "    'question': [\n",
    "        \"Who created Python?\",\n",
    "        \"What is Machine Learning?\"\n",
    "    ],\n",
    "    'answers': [\n",
    "        {'text': ['Guido van Rossum'], 'answer_start': [22]},\n",
    "        {'text': ['a subset of AI'], 'answer_start': [21]}\n",
    "    ]\n",
    "}\n",
    "train_df = pd.DataFrame(data)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02e731",
   "metadata": {},
   "source": [
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276049bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "    # Токенизация\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # Находим позиции ответов\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    \n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "    \n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples['answers'][sample_index]\n",
    "        \n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "            \n",
    "            token_start_index = 0\n",
    "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                token_start_index += 1\n",
    "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "            \n",
    "            token_end_index = len(offsets) - 1\n",
    "            while token_end_index >= 0 and offsets[token_end_index][1] >= end_char:\n",
    "                token_end_index -= 1\n",
    "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "    \n",
    "    return tokenized_examples\n",
    "\n",
    "# train_dataset = Dataset.from_pandas(train_df)\n",
    "# tokenized_dataset = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90886a12",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./qa_model\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "# )\n",
    "\n",
    "# data_collator = DefaultDataCollator()\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     data_collator=data_collator,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "# trainer.save_model(\"./qa_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e36047",
   "metadata": {},
   "source": [
    "## 5. Предсказания для соревнования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad121d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ТЕСТОВЫЕ ДАННЫЕ ===\n",
    "test_df = pd.read_csv('test_qa.csv')  # Колонки: context, question\n",
    "\n",
    "predictions = []\n",
    "for _, row in test_df.iterrows():\n",
    "    result = qa_pipeline(\n",
    "        question=row['question'],\n",
    "        context=row['context']\n",
    "    )\n",
    "    predictions.append(result['answer'])\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index if 'id' not in test_df.columns else test_df['id'],\n",
    "    'answer': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('qa_submission.csv', index=False)\n",
    "print(\"✓ Submission сохранен!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d0063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
