{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6829be8",
   "metadata": {},
   "source": [
    "# CatBoost с массивной генерацией признаков\n",
    "\n",
    "Пайплайн для:\n",
    "- Автоматическая генерация сотен признаков\n",
    "- Полиномиальные признаки, взаимодействия\n",
    "- Статистические агрегации\n",
    "- Target encoding, frequency encoding\n",
    "- CatBoost с автоматическим отбором признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b66aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost pandas numpy scikit-learn category_encoders itertools -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d30958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\n",
    "from category_encoders import TargetEncoder\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Библиотеки загружены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e355eb",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de430687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "TARGET_COL = 'target'\n",
    "ID_COL = 'id'\n",
    "TASK = 'classification'  # 'classification' или 'regression'\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df[TARGET_COL].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7153e79",
   "metadata": {},
   "source": [
    "## 2. Разделение на типы признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b618fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение признаков\n",
    "numeric_features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Удаляем служебные колонки\n",
    "if ID_COL in numeric_features:\n",
    "    numeric_features.remove(ID_COL)\n",
    "if TARGET_COL in numeric_features:\n",
    "    numeric_features.remove(TARGET_COL)\n",
    "\n",
    "print(f\"Числовых признаков: {len(numeric_features)}\")\n",
    "print(f\"Категориальных признаков: {len(categorical_features)}\")\n",
    "print(f\"\\nЧисловые: {numeric_features[:10]}...\")\n",
    "print(f\"Категориальные: {categorical_features[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d9658",
   "metadata": {},
   "source": [
    "## 3. Генерация признаков: Числовые взаимодействия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_numeric_interactions(df, numeric_cols, max_pairs=20):\n",
    "    \"\"\"\n",
    "    Генерация взаимодействий между числовыми признаками\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_features_count = 0\n",
    "    \n",
    "    # Берем топ-N признаков для взаимодействий (чтобы не создать миллионы признаков)\n",
    "    selected_cols = numeric_cols[:max_pairs]\n",
    "    \n",
    "    print(f\"Генерация взаимодействий для {len(selected_cols)} признаков...\")\n",
    "    \n",
    "    # Парные взаимодействия\n",
    "    for col1, col2 in combinations(selected_cols, 2):\n",
    "        # Произведение\n",
    "        df[f'{col1}_mul_{col2}'] = df[col1] * df[col2]\n",
    "        new_features_count += 1\n",
    "        \n",
    "        # Сумма\n",
    "        df[f'{col1}_add_{col2}'] = df[col1] + df[col2]\n",
    "        new_features_count += 1\n",
    "        \n",
    "        # Разность\n",
    "        df[f'{col1}_sub_{col2}'] = df[col1] - df[col2]\n",
    "        new_features_count += 1\n",
    "        \n",
    "        # Деление (с защитой от деления на 0)\n",
    "        df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)\n",
    "        df[f'{col2}_div_{col1}'] = df[col2] / (df[col1] + 1e-5)\n",
    "        new_features_count += 2\n",
    "        \n",
    "        # Максимум и минимум\n",
    "        df[f'{col1}_max_{col2}'] = df[[col1, col2]].max(axis=1)\n",
    "        df[f'{col1}_min_{col2}'] = df[[col1, col2]].min(axis=1)\n",
    "        new_features_count += 2\n",
    "    \n",
    "    print(f\"✓ Создано {new_features_count} новых признаков из взаимодействий\")\n",
    "    return df\n",
    "\n",
    "train_df = generate_numeric_interactions(train_df, numeric_features, max_pairs=15)\n",
    "test_df = generate_numeric_interactions(test_df, numeric_features, max_pairs=15)\n",
    "\n",
    "print(f\"Размер после взаимодействий: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd1801",
   "metadata": {},
   "source": [
    "## 4. Генерация признаков: Полиномиальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polynomial_features(df, numeric_cols, max_degree=3, max_cols=20):\n",
    "    \"\"\"\n",
    "    Полиномиальные признаки: степени, корни, логарифмы\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_features_count = 0\n",
    "    \n",
    "    selected_cols = numeric_cols[:max_cols]\n",
    "    print(f\"Генерация полиномиальных признаков для {len(selected_cols)} колонок...\")\n",
    "    \n",
    "    for col in selected_cols:\n",
    "        # Степени 2, 3\n",
    "        for degree in range(2, max_degree + 1):\n",
    "            df[f'{col}_pow{degree}'] = df[col] ** degree\n",
    "            new_features_count += 1\n",
    "        \n",
    "        # Корни\n",
    "        df[f'{col}_sqrt'] = np.sqrt(np.abs(df[col]))\n",
    "        df[f'{col}_cbrt'] = np.cbrt(df[col])\n",
    "        new_features_count += 2\n",
    "        \n",
    "        # Логарифмы\n",
    "        df[f'{col}_log'] = np.log1p(np.abs(df[col]))\n",
    "        df[f'{col}_log10'] = np.log10(np.abs(df[col]) + 1)\n",
    "        new_features_count += 2\n",
    "        \n",
    "        # Экспонента (с ограничением для стабильности)\n",
    "        df[f'{col}_exp'] = np.exp(np.clip(df[col], -10, 10))\n",
    "        new_features_count += 1\n",
    "        \n",
    "        # Тригонометрические (если значения в разумном диапазоне)\n",
    "        if df[col].abs().max() < 100:\n",
    "            df[f'{col}_sin'] = np.sin(df[col])\n",
    "            df[f'{col}_cos'] = np.cos(df[col])\n",
    "            new_features_count += 2\n",
    "    \n",
    "    print(f\"✓ Создано {new_features_count} полиномиальных признаков\")\n",
    "    return df\n",
    "\n",
    "train_df = generate_polynomial_features(train_df, numeric_features, max_degree=3, max_cols=15)\n",
    "test_df = generate_polynomial_features(test_df, numeric_features, max_degree=3, max_cols=15)\n",
    "\n",
    "print(f\"Размер после полиномиальных: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b211b80",
   "metadata": {},
   "source": [
    "## 5. Генерация признаков: Статистические агрегации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c39460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_statistical_features(df, numeric_cols):\n",
    "    \"\"\"\n",
    "    Статистические признаки по строкам\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        return df\n",
    "    \n",
    "    print(f\"Генерация статистических признаков...\")\n",
    "    \n",
    "    numeric_data = df[numeric_cols]\n",
    "    \n",
    "    # Базовые статистики\n",
    "    df['row_mean'] = numeric_data.mean(axis=1)\n",
    "    df['row_std'] = numeric_data.std(axis=1)\n",
    "    df['row_median'] = numeric_data.median(axis=1)\n",
    "    df['row_min'] = numeric_data.min(axis=1)\n",
    "    df['row_max'] = numeric_data.max(axis=1)\n",
    "    df['row_sum'] = numeric_data.sum(axis=1)\n",
    "    \n",
    "    # Производные\n",
    "    df['row_range'] = df['row_max'] - df['row_min']\n",
    "    df['row_cv'] = df['row_std'] / (df['row_mean'] + 1e-5)  # Коэффициент вариации\n",
    "    df['row_skew'] = numeric_data.skew(axis=1)\n",
    "    df['row_kurtosis'] = numeric_data.kurtosis(axis=1)\n",
    "    \n",
    "    # Квантили\n",
    "    df['row_q25'] = numeric_data.quantile(0.25, axis=1)\n",
    "    df['row_q75'] = numeric_data.quantile(0.75, axis=1)\n",
    "    df['row_iqr'] = df['row_q75'] - df['row_q25']\n",
    "    \n",
    "    # Количество нулей, положительных, отрицательных\n",
    "    df['row_zeros'] = (numeric_data == 0).sum(axis=1)\n",
    "    df['row_positive'] = (numeric_data > 0).sum(axis=1)\n",
    "    df['row_negative'] = (numeric_data < 0).sum(axis=1)\n",
    "    \n",
    "    print(f\"✓ Создано {16} статистических признаков\")\n",
    "    return df\n",
    "\n",
    "# Обновляем список числовых признаков\n",
    "current_numeric = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if ID_COL in current_numeric:\n",
    "    current_numeric.remove(ID_COL)\n",
    "if TARGET_COL in current_numeric:\n",
    "    current_numeric.remove(TARGET_COL)\n",
    "\n",
    "train_df = generate_statistical_features(train_df, numeric_features)\n",
    "test_df = generate_statistical_features(test_df, numeric_features)\n",
    "\n",
    "print(f\"Размер после статистических: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef89e0",
   "metadata": {},
   "source": [
    "## 6. Генерация признаков: Категориальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6454e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_categorical_features(train, test, cat_cols, target_col):\n",
    "    \"\"\"\n",
    "    Frequency encoding, target encoding, комбинации категорий\n",
    "    \"\"\"\n",
    "    train = train.copy()\n",
    "    test = test.copy()\n",
    "    \n",
    "    if len(cat_cols) == 0:\n",
    "        return train, test\n",
    "    \n",
    "    print(f\"Генерация категориальных признаков для {len(cat_cols)} колонок...\")\n",
    "    new_features_count = 0\n",
    "    \n",
    "    # 1. Frequency Encoding\n",
    "    for col in cat_cols:\n",
    "        freq_map = train[col].value_counts().to_dict()\n",
    "        train[f'{col}_freq'] = train[col].map(freq_map)\n",
    "        test[f'{col}_freq'] = test[col].map(freq_map).fillna(0)\n",
    "        new_features_count += 1\n",
    "    \n",
    "    # 2. Количество уникальных значений (для строк)\n",
    "    for col in cat_cols:\n",
    "        train[f'{col}_nunique'] = train[col].apply(lambda x: len(str(x)))\n",
    "        test[f'{col}_nunique'] = test[col].apply(lambda x: len(str(x)))\n",
    "        new_features_count += 1\n",
    "    \n",
    "    # 3. Комбинации категориальных признаков\n",
    "    if len(cat_cols) >= 2:\n",
    "        for col1, col2 in combinations(cat_cols[:5], 2):  # Ограничиваем 5-ю для скорости\n",
    "            train[f'{col1}_{col2}_combo'] = train[col1].astype(str) + '_' + train[col2].astype(str)\n",
    "            test[f'{col1}_{col2}_combo'] = test[col1].astype(str) + '_' + test[col2].astype(str)\n",
    "            new_features_count += 1\n",
    "    \n",
    "    # 4. Target Encoding (для высокой кардинальности)\n",
    "    high_card_cols = [col for col in cat_cols if train[col].nunique() > 10]\n",
    "    if len(high_card_cols) > 0:\n",
    "        target_encoder = TargetEncoder(cols=high_card_cols)\n",
    "        train[high_card_cols] = target_encoder.fit_transform(train[high_card_cols], train[target_col])\n",
    "        test[high_card_cols] = target_encoder.transform(test[high_card_cols])\n",
    "        print(f\"   Target encoding применен к {len(high_card_cols)} колонкам\")\n",
    "    \n",
    "    # 5. Label Encoding для низкой кардинальности\n",
    "    low_card_cols = [col for col in cat_cols if train[col].nunique() <= 10]\n",
    "    for col in low_card_cols:\n",
    "        le = LabelEncoder()\n",
    "        train[col] = le.fit_transform(train[col].astype(str))\n",
    "        test[col] = le.transform(test[col].astype(str))\n",
    "    \n",
    "    print(f\"✓ Создано {new_features_count}+ категориальных признаков\")\n",
    "    return train, test\n",
    "\n",
    "train_df, test_df = generate_categorical_features(train_df, test_df, categorical_features, TARGET_COL)\n",
    "\n",
    "print(f\"Размер после категориальных: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc249fe",
   "metadata": {},
   "source": [
    "## 7. Обработка пропусков и inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313934a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена inf на NaN\n",
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Заполнение пропусков медианой\n",
    "numeric_cols_all = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if ID_COL in numeric_cols_all:\n",
    "    numeric_cols_all.remove(ID_COL)\n",
    "if TARGET_COL in numeric_cols_all:\n",
    "    numeric_cols_all.remove(TARGET_COL)\n",
    "\n",
    "for col in numeric_cols_all:\n",
    "    if train_df[col].isnull().sum() > 0:\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "        test_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(f\"✓ Пропуски обработаны\")\n",
    "print(f\"Финальный размер train: {train_df.shape}\")\n",
    "print(f\"Финальный размер test: {test_df.shape}\")\n",
    "print(f\"Всего создано признаков: {train_df.shape[1] - len(train_df.columns) + len(numeric_features) + len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a178d9",
   "metadata": {},
   "source": [
    "## 8. Подготовка данных для CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем признаки и таргет\n",
    "feature_cols = [col for col in train_df.columns if col not in [TARGET_COL, ID_COL]]\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df[TARGET_COL]\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "# Train/Val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    "    stratify=y if TASK == 'classification' else None\n",
    ")\n",
    "\n",
    "print(f\"Количество признаков: {len(feature_cols)}\")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fda34",
   "metadata": {},
   "source": [
    "## 9. Обучение CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e944a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры CatBoost\n",
    "catboost_params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'random_seed': 42,\n",
    "    'verbose': 200,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'task_type': 'GPU' if cb.cuda.is_cuda_available() else 'CPU',\n",
    "}\n",
    "\n",
    "if TASK == 'classification':\n",
    "    catboost_params['loss_function'] = 'Logloss'\n",
    "    catboost_params['eval_metric'] = 'AUC'\n",
    "    model = cb.CatBoostClassifier(**catboost_params)\n",
    "else:\n",
    "    catboost_params['loss_function'] = 'RMSE'\n",
    "    catboost_params['eval_metric'] = 'RMSE'\n",
    "    model = cb.CatBoostRegressor(**catboost_params)\n",
    "\n",
    "print(f\"Обучение CatBoost с {len(feature_cols)} признаками...\")\n",
    "\n",
    "# Обучение\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    use_best_model=True,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Обучение завершено!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135783bd",
   "metadata": {},
   "source": [
    "## 10. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc996cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cb6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16b2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286e65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72264538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c6fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbeac84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9e838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeec41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42005890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8fd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696eadda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf0dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59f401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
