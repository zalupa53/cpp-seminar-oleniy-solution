{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7fa432",
   "metadata": {},
   "source": [
    "# Image Classification Pipeline - Классификация изображений\n",
    "\n",
    "Пайплайны для:\n",
    "- Transfer Learning (ResNet, EfficientNet, ViT)\n",
    "- Обучение CNN с нуля\n",
    "- Data Augmentation\n",
    "- TensorFlow/PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision timm albumentations opencv-python pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb22ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import timm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f442c78",
   "metadata": {},
   "source": [
    "## 1. Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ff38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "TRAIN_CSV = 'train.csv'  # CSV с колонками: image_path, label\n",
    "TEST_CSV = 'test.csv'\n",
    "IMAGE_DIR = './images'\n",
    "\n",
    "# === НАСТРОЙКИ МОДЕЛИ ===\n",
    "MODEL_NAME = 'efficientnet_b0'  # 'resnet50', 'vit_base_patch16_224', 'mobilenetv3_large_100'\n",
    "NUM_CLASSES = 10\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "print(f\"Модель: {MODEL_NAME}\")\n",
    "print(f\"Количество классов: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c6f14",
   "metadata": {},
   "source": [
    "## 2. Dataset и Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation с Albumentations\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.image_dir / row['image_path']\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image\n",
    "        else:\n",
    "            label = row['label']\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = ImageDataset(train_df, IMAGE_DIR, train_transforms)\n",
    "test_dataset = ImageDataset(test_df, IMAGE_DIR, test_transforms, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4285dc7",
   "metadata": {},
   "source": [
    "## 3. Модель (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка pre-trained модели с timm\n",
    "model = timm.create_model(\n",
    "    MODEL_NAME,\n",
    "    pretrained=True,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss и optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(\"✓ Модель загружена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb820f",
   "metadata": {},
   "source": [
    "## 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Обучение\n",
    "for epoch in range(EPOCHS):\n",
    "    loss, acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {loss:.4f}, Acc: {acc:.2f}%\")\n",
    "\n",
    "# Сохранение\n",
    "torch.save(model.state_dict(), 'image_classifier.pth')\n",
    "print(\"✓ Модель обучена и сохранена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f960c",
   "metadata": {},
   "source": [
    "## 5. Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index if 'id' not in test_df.columns else test_df['id'],\n",
    "    'prediction': predictions\n",
    "})\n",
    "submission.to_csv('image_classification_submission.csv', index=False)\n",
    "print(\"✓ Submission сохранен!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
