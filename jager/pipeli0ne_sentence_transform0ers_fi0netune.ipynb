{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e751fb32",
   "metadata": {},
   "source": [
    "# Fine-tuning Sentence Transformers на Cosine Similarity\n",
    "\n",
    "Пайплайн для:\n",
    "- Дообучение sentence-transformers моделей\n",
    "- Triplet loss, Contrastive loss, CosineSimilarityLoss\n",
    "- Evaluation на косинусном расстоянии\n",
    "- Поиск похожих текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers torch pandas numpy scikit-learn datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from sentence_transformers import models, datasets as st_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Библиотеки загружены!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f59b33",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "# Формат 1: пары текстов с оценкой похожести (0-1 или 0-5)\n",
    "# Колонки: 'text1', 'text2', 'similarity_score'\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Или формат 2: triplets (anchor, positive, negative)\n",
    "# Колонки: 'anchor', 'positive', 'negative'\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nПример данных:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80416275",
   "metadata": {},
   "source": [
    "## 2. Загрузка базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор базовой модели\n",
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'  # быстрая\n",
    "# MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'  # качественная\n",
    "# MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'  # мультиязычная\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(f\"✓ Модель загружена: {MODEL_NAME}\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f7ba4",
   "metadata": {},
   "source": [
    "## 3. Подготовка данных для обучения\n",
    "\n",
    "### Вариант A: CosineSimilarityLoss (пары с оценками)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если у вас формат: text1, text2, similarity_score\n",
    "def prepare_cosine_loss_data(df):\n",
    "    \"\"\"\n",
    "    Подготовка данных для CosineSimilarityLoss\n",
    "    similarity_score должен быть в диапазоне [0, 1] или [-1, 1]\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        text1 = str(row['text1'])\n",
    "        text2 = str(row['text2'])\n",
    "        score = float(row['similarity_score'])\n",
    "        \n",
    "        # Нормализация score если нужно (например, если 0-5, делим на 5)\n",
    "        # score = score / 5.0\n",
    "        \n",
    "        example = InputExample(texts=[text1, text2], label=score)\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Создаем примеры\n",
    "train_examples = prepare_cosine_loss_data(train_df)\n",
    "print(f\"✓ Создано {len(train_examples)} training examples\")\n",
    "print(f\"\\nПример: {train_examples[0].texts}\")\n",
    "print(f\"Label: {train_examples[0].label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9eebf7",
   "metadata": {},
   "source": [
    "### Вариант B: TripletLoss (anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если у вас формат triplets: anchor, positive, negative\n",
    "def prepare_triplet_loss_data(df):\n",
    "    \"\"\"\n",
    "    Подготовка данных для TripletLoss\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        anchor = str(row['anchor'])\n",
    "        positive = str(row['positive'])\n",
    "        negative = str(row['negative'])\n",
    "        \n",
    "        example = InputExample(texts=[anchor, positive, negative])\n",
    "        examples.append(example)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Раскомментируйте если используете triplet формат\n",
    "# train_examples = prepare_triplet_loss_data(train_df)\n",
    "# print(f\"✓ Создано {len(train_examples)} triplet examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796029c",
   "metadata": {},
   "source": [
    "### Генерация triplets из пар (если нужно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0580728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets_from_pairs(df, similarity_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Генерация triplets из пар с оценками\n",
    "    Высокая схожесть -> positive, низкая -> negative\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    \n",
    "    # Группируем похожие и непохожие пары\n",
    "    similar_pairs = df[df['similarity_score'] >= similarity_threshold]\n",
    "    dissimilar_pairs = df[df['similarity_score'] < similarity_threshold]\n",
    "    \n",
    "    for idx, row in similar_pairs.iterrows():\n",
    "        anchor = str(row['text1'])\n",
    "        positive = str(row['text2'])\n",
    "        \n",
    "        # Берем случайный negative из непохожих пар\n",
    "        if len(dissimilar_pairs) > 0:\n",
    "            neg_row = dissimilar_pairs.sample(1).iloc[0]\n",
    "            negative = str(neg_row['text2'])\n",
    "            \n",
    "            triplets.append(InputExample(texts=[anchor, positive, negative]))\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "# Раскомментируйте если хотите использовать\n",
    "# train_examples = generate_triplets_from_pairs(train_df, similarity_threshold=0.7)\n",
    "# print(f\"✓ Сгенерировано {len(train_examples)} triplets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48833edf",
   "metadata": {},
   "source": [
    "## 4. DataLoader и Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa145dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "BATCH_SIZE = 16\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Выбор loss function\n",
    "# Вариант 1: CosineSimilarityLoss для пар с оценками\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Вариант 2: TripletLoss для triplets\n",
    "# train_loss = losses.TripletLoss(model, distance_metric=losses.TripletDistanceMetric.COSINE)\n",
    "\n",
    "# Вариант 3: MultipleNegativesRankingLoss (популярный для retrieval)\n",
    "# train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Вариант 4: ContrastiveLoss\n",
    "# train_loss = losses.ContrastiveLoss(model)\n",
    "\n",
    "print(f\"✓ Loss function: {type(train_loss).__name__}\")\n",
    "print(f\"Batches per epoch: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba7e93",
   "metadata": {},
   "source": [
    "## 5. Evaluator (опционально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc83f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание валидационного сета\n",
    "train_examples_split, val_examples_split = train_test_split(\n",
    "    train_examples, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Evaluator для cosine similarity\n",
    "sentences1 = [ex.texts[0] for ex in val_examples_split]\n",
    "sentences2 = [ex.texts[1] for ex in val_examples_split]\n",
    "scores = [ex.label for ex in val_examples_split]\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(\n",
    "    sentences1, sentences2, scores,\n",
    "    name='cosine_eval'\n",
    ")\n",
    "\n",
    "# Обновляем train_dataloader для split данных\n",
    "train_dataloader = DataLoader(train_examples_split, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"✓ Evaluator создан\")\n",
    "print(f\"Train: {len(train_examples_split)}, Val: {len(val_examples_split)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e992f",
   "metadata": {},
   "source": [
    "## 6. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab12ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры обучения\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = int(len(train_dataloader) * NUM_EPOCHS * 0.1)\n",
    "OUTPUT_DIR = './finetuned_sentence_transformer'\n",
    "\n",
    "print(f\"Параметры обучения:\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Warmup steps: {WARMUP_STEPS}\")\n",
    "print(f\"Total steps: {len(train_dataloader) * NUM_EPOCHS}\")\n",
    "\n",
    "# Обучение\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    evaluation_steps=len(train_dataloader) // 2,  # Evaluation каждые полэпохи\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    output_path=OUTPUT_DIR,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Fine-tuning завершен!\")\n",
    "print(f\"Модель сохранена в: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84192c29",
   "metadata": {},
   "source": [
    "## 7. Загрузка дообученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем лучшую модель\n",
    "finetuned_model = SentenceTransformer(OUTPUT_DIR)\n",
    "print(\"✓ Дообученная модель загружена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb18c6f",
   "metadata": {},
   "source": [
    "## 8. Генерация эмбеддингов и предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e78434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация эмбеддингов для test данных\n",
    "test_texts1 = test_df['text1'].astype(str).tolist()\n",
    "test_texts2 = test_df['text2'].astype(str).tolist()\n",
    "\n",
    "print(\"Генерация эмбеддингов...\")\n",
    "embeddings1 = finetuned_model.encode(test_texts1, convert_to_numpy=True, show_progress_bar=True)\n",
    "embeddings2 = finetuned_model.encode(test_texts2, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Вычисление cosine similarity\n",
    "cosine_scores = []\n",
    "for emb1, emb2 in zip(embeddings1, embeddings2):\n",
    "    cos_sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "    cosine_scores.append(cos_sim)\n",
    "\n",
    "cosine_scores = np.array(cosine_scores)\n",
    "\n",
    "print(f\"\\n✓ Предсказания готовы!\")\n",
    "print(f\"Min similarity: {cosine_scores.min():.4f}\")\n",
    "print(f\"Max similarity: {cosine_scores.max():.4f}\")\n",
    "print(f\"Mean similarity: {cosine_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbd198",
   "metadata": {},
   "source": [
    "## 9. Сравнение с базовой моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21afa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания базовой модели\n",
    "base_model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "base_embeddings1 = base_model.encode(test_texts1[:100], convert_to_numpy=True)  # Для примера 100\n",
    "base_embeddings2 = base_model.encode(test_texts2[:100], convert_to_numpy=True)\n",
    "\n",
    "base_cosine_scores = []\n",
    "for emb1, emb2 in zip(base_embeddings1, base_embeddings2):\n",
    "    cos_sim = cosine_similarity([emb1], [emb2])[0][0]\n",
    "    base_cosine_scores.append(cos_sim)\n",
    "\n",
    "# Сравнение\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(base_cosine_scores, bins=30, alpha=0.7, label='Base Model')\n",
    "axes[0].set_title('Базовая модель')\n",
    "axes[0].set_xlabel('Cosine Similarity')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(cosine_scores[:100], bins=30, alpha=0.7, label='Fine-tuned Model', color='orange')\n",
    "axes[1].set_title('Дообученная модель')\n",
    "axes[1].set_xlabel('Cosine Similarity')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBase model mean: {np.mean(base_cosine_scores):.4f}\")\n",
    "print(f\"Fine-tuned model mean: {cosine_scores[:100].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625f512",
   "metadata": {},
   "source": [
    "## 10. Semantic Search (бонус)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, corpus, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Поиск наиболее похожих текстов из корпуса\n",
    "    \"\"\"\n",
    "    # Эмбеддинги\n",
    "    query_embedding = model.encode(query, convert_to_numpy=True)\n",
    "    corpus_embeddings = model.encode(corpus, convert_to_numpy=True, show_progress_bar=False)\n",
    "    \n",
    "    # Косинусное сходство\n",
    "    similarities = cosine_similarity([query_embedding], corpus_embeddings)[0]\n",
    "    \n",
    "    # Топ-k результатов\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'text': corpus[idx],\n",
    "            'similarity': similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования\n",
    "query = \"машинное обучение и нейронные сети\"  # === ВАШ ЗАПРОС ===\n",
    "corpus = test_texts1[:1000]  # Корпус для поиска\n",
    "\n",
    "results = semantic_search(query, corpus, finetuned_model, top_k=5)\n",
    "\n",
    "print(f\"\\nЗапрос: {query}\\n\")\n",
    "print(\"Топ-5 похожих текстов:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. Similarity: {result['similarity']:.4f}\")\n",
    "    print(f\"   Text: {result['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4683d4c5",
   "metadata": {},
   "source": [
    "## 11. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df.index,  # или test_df['id']\n",
    "    'similarity': cosine_scores\n",
    "})\n",
    "\n",
    "submission.to_csv('sentence_transformers_submission.csv', index=False)\n",
    "print(\"\\n✓ Submission сохранен!\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
