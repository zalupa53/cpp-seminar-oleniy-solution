{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a020f130",
   "metadata": {},
   "source": [
    "# Recommender Systems - CatBoost Ranker\n",
    "\n",
    "Learning to Rank с CatBoost:\n",
    "- YetiRank / YetiRankPairwise\n",
    "- PairLogitPairwise\n",
    "- Ranking метрики (NDCG, MAP)\n",
    "- Feature engineering для ранкинга\n",
    "- Group-wise обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost pandas numpy scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import ndcg_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Библиотеки загружены!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e18033",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "# Формат для ранкинга: query_id (или user_id), item_id, relevance (или rating), features\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Названия колонок\n",
    "QUERY_COL = 'user_id'  # или 'query_id'\n",
    "ITEM_COL = 'item_id'\n",
    "RELEVANCE_COL = 'rating'  # или 'relevance', 'clicks', etc.\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"\\nУникальных queries (users): {train_df[QUERY_COL].nunique()}\")\n",
    "print(f\"Уникальных items: {train_df[ITEM_COL].nunique()}\")\n",
    "print(f\"\\nПример данных:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e71ae",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering для ранкинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranking_features(df, query_col, item_col, relevance_col):\n",
    "    \"\"\"\n",
    "    Создание признаков для ранкинга\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Query-level признаки\n",
    "    # Количество айтемов у query\n",
    "    query_item_count = df.groupby(query_col).size().to_dict()\n",
    "    df['query_item_count'] = df[query_col].map(query_item_count)\n",
    "    \n",
    "    # Средний relevance для query\n",
    "    query_avg_relevance = df.groupby(query_col)[relevance_col].mean().to_dict()\n",
    "    df['query_avg_relevance'] = df[query_col].map(query_avg_relevance)\n",
    "    \n",
    "    # Максимальный relevance для query\n",
    "    query_max_relevance = df.groupby(query_col)[relevance_col].max().to_dict()\n",
    "    df['query_max_relevance'] = df[query_col].map(query_max_relevance)\n",
    "    \n",
    "    # 2. Item-level признаки\n",
    "    # Популярность айтема (сколько раз встречается)\n",
    "    item_popularity = df.groupby(item_col).size().to_dict()\n",
    "    df['item_popularity'] = df[item_col].map(item_popularity)\n",
    "    \n",
    "    # Средний relevance для айтема\n",
    "    item_avg_relevance = df.groupby(item_col)[relevance_col].mean().to_dict()\n",
    "    df['item_avg_relevance'] = df[item_col].map(item_avg_relevance)\n",
    "    \n",
    "    # Количество уникальных queries для айтема\n",
    "    item_query_count = df.groupby(item_col)[query_col].nunique().to_dict()\n",
    "    df['item_query_count'] = df[item_col].map(item_query_count)\n",
    "    \n",
    "    # 3. Query-Item interaction признаки\n",
    "    # Относительный relevance (relevance / max_relevance в группе)\n",
    "    df['relative_relevance'] = df[relevance_col] / (df['query_max_relevance'] + 1e-5)\n",
    "    \n",
    "    # Z-score relevance внутри query\n",
    "    query_std_relevance = df.groupby(query_col)[relevance_col].std().to_dict()\n",
    "    df['query_std_relevance'] = df[query_col].map(query_std_relevance).fillna(0)\n",
    "    df['relevance_zscore'] = (\n",
    "        (df[relevance_col] - df['query_avg_relevance']) / (df['query_std_relevance'] + 1e-5)\n",
    "    )\n",
    "    \n",
    "    # 4. Ranking-специфичные признаки\n",
    "    # Позиция айтема в отсортированном списке query (по relevance)\n",
    "    df['rank_position'] = df.groupby(query_col)[relevance_col].rank(ascending=False, method='first')\n",
    "    \n",
    "    # Нормализованная позиция (0-1)\n",
    "    df['rank_position_norm'] = df['rank_position'] / df['query_item_count']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Применение\n",
    "print(\"Генерация ranking признаков...\")\n",
    "train_df = create_ranking_features(train_df, QUERY_COL, ITEM_COL, RELEVANCE_COL)\n",
    "\n",
    "print(f\"✓ Признаки созданы!\")\n",
    "print(f\"Количество признаков: {len(train_df.columns)}\")\n",
    "print(f\"\\nНовые признаки:\")\n",
    "new_features = [col for col in train_df.columns if col not in [QUERY_COL, ITEM_COL, RELEVANCE_COL]]\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c35dbe9",
   "metadata": {},
   "source": [
    "## 3. Encoding categorical признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00895c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding для query и item IDs\n",
    "query_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Fit на всех данных\n",
    "all_queries = pd.concat([train_df[QUERY_COL], test_df[QUERY_COL]]).unique()\n",
    "all_items = pd.concat([train_df[ITEM_COL], test_df[ITEM_COL]]).unique()\n",
    "\n",
    "query_encoder.fit(all_queries)\n",
    "item_encoder.fit(all_items)\n",
    "\n",
    "train_df['query_encoded'] = query_encoder.transform(train_df[QUERY_COL])\n",
    "train_df['item_encoded'] = item_encoder.transform(train_df[ITEM_COL])\n",
    "\n",
    "print(\"✓ Encoding завершен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e761660",
   "metadata": {},
   "source": [
    "## 4. Подготовка данных для CatBoost Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор признаков\n",
    "feature_cols = [\n",
    "    'query_encoded', 'item_encoded',\n",
    "    'query_item_count', 'query_avg_relevance', 'query_max_relevance',\n",
    "    'item_popularity', 'item_avg_relevance', 'item_query_count',\n",
    "    'relative_relevance', 'relevance_zscore',\n",
    "    'rank_position', 'rank_position_norm'\n",
    "]\n",
    "\n",
    "# Добавляем все остальные числовые признаки если есть\n",
    "other_numeric = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in other_numeric:\n",
    "    if col not in feature_cols and col not in [QUERY_COL, ITEM_COL, RELEVANCE_COL]:\n",
    "        feature_cols.append(col)\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df[RELEVANCE_COL]\n",
    "groups = train_df['query_encoded']  # Group ID для ранкинга\n",
    "\n",
    "print(f\"Признаков для обучения: {len(feature_cols)}\")\n",
    "print(f\"Групп (queries): {groups.nunique()}\")\n",
    "print(f\"Samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4ebae0",
   "metadata": {},
   "source": [
    "## 5. Train/Val split с сохранением групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем по query groups, а не по отдельным samples\n",
    "unique_queries = train_df['query_encoded'].unique()\n",
    "train_queries, val_queries = train_test_split(\n",
    "    unique_queries, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_mask = train_df['query_encoded'].isin(train_queries)\n",
    "val_mask = train_df['query_encoded'].isin(val_queries)\n",
    "\n",
    "X_train = X[train_mask]\n",
    "y_train = y[train_mask]\n",
    "groups_train = groups[train_mask]\n",
    "\n",
    "X_val = X[val_mask]\n",
    "y_val = y[val_mask]\n",
    "groups_val = groups[val_mask]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples, {groups_train.nunique()} queries\")\n",
    "print(f\"Val: {len(X_val)} samples, {groups_val.nunique()} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d72eb7",
   "metadata": {},
   "source": [
    "## 6. Создание CatBoost Pool с группами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2088135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Pool для ranking\n",
    "train_pool = cb.Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=groups_train  # Важно для ranking!\n",
    ")\n",
    "\n",
    "val_pool = cb.Pool(\n",
    "    data=X_val,\n",
    "    label=y_val,\n",
    "    group_id=groups_val\n",
    ")\n",
    "\n",
    "print(\"✓ CatBoost Pools созданы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae3880",
   "metadata": {},
   "source": [
    "## 7. Обучение CatBoost Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb862e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для ranking\n",
    "ranker_params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'YetiRank',  # Можно также: 'YetiRankPairwise', 'PairLogitPairwise'\n",
    "    'eval_metric': 'NDCG',  # Можно также: 'PFound', 'MAP'\n",
    "    'random_seed': 42,\n",
    "    'verbose': 200,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'task_type': 'GPU' if cb.cuda.is_cuda_available() else 'CPU'\n",
    "}\n",
    "\n",
    "print(f\"Обучение CatBoost Ranker с {ranker_params['loss_function']}...\\n\")\n",
    "\n",
    "ranker = cb.CatBoost(ranker_params)\n",
    "ranker.fit(\n",
    "    train_pool,\n",
    "    eval_set=val_pool,\n",
    "    use_best_model=True,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "print(\"\\n✓ CatBoost Ranker обучен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1020d46b",
   "metadata": {},
   "source": [
    "## 8. Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56419e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания на валидации\n",
    "val_predictions = ranker.predict(val_pool)\n",
    "\n",
    "# Вычисление NDCG для каждой query\n",
    "def compute_ndcg_per_query(y_true, y_pred, groups, k=10):\n",
    "    \"\"\"\n",
    "    Вычисление NDCG@k для каждой группы\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for group_id in np.unique(groups):\n",
    "        mask = groups == group_id\n",
    "        group_true = y_true[mask]\n",
    "        group_pred = y_pred[mask]\n",
    "        \n",
    "        if len(group_true) > 1:\n",
    "            # NDCG требует 2D массивы\n",
    "            ndcg = ndcg_score([group_true], [group_pred], k=min(k, len(group_true)))\n",
    "            ndcg_scores.append(ndcg)\n",
    "    \n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "# NDCG@10\n",
    "ndcg_10 = compute_ndcg_per_query(\n",
    "    y_val.values, \n",
    "    val_predictions, \n",
    "    groups_val.values, \n",
    "    k=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ВАЛИДАЦИИ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"NDCG@10: {ndcg_10:.4f}\")\n",
    "print(f\"Best iteration: {ranker.get_best_iteration()}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674e732",
   "metadata": {},
   "source": [
    "## 9. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': ranker.get_feature_importance()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-15 важных признаков:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance.head(15)['feature'], feature_importance.head(15)['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Топ-15 важных признаков для ранкинга')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b39899",
   "metadata": {},
   "source": [
    "## 10. Анализ топ предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame с предсказаниями\n",
    "val_results = train_df[val_mask].copy()\n",
    "val_results['predicted_score'] = val_predictions\n",
    "\n",
    "# Для одного query смотрим топ-10 предсказанных айтемов\n",
    "sample_query = val_results['query_encoded'].iloc[0]\n",
    "query_results = val_results[val_results['query_encoded'] == sample_query].sort_values(\n",
    "    'predicted_score', ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(f\"\\nТоп-10 предсказаний для query {sample_query}:\")\n",
    "print(query_results[[ITEM_COL, RELEVANCE_COL, 'predicted_score', 'rank_position']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbc3fb",
   "metadata": {},
   "source": [
    "## 11. Подготовка test данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced95838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применяем ту же генерацию признаков\n",
    "# Но используем статистику из train!\n",
    "\n",
    "def create_test_features(test_df, train_df, query_col, item_col):\n",
    "    \"\"\"\n",
    "    Создание признаков для test используя статистику из train\n",
    "    \"\"\"\n",
    "    test = test_df.copy()\n",
    "    \n",
    "    # Строим маппинги из train\n",
    "    item_popularity = train_df.groupby(item_col).size().to_dict()\n",
    "    item_avg_relevance = train_df.groupby(item_col)[RELEVANCE_COL].mean().to_dict()\n",
    "    item_query_count = train_df.groupby(item_col)[query_col].nunique().to_dict()\n",
    "    \n",
    "    # Применяем к test\n",
    "    test['item_popularity'] = test[item_col].map(item_popularity).fillna(0)\n",
    "    test['item_avg_relevance'] = test[item_col].map(item_avg_relevance).fillna(\n",
    "        train_df[RELEVANCE_COL].mean()\n",
    "    )\n",
    "    test['item_query_count'] = test[item_col].map(item_query_count).fillna(0)\n",
    "    \n",
    "    # Query-level признаки (считаем по test, т.к. это айтемы для одного запроса)\n",
    "    test['query_item_count'] = test.groupby(query_col)[item_col].transform('count')\n",
    "    \n",
    "    # Encoding\n",
    "    test['query_encoded'] = query_encoder.transform(test[query_col])\n",
    "    test['item_encoded'] = item_encoder.transform(test[item_col])\n",
    "    \n",
    "    # Заполняем остальные признаки нулями или средними\n",
    "    for col in feature_cols:\n",
    "        if col not in test.columns:\n",
    "            test[col] = 0\n",
    "    \n",
    "    return test\n",
    "\n",
    "print(\"Подготовка test данных...\")\n",
    "test_df = create_test_features(test_df, train_df, QUERY_COL, ITEM_COL)\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "groups_test = test_df['query_encoded']\n",
    "\n",
    "test_pool = cb.Pool(\n",
    "    data=X_test,\n",
    "    group_id=groups_test\n",
    ")\n",
    "\n",
    "print(f\"✓ Test данные готовы: {len(X_test)} samples, {groups_test.nunique()} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2415c",
   "metadata": {},
   "source": [
    "## 12. Предсказания на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9927bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация предсказаний\n",
    "test_predictions = ranker.predict(test_pool)\n",
    "test_df['predicted_score'] = test_predictions\n",
    "\n",
    "print(\"✓ Предсказания готовы!\")\n",
    "print(f\"\\nСтатистика предсказанных scores:\")\n",
    "print(test_df['predicted_score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0434b",
   "metadata": {},
   "source": [
    "## 13. Генерация топ-N рекомендаций для каждого query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ffb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для каждого query берем топ-10 айтемов\n",
    "def get_top_n_per_query(df, query_col, item_col, score_col, n=10):\n",
    "    \"\"\"\n",
    "    Получить топ-N айтемов для каждого query\n",
    "    \"\"\"\n",
    "    top_n = (\n",
    "        df.sort_values([query_col, score_col], ascending=[True, False])\n",
    "        .groupby(query_col)\n",
    "        .head(n)\n",
    "    )\n",
    "    \n",
    "    return top_n\n",
    "\n",
    "top_recommendations = get_top_n_per_query(\n",
    "    test_df, QUERY_COL, ITEM_COL, 'predicted_score', n=10\n",
    ")\n",
    "\n",
    "print(f\"\\nТоп-10 рекомендаций для {top_recommendations[QUERY_COL].nunique()} queries\")\n",
    "print(f\"Всего рекомендаций: {len(top_recommendations)}\")\n",
    "\n",
    "# Пример для одного query\n",
    "sample_query_id = test_df[QUERY_COL].iloc[0]\n",
    "sample_recs = top_recommendations[top_recommendations[QUERY_COL] == sample_query_id]\n",
    "print(f\"\\nПример рекомендаций для query {sample_query_id}:\")\n",
    "print(sample_recs[[ITEM_COL, 'predicted_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265ca42",
   "metadata": {},
   "source": [
    "## 14. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca709cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вариант 1: Все пары с predicted scores\n",
    "submission_full = pd.DataFrame({\n",
    "    'user_id': test_df[QUERY_COL],\n",
    "    'item_id': test_df[ITEM_COL],\n",
    "    'predicted_score': test_df['predicted_score']\n",
    "})\n",
    "\n",
    "submission_full.to_csv('catboost_ranker_full_submission.csv', index=False)\n",
    "print(\"✓ Full submission сохранен!\")\n",
    "\n",
    "# Вариант 2: Только топ-10 для каждого query\n",
    "submission_top10 = pd.DataFrame({\n",
    "    'user_id': top_recommendations[QUERY_COL],\n",
    "    'item_id': top_recommendations[ITEM_COL],\n",
    "    'predicted_score': top_recommendations['predicted_score']\n",
    "})\n",
    "\n",
    "submission_top10.to_csv('catboost_ranker_top10_submission.csv', index=False)\n",
    "print(\"✓ Top-10 submission сохранен!\")\n",
    "\n",
    "print(\"\\nПример submission:\")\n",
    "print(submission_top10.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f0bff",
   "metadata": {},
   "source": [
    "## 15. Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ranker.save_model('catboost_ranker_model.cbm')\n",
    "print(\"✓ Модель сохранена!\")\n",
    "\n",
    "# Загрузка модели\n",
    "# loaded_ranker = cb.CatBoost()\n",
    "# loaded_ranker.load_model('catboost_ranker_model.cbm')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
