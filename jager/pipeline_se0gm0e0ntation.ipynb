{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc21615",
   "metadata": {},
   "source": [
    "# Segmentation Pipeline - Сегментация изображений\n",
    "\n",
    "Пайплайны для:\n",
    "- Семантическая сегментация (U-Net, DeepLab)\n",
    "- Instance сегментация (Mask R-CNN)\n",
    "- Panoptic сегментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision segmentation-models-pytorch albumentations opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95132c7d",
   "metadata": {},
   "source": [
    "## 1. Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ВАШИ ДАННЫЕ ===\n",
    "IMAGES_DIR = './images'\n",
    "MASKS_DIR = './masks'\n",
    "TRAIN_CSV = 'train.csv'  # image_path, mask_path\n",
    "TEST_CSV = 'test.csv'\n",
    "\n",
    "# === НАСТРОЙКИ ===\n",
    "ENCODER = 'resnet50'  # 'efficientnet-b0', 'mobilenet_v2'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "NUM_CLASSES = 1  # Бинарная сегментация (фон/объект)\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318087e3",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b454a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, masks_dir=None, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.masks_dir = Path(masks_dir) if masks_dir else None\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.images_dir / row['image_path']\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.is_test:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        else:\n",
    "            mask_path = self.masks_dir / row['mask_path']\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "            mask = (mask > 0).astype(np.float32)\n",
    "            \n",
    "            if self.transform:\n",
    "                transformed = self.transform(image=image, mask=mask)\n",
    "                image = transformed['image']\n",
    "                mask = transformed['mask']\n",
    "            \n",
    "            return image, mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "train_dataset = SegmentationDataset(train_df, IMAGES_DIR, MASKS_DIR, train_transform)\n",
    "test_dataset = SegmentationDataset(test_df, IMAGES_DIR, transform=test_transform, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2bfbb5",
   "metadata": {},
   "source": [
    "## 3. Модель U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67345d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net с pre-trained энкодером\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None,  # Sigmoid добавим в loss\n",
    ").to(device)\n",
    "\n",
    "# Альтернативы:\n",
    "# model = smp.FPN(...)       # Feature Pyramid Network\n",
    "# model = smp.DeepLabV3Plus(...) # DeepLab\n",
    "# model = smp.PSPNet(...)    # PSPNet\n",
    "\n",
    "# Loss и optimizer\n",
    "loss_fn = smp.losses.DiceLoss(mode='binary')\n",
    "# loss_fn = smp.losses.JaccardLoss(mode='binary')\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(\"✓ Модель создана!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cf0f2",
   "metadata": {},
   "source": [
    "## 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942bb2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'segmentation_model.pth')\n",
    "print(\"✓ Модель обучена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4db6c",
   "metadata": {},
   "source": [
    "## 5. Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d47713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        masks = torch.sigmoid(outputs) > 0.5\n",
    "        predictions.extend(masks.cpu().numpy())\n",
    "\n",
    "# Сохранение масок\n",
    "# for i, mask in enumerate(predictions):\n",
    "#     cv2.imwrite(f'predictions/mask_{i}.png', (mask[0] * 255).astype(np.uint8))\n",
    "\n",
    "print(\"✓ Предсказания готовы!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
