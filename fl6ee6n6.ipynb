{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afffd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_data = pd.read_parquet('train_data.pq')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "MAX_DATE = 46\n",
    "VAL_START = 40\n",
    "TEST_START = 47\n",
    "\n",
    "user_ids_test = set(sample_sub['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57eae52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(train, user_ids, train_days=17, recent_days=3, personal_window_days=10, top_k_candidates=100):\n",
    "    print(\"generate_candidates\")\n",
    "    max_date = train['date'].max()\n",
    "    train_period = train[train['date'] >= (max_date - train_days + 1)].copy()\n",
    "    recent_cutoff = max_date - recent_days + 1\n",
    "    personal_cutoff = max_date - personal_window_days + 1\n",
    "\n",
    "    recent_data = train_period[train_period['date'] >= recent_cutoff]\n",
    "    personal_data = train_period[train_period['date'] >= personal_cutoff]\n",
    "\n",
    "    global_top = train_period['item_id'].value_counts().head(top_k_candidates).index.values\n",
    "    recent_top = recent_data['item_id'].value_counts().head(top_k_candidates).index.values\n",
    "\n",
    "    user_recent_items = (\n",
    "        recent_data\n",
    "        .sort_values(['user_id', 'date'])\n",
    "        .groupby('user_id')['item_id']\n",
    "        .agg(lambda x: x.drop_duplicates().tail(5)[::-1].tolist())\n",
    "    )\n",
    "    user_personal_top = (\n",
    "        personal_data\n",
    "        .groupby('user_id')['item_id']\n",
    "        .value_counts()\n",
    "        .groupby('user_id')\n",
    "        .head(10)\n",
    "        .reset_index(name='count')\n",
    "        .groupby('user_id')['item_id']\n",
    "        .apply(list)\n",
    "    )\n",
    "\n",
    "    candidates = []\n",
    "    for user_id in tqdm(user_ids, desc=\"Генерация кандидатов\"):\n",
    "        seen = set()\n",
    "        cand = []\n",
    "\n",
    "        if user_id in user_recent_items.index:\n",
    "            for item in user_recent_items[user_id]:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'recent'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        if user_id in user_personal_top.index:\n",
    "            for item in user_personal_top[user_id]:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'personal'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        for item in recent_top:\n",
    "            if len(cand) >= top_k_candidates: break\n",
    "            if item not in seen:\n",
    "                cand.append((user_id, item, 'trend'))\n",
    "                seen.add(item)\n",
    "\n",
    "        for item in global_top:\n",
    "            if len(cand) >= top_k_candidates: break\n",
    "            if item not in seen:\n",
    "                cand.append((user_id, item, 'global'))\n",
    "                seen.add(item)\n",
    "\n",
    "        while len(cand) < top_k_candidates and len(seen) < len(global_top):\n",
    "            for item in global_top:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'fallback'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        candidates.extend(cand[:top_k_candidates])\n",
    "\n",
    "    return pd.DataFrame(candidates, columns=['user_id', 'item_id', 'candidate_source'])\n",
    "\n",
    "\n",
    "def create_features(df, full_train, max_date_for_features):\n",
    "    print(\"create_features\")\n",
    "    user_stats = full_train.groupby('user_id')['date'].agg(\n",
    "        user_total_clicks='count',\n",
    "        user_last_click_day='max',\n",
    "        user_first_click_day='min'\n",
    "    ).reset_index()\n",
    "    user_stats['user_active_days'] = user_stats['user_last_click_day'] - user_stats['user_first_click_day'] + 1\n",
    "    user_stats['user_recency'] = max_date_for_features - user_stats['user_last_click_day']\n",
    "\n",
    "    item_stats = full_train.groupby('item_id')['date'].agg(\n",
    "        item_total_clicks='count',\n",
    "        item_last_click_day='max',\n",
    "        item_first_click_day='min'\n",
    "    ).reset_index()\n",
    "    item_stats['item_recency'] = max_date_for_features - item_stats['item_last_click_day']\n",
    "\n",
    "    for days in [1, 3, 7, 14]:\n",
    "        cutoff = max_date_for_features - days + 1\n",
    "        pop = full_train[full_train['date'] >= cutoff].groupby('item_id').size().rename(f'item_pop_{days}d')\n",
    "        item_stats = item_stats.merge(pop, on='item_id', how='left')\n",
    "\n",
    "    user_item_stats = full_train.groupby(['user_id', 'item_id'])['date'].agg(\n",
    "        ui_clicks='count',\n",
    "        ui_last_click='max',\n",
    "        ui_first_click='min'\n",
    "    ).reset_index()\n",
    "    user_item_stats['ui_recency'] = max_date_for_features - user_item_stats['ui_last_click']\n",
    "    user_item_stats['ui_frequency'] = user_item_stats['ui_clicks'] / (user_item_stats['ui_last_click'] - user_item_stats['ui_first_click'] + 1)\n",
    "\n",
    "    df = df.merge(user_stats, on='user_id', how='left')\n",
    "    df = df.merge(item_stats, on='item_id', how='left')\n",
    "    df = df.merge(user_item_stats, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    df['ui_clicks'] = df['ui_clicks'].fillna(0)\n",
    "    df['ui_recency'] = df['ui_recency'].fillna(999)\n",
    "    df['ui_frequency'] = df['ui_frequency'].fillna(0)\n",
    "    for col in tqdm(df.columns):\n",
    "        if 'pop_' in col:\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6ea75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация кандидатов: 100%|██████████| 592309/592309 [00:09<00:00, 61854.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 37.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_hist = train_data[train_data['date'] < VAL_START].copy()\n",
    "val_true = train_data[train_data['date'] >= VAL_START].copy()\n",
    "\n",
    "user_ids_val = sorted(val_true['user_id'].unique())\n",
    "\n",
    "candidates_val = generate_candidates(\n",
    "    train=train_hist,\n",
    "    user_ids=user_ids_val,\n",
    "    train_days=17,\n",
    "    recent_days=3,\n",
    "    personal_window_days=10,\n",
    "    top_k_candidates=50\n",
    ")\n",
    "\n",
    "candidates_val = create_features(candidates_val, train_hist, max_date_for_features=VAL_START - 1)\n",
    "\n",
    "val_pairs = val_true[['user_id', 'item_id']].drop_duplicates()\n",
    "val_pairs['target'] = 1\n",
    "candidates_val = candidates_val.merge(val_pairs, on=['user_id', 'item_id'], how='left')\n",
    "candidates_val['target'] = candidates_val['target'].fillna(0).astype(int)\n",
    "\n",
    "feature_cols = [col for col in candidates_val.columns if col not in ['user_id', 'item_id', 'candidate_source', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab50a818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttotal: 1.48s\tremaining: 4m 54s\n",
      "10:\ttotal: 15.2s\tremaining: 4m 20s\n",
      "20:\ttotal: 29.3s\tremaining: 4m 9s\n",
      "30:\ttotal: 43s\tremaining: 3m 54s\n",
      "40:\ttotal: 57.8s\tremaining: 3m 44s\n",
      "50:\ttotal: 1m 11s\tremaining: 3m 29s\n",
      "60:\ttotal: 1m 25s\tremaining: 3m 14s\n",
      "70:\ttotal: 1m 40s\tremaining: 3m 1s\n",
      "80:\ttotal: 1m 54s\tremaining: 2m 48s\n",
      "90:\ttotal: 2m 9s\tremaining: 2m 34s\n",
      "100:\ttotal: 2m 26s\tremaining: 2m 23s\n",
      "110:\ttotal: 2m 41s\tremaining: 2m 9s\n",
      "120:\ttotal: 2m 56s\tremaining: 1m 54s\n",
      "130:\ttotal: 3m 10s\tremaining: 1m 40s\n",
      "140:\ttotal: 3m 25s\tremaining: 1m 26s\n",
      "150:\ttotal: 3m 40s\tremaining: 1m 11s\n",
      "160:\ttotal: 3m 54s\tremaining: 56.9s\n",
      "170:\ttotal: 4m 10s\tremaining: 42.5s\n",
      "180:\ttotal: 4m 28s\tremaining: 28.1s\n",
      "190:\ttotal: 4m 43s\tremaining: 13.4s\n",
      "199:\ttotal: 5m 1s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x25e5fb14590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    task_type='CPU',\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "model_val.fit(candidates_val[feature_cols], candidates_val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac90863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_candidates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация кандидатов: 100%|██████████| 293230/293230 [00:05<00:00, 55054.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 63.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "user_ids_test = sample_sub['user_id'].unique()\n",
    "\n",
    "candidates_test = generate_candidates(\n",
    "    train=train_data,\n",
    "    user_ids=user_ids_test,\n",
    "    train_days=17,\n",
    "    recent_days=3,\n",
    "    personal_window_days=10,\n",
    "    top_k_candidates=50\n",
    ")\n",
    "\n",
    "candidates_test = create_features(candidates_test, train_data, max_date_for_features=MAX_DATE)\n",
    "print(\"---\")\n",
    "candidates_test['pred'] = model_val.predict_proba(candidates_test[feature_cols])[:, 1]\n",
    "\n",
    "submission = (\n",
    "    candidates_test\n",
    "    .sort_values(['user_id', 'pred'], ascending=[True, False])\n",
    "    .groupby('user_id')\n",
    "    .head(20)\n",
    "    [['user_id', 'item_id']]\n",
    ")\n",
    "\n",
    "global_top_20_test = train_data['item_id'].value_counts().head(20).index.tolist()\n",
    "all_users_test = set(user_ids_test)\n",
    "pred_users_test = set(submission['user_id'])\n",
    "missing_users_test = all_users_test - pred_users_test\n",
    "\n",
    "if missing_users_test:\n",
    "    extra = []\n",
    "    for uid in tqdm(missing_users_test):\n",
    "        for item in global_top_20_test[:20]:\n",
    "            extra.append({'user_id': uid, 'item_id': item})\n",
    "    extra_df = pd.DataFrame(extra)\n",
    "    submission = pd.concat([submission, extra_df], ignore_index=True)\n",
    "\n",
    "submission = submission.groupby('user_id').head(20).reset_index(drop=True)\n",
    "\n",
    "submission.to_csv('i_love_catboost_17.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
