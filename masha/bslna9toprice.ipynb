{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Всероссийская олимпиада по искусственному интеллекту 2025"
      ],
      "metadata": {
        "id": "oekPRLGIWhJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Учебный бейзлайн-ноутбук № 2"
      ],
      "metadata": {
        "id": "3MVFDP630dbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Введение"
      ],
      "metadata": {
        "id": "q9qohjkm4ZkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приветствуем вас во втором ноутбуке нашей учебной серии!\n",
        "\n",
        "В первой части мы уже успели разобрать основы машинного обучения: типы задач, метрики, сплиты, базовые инструменты - теперь здесь мы сосредоточимся на задаче **компьютерного зрения** (Computer Vision, CV).\n",
        "\n",
        "Наша цель - научить модель смотреть на фотографии и делать на их основе выводы. Вместо того чтобы анализировать описания, мы будем анализировать пиксели. По условием задания у нас - `регрессии`, предсказываем числовое значение и строим модель, которая оценивает стоимость автомобиля по его фотографиям.\n",
        "\n",
        "**План нашей работы**\n",
        "Чтобы вам было проще ориентироваться, вот структура нашего ноутбука:\n",
        "\n",
        "1. **Цифровое изображение и его преобразования.** Разберемся, как компьютер \"видит\" картинку (пиксели, каналы, тензоры). Поговорим о двух ключевых типах преобразований: `предобработке` (обязательные шаги, как изменение размера) и `аугментациях` (случайные изменения для усиления модели).\n",
        "\n",
        "2. **Модели для компьютерного зрения.** Познакомимся с главной идеей современного CV: использованием предобученных моделей (например, `ResNet`). Узнаем, как взять мощную нейросеть, обученную на миллионах изображений, и быстро настроить ее под нашу конкретную задачу.\n",
        "\n",
        "3. **Подходы, как подружить картинки и таблицы.** В нашей задаче есть не только фото, но и много полезной информации в таблице (пробег, тип кузова, комплектация). Мы обсудим основные стратегии \"фьюжна\" (`fusion`) - объединения данных из разных источников, чтобы получить максимально точное предсказание.\n",
        "\n",
        "4. **Бейзлайн решения.** Соберем все полученные знания вместе и напишем базовое, но полноценное решение. Для начала оно будет предсказывать цену только по фотографиям, чтобы отточить навыки работы с CV-моделями.\n",
        "\n",
        "5. **Заключение.** Подведем итоги и наметим четкий план по улучшению нашего бейзлайна. Главным шагом, конечно же, будет добавление табличных данных к нашей модели.\n",
        "\n",
        "Отлично, тогда приступим - и первым делом обсудим цифровые изображения.\n"
      ],
      "metadata": {
        "id": "FFd0jN8e5BT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Цифровое изображение и его преобразования"
      ],
      "metadata": {
        "id": "jpADEJtnBrxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Когда мы говорим \"картинка для нейросети\", речь просто о таблице чисел. Представьте тетрадный лист в клетку: каждая клетка - `пиксель`. У цветной фотографии у каждого пикселя три базовых цвета: **R** (красный), **G** (зелёный), **B** (синий). Поэтому изображение - это тензор формата **H×W×C** (высота × ширина × каналы).\n",
        "\n",
        "Компьютер хранит цвета как числа от 0 до 255 (тип `uint8`). Перед подачей в модель мы обычно переводим их в вещественные числа (`float32`) и нормируем.\n",
        "\n",
        "В `PyTorch` модели ждут порядок каналов **C×H×W**. А в нашем датасете бывает по 1–4 фото на машину, поэтому в памяти это выглядит так:\n",
        "\n",
        "* одно фото: `3 × 192 × 192`\n",
        "* несколько фото на один объект: `N × 3 × 192 × 192`\n",
        "* батч из `B` объектов: `B × N × 3 × 192 × 192`\n",
        "\n",
        "> Забежим сразу вперед. В бейзлайне мы сделаем просто: прогоняем каждое фото через сеть и усредняем признаки (или предсказания) по фото - такой \"[пулинг](https://deepmachinelearning.ru/docs/Neural-networks/ConvPool-1D/Pooling-1D) по картинкам\" устойчив и быстрый."
      ],
      "metadata": {
        "id": "dKyecYK67PY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Предобработка vs Аугментации**\n",
        "\n",
        "Фотографии из нашего датасета очень разные: одни квадратные, другие прямоугольные; одни большие, другие маленькие. Нейросеть, как заводской конвейер, может работать только с деталями одинакового размера. Поэтому, прежде чем подавать картинки в модель, их нужно привести к единому стандарту. Этот процесс делится на два типа преобразований.\n",
        "\n",
        "> Но перед тем, как мы их рассмотрим, сразу отметим, шаги предобработки зависят от модели и метода, с которыми вы будете работать. Мы возьмем предобученный `ResNet18` (ImageNet), сверточную сеть, отрежем ей \"голову\" (ууу, кровожадные), добавим линейную голову на 1 число и научим предсказывать логарифм цены.\n",
        "\n",
        "**1) Предобработка (Preprocessing)**\n",
        "\n",
        "Это детерминированные (то есть одинаковые для всех) шаги, которые мы обязаны сделать, чтобы модель в принципе смогла работать с данными.\n",
        "\n",
        "* **Размеры и пропорции.** Модели ждут на вход тензор фиксированного размера (например, `224×224`). Чтобы привести к нему разные картинки, есть несколько путей:\n",
        "    * **Растянуть/сжать.** Самый простой, но плохой способ. Он искажает пропорции, и квадратный внедорожник может превратиться в вытянутый лимузин, что запутает модель.\n",
        "    * **Обрезать края (`CenterCrop`).** Можно привести картинку к нужному размеру по меньшей стороне, а лишнее по большей - обрезать. Метод хороший, но есть риск отрезать важную деталь, например, бампер или спойлер.\n",
        "    * **Сохранить пропорции и дополнить полями (`PadIfNeeded`).** Лучший компромисс. Мы уменьшаем картинку по длинной стороне до нужного размера, а пустое пространство по короткой стороне заполняем \"полями\" (обычно черными). Так мы сохраняем всю информацию и не искажаем объект. Именно этот метод используется в нашем бейзлайне.\n",
        "\n",
        "* **Нормализация.** Значения пикселей от 0 до 255 - слишком большой разброс для нейросети. Мы приводим их к стандартному, маленькому диапазону. Для моделей, предобученных на гигантском датасете **ImageNet** (а это почти все современные модели), принято использовать конкретные \"волшебные\" числа:\n",
        "\n",
        "  * mean = (0.485, 0.456, 0.406)\n",
        "  * std  = (0.229, 0.224, 0.225)\n",
        "  \n",
        "  Это стабилизирует обучение, так как \"распределение\" наших данных становится похожим на то, на чём сеть училась изначально.\n",
        "\n",
        "**2) Аугментации (Augmentations)**\n",
        "\n",
        "Это случайные изменения, которые применяются *только к обучающим данным*. Их цель - сделать модель умнее, сильнее и устойчивее к разнообразию реального мира.\n",
        "\n",
        "Аугментации можно разделить на несколько семейств:\n",
        "\n",
        "* **Геометрические.** Имитируют съемку с разных ракурсов. Это отражения (`flip`), повороты (`rotate`), сдвиги и масштабирование (`shift/scale`, `affine`, `perspective`).\n",
        "* **Фотометрические (цветовые).** Имитируют разные условия освещения и настройки камеры. Это изменение яркости/контраста, цветового тона, добавление шума или размытия (`brightness/contrast`, `hue/saturation`, `blur`, `noise`, `JPEG-компрессия`).\n",
        "* **Маскирующие.** Имитируют частичное перекрытие объекта. Самый известный пример - `Cutout`, который случайно \"вырезает\" и закрашивает черным один или несколько квадратов на картинке. Это заставляет модель обращать внимание не на одну деталь, а на весь объект целиком.\n",
        "\n",
        "Есть и более продвинутые техники вроде **MixUp/CutMix**, где смешиваются целые картинки и их таргеты, но в бейзлайне мы их использовать не будем.\n",
        "\n",
        "```\n",
        "Как это реализовано у нас?\n",
        "\n",
        "Мы используем Albumentations: это быстрые и удобные трансформации на базе OpenCV.\n",
        "В коде вы уже видели два пайплайна:\n",
        "\n",
        "`train_tfms`: `LongestMaxSize → PadIfNeeded → Flip/Color/Rotate → Normalize → ToTensorV2`\n",
        "`valid_tfms`: `LongestMaxSize → PadIfNeeded → Normalize → ToTensorV2`\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "AHNMQiPg_iqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Вы резонно спросите, а если картинок несколько?*\n",
        "\n",
        "В нашей задаче на один автомобиль может быть до 4 фотографий. Есть несколько вариантов, как использовать их все:\n",
        "\n",
        "* **Пулинг по эмбеддингам (`Mid-level fusion`).** Пропустить каждую картинку через нейросеть, получить для каждой вектор признаков (эмбеддинг), а затем эти векторы \"схлопнуть\" в один - например, усреднить (`mean-pooling`) или взять максимум по каждому измерению (`max-pooling`).\n",
        "* **Пулинг по предсказаниям (`Late fusion`).** Получить предсказание цены для каждой картинки отдельно, а затем усреднить итоговые цены.\n",
        "\n",
        "В нашем бейзлайне для простоты мы будем использовать только одно фото на автомобиль, но задействовать все - очевидный шаг к улучшению модели.\n",
        "\n",
        "**И опять о них - о ресурсах**\n",
        "\n",
        "Напоследок, пара практических советов:\n",
        "* **Баланс.** Чем больше разрешение картинки (`IMG_SIZE`) и чем больше картинок в батче (`BATCH_SIZE`), тем больше видеопамяти (VRAM) на GPU вам потребуется. Если вы ловите ошибку `CUDA Out of Memory` (OOM), первое, что нужно сделать - уменьшить размер батча.\n",
        "* **Ускорение.** На современных видеокартах можно использовать AMP (Automatic Mixed Precision), мы уже говорили о нем в прошлом ноутбуке. Это специальный режим вычислений в \"полуточной\" точности (`fp16`), который значительно ускоряет обучение и снижает потребление памяти почти без потери качества. В нашем коде он включается флагом `fp16=True`.\n",
        "\n",
        "С обработкой разобрались, давайте посмотрим на модельки и подходы, которые мы можем использовать в задачах CV."
      ],
      "metadata": {
        "id": "sWcMeBcC-WN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модели для компьютерного зрения"
      ],
      "metadata": {
        "id": "7nNQ3c9pWFDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, у нас есть картинки, представленные в виде чисел (тензоров). Казалось бы, можно создать нейросеть с нуля, которая будет смотреть на эти числа и предсказывать цену. Но есть одна проблема: это невероятно *сложно*, *долго* и *дорого*.\n",
        "\n",
        "Так и не надо :)\n",
        "\n",
        "В современном CV доминирует идея **трансферного обучения** (Transfer Learning).\n",
        "\n",
        "> Суть проста. Мы берем модель, которую уже обучили на гигантском датасете (обычно это `ImageNet` с миллионами картинок и тысячей классов), и адаптируем ее под нашу узкую задачу. Мы не учим модель видеть с нуля, а как бы говорим уже опытному эксперту по картинкам: \"Смотри, ты уже умеешь отличать кошек от собак и самолетов. Теперь используй свои знания, чтобы научиться отличать дорогие машины от дешевых\".\n",
        "\n",
        "Как мы это сделаем в бейзлайне?\n",
        "\n",
        "1. Возьмем готовый *бэкбон* (\"спину\") - сеть, которая превращает картинку в вектор признаков (эмбеддинг);\n",
        "\n",
        "2. Добавим \"голову\" под нашу задачу (у нас - регрессия цены → один выход);\n",
        "\n",
        "3. Немного дообучаем (это называется `fine-tune`) и получим рабочую модель.\n",
        "\n",
        "Это резко сокращает время, требования к данным и даёт хороший старт.\n",
        "\n",
        "**Опять этот зоопарк**\n",
        "\n",
        "Существует множество архитектур нейросетей для зрения. Вот основные типы, с которыми вы столкнетесь:\n",
        "\n",
        "* **Сверточные нейронные сети** (CNN). Это классика CV. Такие сети работают по принципу \"скользящего окошка\": они смотрят на небольшие участки изображения, находят там простые паттерны (линии, углы), затем объединяют их в более сложные (текстуры, формы) и так далее, пока не \"поймут\" все изображение целиком.\n",
        "\n",
        "    * `ResNet-18/34/50` - классика, надёжно, быстро, куча примеров. Отличный бэйзлайн.\n",
        "    * `EfficientNet-B0/B3` - точнее при тех же FLOPs, но чувствительны к размеру входа и аугментациям.\n",
        "    * `MobileNet/RegNet` - компактные, хороши на слабом GPU/CPU.\n",
        "    * `ConvNeXt-T/S` - современные сверточные трансформеры: часто сильнее ResNet при умеренной цене.\n",
        "\n",
        "* **Вижен-трансформеры**. Это более современный подход, пришедший из мира текстов. Вместо того чтобы смотреть на картинку по частям, трансформер разрезает ее на сетку из небольших патчей (как на слова в предложении) и анализирует их все сразу, находя взаимосвязи между самыми дальними частями изображения.\n",
        "\n",
        "    * ViT/DeiT/Swin - трансформеры для изображений. Сильные, но обычно требуют чуть больше заботы (аугментации/размеры).\n",
        "\n",
        "* **Мультимодальные модели**. Это супер-звезды последних лет. Их обучали одновременно и на картинках, и на текстах, которые эти картинки описывают. В итоге они научились понимать смысл изображения на очень глубоком уровне. Они могут связать фото собаки и текст \"веселый золотистый ретривер бежит по траве\".\n",
        "\n",
        "    * CLIP/SigLIP - учились сопоставлять изображения и подписи. Их image-tower даёт очень универсальные эмбеддинги.\n",
        "\n",
        "> Ну очень сильно советуем на досуге заглянуть на курсы (например, [Глубинное обучение-1](https://github.com/xiyori/intro-to-dl-hse)) и почитать/послушать про модели в глубинном обучении. Как обычно: просто не будет, но раз вы уже здесь, то к этому уже готовы.\n"
      ],
      "metadata": {
        "id": "4k439C36WIEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Два пути**\n",
        "\n",
        "Итак, мы выбрали предобученную модель. Как именно ее использовать? Здесь, как и в задаче с текстами, есть два основных пути.\n",
        "\n",
        "**Вариант 1: Fine-tuning**\n",
        "\n",
        "Это тот самый подход, который мы используем в нашем бейзлайне. Мы берем предобученную модель (наш `ResNet18`) и видим в ней две части:\n",
        "\n",
        "- \"Спину\" (`backbone`). Огромная часть сети, которая уже умеет извлекать из картинки полезные признаки (эмбеддинги). Это ее глаза и зрительная кора.\n",
        "\n",
        "- \"Голову\" (`head`). Маленький последний слой, который принимал решение о том, к какому из 1000 классов `ImageNet` относится картинка.\n",
        "\n",
        "Мы \"отрезаем\" старую голову (ува-ха-ха) и на ее место прикрепляем новую, которая подходит для нашей задачи - простой линейный слой, выдающий одно число (цену). После этого мы запускаем процесс дообучения (`fine-tuning`): показываем модели наши картинки с машинами и их ценами и немного корректируем веса всей сети, чтобы она \"переквалифицировалась\" с общей задачи на нашу, конкретную.\n",
        "\n",
        "**Вариант 2: Feature Extraction**\n",
        "\n",
        "Иногда нам не нужно, чтобы модель сама давала финальный ответ. Мы можем использовать ее только как очень умного \"извлекателя признаков\". Этот подход идеально подходит, когда у нас, помимо картинок, есть еще и табличные данные.\n",
        "\n",
        "Схема такая:\n",
        "\n",
        "1. **Получаем эмбеддинги**. Прогоняем все наши картинки через мощную модель (особенно хорошо здесь подходят мультимодальные, вроде CLIP или SigLIP) и на выходе получаем для каждой картинки один вектор чисел (эмбеддинг). Этот вектор - концентрированная суть изображения.\n",
        "\n",
        "2. **Объединяем данные**. Добавляем этот вектор как новые колонки в нашу исходную таблицу с данными (пробег, цвет, тип кузова...).\n",
        "\n",
        "3. **Обучаем решателя**. Обучаем на этой новой, обогащенной таблице классическую, но очень мощную модель, например, градиентный бустинг (CatBoost, LightGBM).\n",
        "\n",
        "Этот двухэтапный подход невероятно силен. Нейросеть выступает в роли \"эксперта-консультанта\" по картинкам, а бустинг - в роли \"суперменеджера\", который принимает финальное решение, учитывая и мнение эксперта по фото, и все остальные табличные данные."
      ],
      "metadata": {
        "id": "EpMM2db7aCqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Как объединять изображения и табличные признаки"
      ],
      "metadata": {
        "id": "LfrzLiRVb_0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наш бейзлайн, вы скоро уже до него доберетесь, работающий только с картинками, - это отличная отправная точка. Но давайте будем честны: по одной лишь фотографии сложно отличить машину с пробегом 10 000 км от такой же, но с пробегом 150 000 км. Вся эта бесценная информация лежит в табличных данных.\n",
        "\n",
        "Задача специалиста по данным - использовать все доступные источники информации. Процесс объединения данных из разных источников (в нашем случае, картинок и таблиц) называется **фьюжном **(`fusion`). Существует три базовых подхода.\n",
        "\n",
        "**Подход 1: Late Fusion (Ансамбль на уровне предсказаний)**\n",
        "\n",
        "Это самый простой и интуитивный способ. Его можно назвать \"советом экспертов\".\n",
        "\n",
        "Как это работает:\n",
        "\n",
        "1.  Обучаем CV-модель (например, наш `ResNet`), которая смотрит только на фото и выдает свое предсказание цены ($\\hat y_{\\text{image}}$).\n",
        "2.  Затем берем только табличные данные и обучаем на них отдельную, классическую модель. Этот \"эксперт\" тоже выдает свое предсказание цены ($\\hat y_{\\text{tabular}}$).\n",
        "3.  А после просто смешиваем их предсказания, например, взяв взвешенное среднее:\n",
        "\n",
        "    $$\n",
        "    \\hat y = w \\cdot \\hat y_{\\text{image}} + (1-w)\\cdot \\hat y_{\\text{tabular}}\n",
        "    $$\n",
        "\n",
        "Где весовой коэффициент `w` (например, 0.4) можно подобрать на валидационной выборке, чтобы минимизировать нашу метрику `medianAPE`.\n",
        "\n",
        "**Плюсы.** Просто, надёжно, легко реализовать.\n",
        "\n",
        "**Минусы.** Модели не \"общаются\" друг с другом во время обучения.\n",
        "\n",
        "**Подход 2: Mid-level Fusion (Склеиваем признаки)**\n",
        "\n",
        "Это более продвинутый и, как правило, более мощный подход.\n",
        "\n",
        "1. Прогоняем все картинки через `ResNet`, но вместо предсказания цены забираем *эмбеддинг*, который нейросеть извлекла из изображения (в нашем случае, это 512 чисел).\n",
        "2. Все табличные признаки тоже превращаем в числа (нормализуем пробег, кодируем категории и т.д.).\n",
        "3. Соединяем вектор от картинки и вектор от таблицы в один огромный вектор признаков.\n",
        "4. Обучаем одну мощную модель на этом объединенном сете.\n",
        "\n",
        "**Плюсы.** Модель видит всю информацию сразу и может находить сложные зависимости (например, \"для *такого-то* типа кузова на фото низкий пробег из таблицы особенно сильно повышает цену\").\n",
        "\n",
        "**Минусы.** Нужно аккуратно готовить все признаки и следить за утечками данных.\n",
        "\n",
        "**Подход 3: Early Fusion (Продвинутый)**\n",
        "\n",
        "В этом подходе мы строим единую, сложную нейросеть, у которой есть несколько \"входов\": одна \"голова\" для картинок, другая - для табличных данных. Признаки из них объединяются где-то в середине архитектуры. Это мощно, но сложно в реализации и не подходит для бейзлайна."
      ],
      "metadata": {
        "id": "GdTn3YYacG9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Пара советов перед стартом:\n",
        ">\n",
        "> Помните, что данные разделены по времени (тест - это декабрь). Для честной оценки всегда делайте валидацию на \"конце\" обучающих данных (например, на ноябре). Все \"обучаемые\" преобразования (скейлеры, кодировщики) настраивайте (`.fit()`) **только на `train`**!\n",
        ">\n",
        "> Категориальные признаки можно превратить в `one-hot` векторы или просто оставить как есть и отдать в `CatBoost` (он умеет работать с категориями напрямую). А можно и в набор бинарных флагов.\n",
        ">\n",
        "> Попробуйте обучиться на логарифме `log1p(price)`, как в бейзлайне. Это приятно.\n"
      ],
      "metadata": {
        "id": "qaG_wqwahRcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бейзлайн"
      ],
      "metadata": {
        "id": "OJeEG5tZYstC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну что ж, теория - это хорошо, но пора переходить к практике! Сейчас мы соберем наше первое, базовое решение для задачи предсказания цены.\n",
        "\n",
        "Наша стратегия для бейзлайна:\n",
        "\n",
        "1. **Фокусируемся на картинках.** Мы намеренно будем использовать только фотографии автомобилей, чтобы отточить навыки работы с CV-моделями. Подключение табличных данных - это следующий, очевидный шаг для улучшения, который мы оставим уже за вами.\n",
        "\n",
        "2. **Берем готовую модель.** Мы не будем изобретать нейросеть с нуля. Мы возьмем популярную и проверенную архитектуру `ResNet18`, уже предобученную на миллионах изображений из *ImageNet*.\n",
        "\n",
        "3. **Просто и понятно.** Весь код будет написан максимально прямолинейно, чтобы был понятен каждый этап: от загрузки данных до получения файла с предсказаниями.\n",
        "\n",
        "Тогда поехали.\n",
        "\n"
      ],
      "metadata": {
        "id": "3JevqcPeGJyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка окружения и импорты"
      ],
      "metadata": {
        "id": "skvQ6XyqGdmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "524e2f55"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2 # OpenCV для работы с изображениями\n",
        "import re\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.models import resnet18, ResNet18_Weights # Наша предобученная модель\n",
        "\n",
        "from collections import defaultdict # Удобный словарь, который не выдает ошибку, если ключа нет\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e7cf571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15864a5f-ea33-4a69-fa85-28bfa49b2e4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Рекомендуем запускать код в среде выполения с cuda\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных"
      ],
      "metadata": {
        "id": "Dogm875sGq-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фотографии для соревнования хранятся в облаке. Нам нужно написать несколько вспомогательных функций, чтобы скачать и распаковать архивы с изображениями. Не стоит скачивать их к себе на рабочую машину, если вы работаете в облачных сервисах - только потратите время."
      ],
      "metadata": {
        "id": "O4Vjq2pEGt5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_direct_file_link(mailru_file_url: str) -> str:\n",
        "    \"\"\"\n",
        "    Превращает ссылку на конкретный файл внутри папки cloud.mail.ru/public/XXX/YYYY/filename\n",
        "    в прямую ссылку на CDN.\n",
        "    \"\"\"\n",
        "    resp = requests.get(mailru_file_url)\n",
        "    if resp.status_code != 200:\n",
        "        raise RuntimeError(f\"Ошибка {resp.status_code} при запросе {mailru_file_url}\")\n",
        "    page = resp.text\n",
        "\n",
        "    match = re.search(r'dispatcher.*?weblink_get.*?url\":\"(.*?)\"', page)\n",
        "    if not match:\n",
        "        raise RuntimeError(\"Не удалось найти CDN ссылку в HTML\")\n",
        "    base_url = match.group(1)\n",
        "\n",
        "    # вычленяем /XXX/YYYY/filename\n",
        "    parts = mailru_file_url.split('/')[-3:]\n",
        "    return f\"{base_url}/{parts[0]}/{parts[1]}/{parts[2]}\"\n",
        "\n",
        "def download_from_mailru(file_url: str, local_name: str):\n",
        "    direct = get_direct_file_link(file_url)\n",
        "    print(f\"Скачиваем {file_url} → {local_name}\")\n",
        "    os.system(f\"wget --content-disposition '{direct}' -O '{local_name}'\")"
      ],
      "metadata": {
        "id": "lKJ9nfxDab5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ссылки на архивы с картинками\n",
        "train_link = \"https://cloud.mail.ru/public/2kaD/W4xWY9vgr/train_images.zip\"\n",
        "test_link  = \"https://cloud.mail.ru/public/2kaD/W4xWY9vgr/test_images.zip\"\n",
        "\n",
        "train_zip = download_from_mailru(train_link, \"train_images.zip\")\n",
        "test_zip  = download_from_mailru(test_link,  \"test_images.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff-vbXFfeXOQ",
        "outputId": "2deb3d3d-f935-42af-a456-7100f9408a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скачиваем https://cloud.mail.ru/public/2kaD/W4xWY9vgr/train_images.zip → train_images.zip\n",
            "Скачиваем https://cloud.mail.ru/public/2kaD/W4xWY9vgr/test_images.zip → test_images.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Распаковываем архивы в соответствующие папки\n",
        "\n",
        "!unzip -q train_images.zip -d train_images\n",
        "!unzip -q test_images.zip -d test_images"
      ],
      "metadata": {
        "id": "4bCz2Hy8ecEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Константы и гиперпараметры"
      ],
      "metadata": {
        "id": "HlF5udwKHHqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хорошая практика - выносить все ключевые настройки в начало кода. Так их легко найти и изменить, проводя новые эксперименты."
      ],
      "metadata": {
        "id": "PXuLD1Q_HJQ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77c320ae"
      },
      "outputs": [],
      "source": [
        "TRAIN_PQ = \"train_dataset.parquet\"\n",
        "TEST_PQ  = \"test_dataset.parquet\"\n",
        "TRAIN_IMG_DIR = \"train_images\"\n",
        "TEST_IMG_DIR  = \"test_images\"\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV  = \"test.csv\"\n",
        "CKPT_NAME = \"efishnet4\"\n",
        "CKPT_PATH = f\"{CKPT_NAME}.pth\"\n",
        "USE_LOG_TARGET = True # Используем логарифмический маштаб таргета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da2df093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bc263e-461c-451c-801a-01c3e586031e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fec2cafae70>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Гиперпараметры\n",
        "\n",
        "IMG_SIZE = 288        # Приводим все картинки к размеру 192x192\n",
        "N_IMAGES_PER_ITEM = 4  # Для бейзлайна берем только 1 картинку на объявление\n",
        "BATCH_SIZE = 16        # Сколько картинок обрабатывать за один шаг\n",
        "EPOCHS = 5             # Сколько раз прогонять все обучающие данные\n",
        "LR = 3e-4              # Скорость обучения (learning rate)\n",
        "WEIGHT_DECAY = 1e-6    # Параметр регуляризации для предотвращения переобучения\n",
        "VAL_SIZE = 0.2         # Какую долю данных отложить для валидации (20%)\n",
        "KEEP_RATIO = 1       # Для ускорения экспериментов можем взять не все данные, а только 50%\n",
        "\n",
        "# Фиксируем \"зерно\" случайности, чтобы наши эксперименты были повторяемыми\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка данных"
      ],
      "metadata": {
        "id": "_l3azxXVHgm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сейчас у нас есть таблица с данными (`.parquet`) и папка с картинками. Нам нужно их подружить - для каждой строки в таблице найти соответствующий файл с изображением. Мы напишем функцию, которая создаст удобный `CSV-файл` с тремя колонками: ID объявления, путь к картинке и цена."
      ],
      "metadata": {
        "id": "ANkGYV_OHk4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b115b96"
      },
      "outputs": [],
      "source": [
        "# Загружаем табличные данные\n",
        "train_df = pd.read_parquet(TRAIN_PQ)\n",
        "test_df  = pd.read_parquet(TEST_PQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2d9b39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "4597dafc-87f9-41da-9b24-e565b13ee610"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID equipment    body_type drive_type engine_type  doors_number  \\\n",
              "0   58146   Базовая        Седан   Передний      Бензин             4   \n",
              "1  112144   Базовая    Универсал     Задний      Бензин             5   \n",
              "2  120705      None  Внедорожник     Полный      Гибрид             5   \n",
              "3  291392  Titanium        Седан   Передний      Бензин             4   \n",
              "4   35742   Базовая        Седан   Передний      Бензин             4   \n",
              "\n",
              "        color          pts audiosistema diski  ...  \\\n",
              "0       Синий     Дубликат         None  None  ...   \n",
              "1     Бежевый     Оригинал         None   14\"  ...   \n",
              "2      Чёрный  Электронный         None  None  ...   \n",
              "3  Серебряный     Оригинал    6 колонок   16\"  ...   \n",
              "4      Чёрный     Оригинал         None  None  ...   \n",
              "\n",
              "                                           fary_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [Противотуманные, Омыватели фар, Адаптивное ос...   \n",
              "3                                             [None]   \n",
              "4                                             [None]   \n",
              "\n",
              "                           multimedia_navigacia_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [CD привод, MP3, Радио, TV, Экран, Управление ...   \n",
              "3  [CD привод, MP3, Радио, TV, Экран, Управление ...   \n",
              "4                                             [None]   \n",
              "\n",
              "                                        obogrev_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [Передних сидений, Задних сидений, Зеркал, Зад...   \n",
              "3                 [Передних сидений, Заднего стекла]   \n",
              "4                                             [None]   \n",
              "\n",
              "                                pamyat_nastroek_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [Сиденья водителя, Задних сидений, Зеркал, Рул...   \n",
              "3                                             [None]   \n",
              "4                                             [None]   \n",
              "\n",
              "                          podushki_bezopasnosti_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [Фронтальная для водителя, Коленные, Шторки, Б...   \n",
              "3  [Фронтальная для водителя, Коленные, Шторки, Б...   \n",
              "4                                             [None]   \n",
              "\n",
              "                           pomosh_pri_vozhdenii_mult  \\\n",
              "0                                             [None]   \n",
              "1                                             [None]   \n",
              "2  [Автопарковщик, Датчик дождя, Датчик света, Па...   \n",
              "3  [Датчик дождя, Датчик света, Парктроник задний...   \n",
              "4                                             [None]   \n",
              "\n",
              "                        protivoygonnaya_sistema_mult           salon_mult  \\\n",
              "0                                             [None]               [None]   \n",
              "1                                     [Сигнализация]               [None]   \n",
              "2  [Сигнализация, Центральный замок, Иммобилайзер...  [Кожаный руль, Люк]   \n",
              "3                  [Сигнализация, Центральный замок]       [Кожаный руль]   \n",
              "4                                             [None]               [None]   \n",
              "\n",
              "                       upravlenie_klimatom_mult  price_TARGET  \n",
              "0                                        [None]         51000  \n",
              "1                                        [None]        195000  \n",
              "2  [Управление на руле, Атермальное остекление]       7251000  \n",
              "3                          [Управление на руле]       1067000  \n",
              "4                                        [None]         54000  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f37a86da-c478-4fd3-b121-87b20d3eec9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>equipment</th>\n",
              "      <th>body_type</th>\n",
              "      <th>drive_type</th>\n",
              "      <th>engine_type</th>\n",
              "      <th>doors_number</th>\n",
              "      <th>color</th>\n",
              "      <th>pts</th>\n",
              "      <th>audiosistema</th>\n",
              "      <th>diski</th>\n",
              "      <th>...</th>\n",
              "      <th>fary_mult</th>\n",
              "      <th>multimedia_navigacia_mult</th>\n",
              "      <th>obogrev_mult</th>\n",
              "      <th>pamyat_nastroek_mult</th>\n",
              "      <th>podushki_bezopasnosti_mult</th>\n",
              "      <th>pomosh_pri_vozhdenii_mult</th>\n",
              "      <th>protivoygonnaya_sistema_mult</th>\n",
              "      <th>salon_mult</th>\n",
              "      <th>upravlenie_klimatom_mult</th>\n",
              "      <th>price_TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58146</td>\n",
              "      <td>Базовая</td>\n",
              "      <td>Седан</td>\n",
              "      <td>Передний</td>\n",
              "      <td>Бензин</td>\n",
              "      <td>4</td>\n",
              "      <td>Синий</td>\n",
              "      <td>Дубликат</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>51000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>112144</td>\n",
              "      <td>Базовая</td>\n",
              "      <td>Универсал</td>\n",
              "      <td>Задний</td>\n",
              "      <td>Бензин</td>\n",
              "      <td>5</td>\n",
              "      <td>Бежевый</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>None</td>\n",
              "      <td>14\"</td>\n",
              "      <td>...</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[Сигнализация]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>195000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120705</td>\n",
              "      <td>None</td>\n",
              "      <td>Внедорожник</td>\n",
              "      <td>Полный</td>\n",
              "      <td>Гибрид</td>\n",
              "      <td>5</td>\n",
              "      <td>Чёрный</td>\n",
              "      <td>Электронный</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>[Противотуманные, Омыватели фар, Адаптивное ос...</td>\n",
              "      <td>[CD привод, MP3, Радио, TV, Экран, Управление ...</td>\n",
              "      <td>[Передних сидений, Задних сидений, Зеркал, Зад...</td>\n",
              "      <td>[Сиденья водителя, Задних сидений, Зеркал, Рул...</td>\n",
              "      <td>[Фронтальная для водителя, Коленные, Шторки, Б...</td>\n",
              "      <td>[Автопарковщик, Датчик дождя, Датчик света, Па...</td>\n",
              "      <td>[Сигнализация, Центральный замок, Иммобилайзер...</td>\n",
              "      <td>[Кожаный руль, Люк]</td>\n",
              "      <td>[Управление на руле, Атермальное остекление]</td>\n",
              "      <td>7251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>291392</td>\n",
              "      <td>Titanium</td>\n",
              "      <td>Седан</td>\n",
              "      <td>Передний</td>\n",
              "      <td>Бензин</td>\n",
              "      <td>4</td>\n",
              "      <td>Серебряный</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>6 колонок</td>\n",
              "      <td>16\"</td>\n",
              "      <td>...</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[CD привод, MP3, Радио, TV, Экран, Управление ...</td>\n",
              "      <td>[Передних сидений, Заднего стекла]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[Фронтальная для водителя, Коленные, Шторки, Б...</td>\n",
              "      <td>[Датчик дождя, Датчик света, Парктроник задний...</td>\n",
              "      <td>[Сигнализация, Центральный замок]</td>\n",
              "      <td>[Кожаный руль]</td>\n",
              "      <td>[Управление на руле]</td>\n",
              "      <td>1067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35742</td>\n",
              "      <td>Базовая</td>\n",
              "      <td>Седан</td>\n",
              "      <td>Передний</td>\n",
              "      <td>Бензин</td>\n",
              "      <td>4</td>\n",
              "      <td>Чёрный</td>\n",
              "      <td>Оригинал</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>54000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f37a86da-c478-4fd3-b121-87b20d3eec9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f37a86da-c478-4fd3-b121-87b20d3eec9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f37a86da-c478-4fd3-b121-87b20d3eec9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1fddba4a-4573-489d-8f1a-6e6e5f9ef137\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1fddba4a-4573-489d-8f1a-6e6e5f9ef137')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1fddba4a-4573-489d-8f1a-6e6e5f9ef137 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_df.head() # посмотрим на данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e281341a"
      },
      "outputs": [],
      "source": [
        "def build_img_csv(df, img_dir, out_csv, n_images=1, keep_ratio=1.0, seed=42):\n",
        "\n",
        "    \"\"\"\n",
        "    Функция для создания CSV-файла, связывающего ID объявления с путями к его фотографиям.\n",
        "    \"\"\"\n",
        "\n",
        "    all_files = os.listdir(img_dir)\n",
        "    id_to_files = defaultdict(list)\n",
        "    for fname in all_files:\n",
        "        if fname.endswith(\".jpg\"):\n",
        "            iid = int(fname.split(\"_\")[0])  # предполагаем формат ID_xxx.jpg\n",
        "            id_to_files[iid].append(os.path.join(img_dir, fname))\n",
        "\n",
        "    rows = []\n",
        "    for r in df.itertuples(index=False):\n",
        "        iid = getattr(r, \"ID\")\n",
        "        paths = sorted(id_to_files.get(iid, []))\n",
        "        if len(paths) > n_images:\n",
        "            paths = paths[:n_images]\n",
        "\n",
        "        row = {\n",
        "            \"item_id\": iid,\n",
        "            \"paths\": \";\".join(paths)\n",
        "        }\n",
        "\n",
        "        # цена есть только в train\n",
        "        if \"price_TARGET\" in df.columns:\n",
        "            row[\"price\"] = getattr(r, \"price_TARGET\")\n",
        "        else:\n",
        "            row[\"price\"] = -1  # заглушка для test\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    # Создаем и сохраняем итоговый DataFrame\n",
        "    csv_df = pd.DataFrame(rows)\n",
        "\n",
        "    # Если нужно, оставляем только часть данных для быстрых экспериментов\n",
        "    if keep_ratio < 1.0:\n",
        "        csv_df = csv_df.sample(frac=keep_ratio, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    csv_df.to_csv(out_csv, index=False)\n",
        "    print(f\"CSV сохранён: {out_csv}, shape={csv_df.shape}\")\n",
        "    return csv_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запускаем функцию для train и test выборок\n",
        "\n",
        "train_csv_df = build_img_csv(train_df, TRAIN_IMG_DIR, TRAIN_CSV)\n",
        "test_csv_df  = build_img_csv(test_df,  TEST_IMG_DIR,  TEST_CSV)"
      ],
      "metadata": {
        "id": "9ExdqNUobmP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f353433d-0605-4ea8-c69e-cc0f285a5668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV сохранён: train.csv, shape=(70000, 3)\n",
            "CSV сохранён: test.csv, shape=(25000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61092cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "acadbd91-c76b-4e16-86b6-e20a02a6560a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   item_id                      paths    price\n",
              "0    58146   train_images/58146_0.jpg    51000\n",
              "1   112144  train_images/112144_0.jpg   195000\n",
              "2   120705  train_images/120705_0.jpg  7251000\n",
              "3   291392  train_images/291392_0.jpg  1067000\n",
              "4    35742   train_images/35742_0.jpg    54000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-454d6104-507d-4987-95aa-ceb94215d7e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id</th>\n",
              "      <th>paths</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58146</td>\n",
              "      <td>train_images/58146_0.jpg</td>\n",
              "      <td>51000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>112144</td>\n",
              "      <td>train_images/112144_0.jpg</td>\n",
              "      <td>195000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120705</td>\n",
              "      <td>train_images/120705_0.jpg</td>\n",
              "      <td>7251000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>291392</td>\n",
              "      <td>train_images/291392_0.jpg</td>\n",
              "      <td>1067000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35742</td>\n",
              "      <td>train_images/35742_0.jpg</td>\n",
              "      <td>54000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-454d6104-507d-4987-95aa-ceb94215d7e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-454d6104-507d-4987-95aa-ceb94215d7e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-454d6104-507d-4987-95aa-ceb94215d7e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d31667de-c1e4-4cbd-b273-ee655e7f3555\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d31667de-c1e4-4cbd-b273-ee655e7f3555')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d31667de-c1e4-4cbd-b273-ee655e7f3555 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_csv_df",
              "summary": "{\n  \"name\": \"train_csv_df\",\n  \"rows\": 70000,\n  \"fields\": [\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101875,\n        \"min\": 1,\n        \"max\": 385202,\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          76569,\n          212077,\n          194859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 70000,\n        \"samples\": [\n          \"train_images/76569_0.jpg\",\n          \"train_images/212077_0.jpg\",\n          \"train_images/194859_0.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 911790,\n        \"min\": 10000,\n        \"max\": 26059000,\n        \"num_unique_values\": 4172,\n        \"samples\": [\n          1666000,\n          2029000,\n          712000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_csv_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание конвейера данных (`Dataset` и `DataLoader`)"
      ],
      "metadata": {
        "id": "-wXFZQAxIZ5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прежде чем обучать модель, нам нужно создать конвейер для подачи данных. Он состоит из двух частей, один из них вам уже знаком:\n",
        "\n",
        "1. `Dataset`. Это чертеж одного объекта. Он знает, как по индексу (например, 5-й элемент) найти нужную строку в `CSV`, прочитать картинку с диска, применить к ней аугментации и вернуть готовый для обучения тензор изображения и его цену.\n",
        "\n",
        "2. `DataLoader`. Это начальник смены на конвейере (мы тут все на заводе работаем, если что). Он берет `Dataset`, говорит ему, сколько объектов нужно взять за раз (`batch_size`), и эффективно собирает их в одну большую пачку (батч), готовую для отправки на GPU."
      ],
      "metadata": {
        "id": "k91z6LlcIgPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала определим нашу функцию для расчета метрики `medianAPE` и опишем наши \"инструменты\" для преобразования изображений из библиотеки `Albumentations`."
      ],
      "metadata": {
        "id": "wRlGHEomIPqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d319209"
      },
      "outputs": [],
      "source": [
        "# Реализуем функцию для подсчета medianAPE в точности как в правилах соревнования\n",
        "\n",
        "def median_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mask = y_true > 0\n",
        "    ape = np.abs(y_true[mask] - y_pred[mask]) / (y_true[mask] + 1e-6)\n",
        "    return float(np.median(ape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01d2489b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50911b7e-c527-4366-a88b-e6c36073fd31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Создаем конвейер преобразований для ТРЕНИРОВОЧНЫХ данных\n",
        "\n",
        "train_tfms = A.Compose([\n",
        "    # Шаги предобработки (обязательные)\n",
        "    A.LongestMaxSize(IMG_SIZE), # Уменьшаем картинку по длинной стороне до IMG_SIZE\n",
        "    A.PadIfNeeded(IMG_SIZE, IMG_SIZE, border_mode=cv2.BORDER_CONSTANT), # Добавляем поля до квадрата\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # Нормализуем \"магическими\" числами ImageNet\n",
        "\n",
        "    # Шаги аугментации (случайные)\n",
        "    A.HorizontalFlip(p=0.5), # Отражаем по горизонтали с вероятностью 50%\n",
        "    A.RandomBrightnessContrast(p=0.3), # Меняем яркость и контраст\n",
        "    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.1, rotate_limit=10,\n",
        "                       border_mode=cv2.BORDER_CONSTANT, p=0.5), # Сдвигаем, масштабируем и поворачиваем\n",
        "\n",
        "    # Финальный шаг предобработки\n",
        "    ToTensorV2(), # Превращаем numpy-массив в тензор PyTorch\n",
        "])\n",
        "\n",
        "# Создаем конвейер преобразований для ВАЛИДАЦИОННЫХ данных (только обязательные шаги)\n",
        "valid_tfms = A.Compose([\n",
        "    A.LongestMaxSize(IMG_SIZE),\n",
        "    A.PadIfNeeded(IMG_SIZE, IMG_SIZE, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь напишем класс `CarsDataset`. Его главная задача - по одному `idx` (индексу) вернуть полностью готовую пару (тензор_картинки, цена)."
      ],
      "metadata": {
        "id": "60ajQwo_JGkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bffd5c79"
      },
      "outputs": [],
      "source": [
        "def _safe_imread(p: str, fallback_hw=(IMG_SIZE, IMG_SIZE)) -> np.ndarray:\n",
        "    \"\"\"Безопасно читает картинку. Если файл битый или не существует, возвращает черный квадрат.\"\"\"\n",
        "    img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        # Если картинка не прочиталась, создаем \"пустышку\"\n",
        "        h, w = fallback_hw\n",
        "        img = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        # OpenCV читает картинки в формате BGR, а нам нужен RGB\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "\n",
        "class CarsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета для PyTorch.\n",
        "    \"\"\"\n",
        "    def __init__(self, df: pd.DataFrame, is_train: bool = True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        # Выбираем нужный набор аугментаций в зависимости от того, обучающий это датасет или нет\n",
        "        self.tfms = train_tfms if is_train else valid_tfms\n",
        "        self.has_target = \"price\" in df.columns\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Возвращает общее количество объектов в датасете.\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        \"\"\"По индексу `idx` возвращает один готовый для обучения пример.\"\"\"\n",
        "        row = self.df.iloc[idx]\n",
        "        # Берем пути к картинкам из строки и очищаем от возможных пустых значений\n",
        "        paths = [p for p in str(row[\"paths\"]).split(\";\") if p and p.lower() != \"nan\"][:N_IMAGES_PER_ITEM]\n",
        "\n",
        "        imgs = []\n",
        "        for p in paths:\n",
        "            img = _safe_imread(p) # Читаем картинку\n",
        "            img = self.tfms(image=img)[\"image\"].contiguous() # Применяем аугментации\n",
        "            imgs.append(img)\n",
        "\n",
        "        # Если картинок меньше, чем N_IMAGES_PER_ITEM, добиваем \"пустыми\" тензорами\n",
        "        while len(imgs) < N_IMAGES_PER_ITEM:\n",
        "            imgs.append(torch.zeros(3, IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "        # Собираем список тензоров в один тензор формы (N, C, H, W)\n",
        "        imgs = torch.stack(imgs, dim=0)\n",
        "\n",
        "        # Если это обучающие данные, возвращаем картинки и цену\n",
        "        if self.has_target:\n",
        "            y = torch.tensor(row[\"price\"], dtype=torch.float32)\n",
        "            # Если включен флаг, берем логарифм от цены. Это стабилизирует обучение.\n",
        "            if USE_LOG_TARGET:\n",
        "                y = torch.log1p(y)\n",
        "            return imgs, y\n",
        "        # Если это тестовые данные, возвращаем картинки и ID объявления\n",
        "        else:\n",
        "            return imgs, torch.tensor(row.get(\"item_id\", -1), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сборка и обучение модели"
      ],
      "metadata": {
        "id": "anHJKMADJY6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все подготовительные работы завершены. Теперь мы можем собрать нашу модель, определить цикл обучения и запустить процесс!\n",
        "\n",
        "**Модель и `collate_fn`**\n",
        "\n",
        "Мы возьмем предобученную `resnet18`, отрежем у нее последний слой, который был предназначен для классификации 1000 классов `ImageNet`, и прикрепим свою голову - простой линейный слой, который будет выдавать одно число (нашу предсказанную цену)."
      ],
      "metadata": {
        "id": "AC1SV5g2Jgek"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc147db9"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Вспомогательная функция для DataLoader. Она умеет правильно собирать\n",
        "    пары (картинка, цена) или (картинка, ID) в один батч.\n",
        "    \"\"\"\n",
        "    imgs = torch.stack([b[0] for b in batch], dim=0)  # (B, N, C, H, W)\n",
        "    target = batch[0][1]\n",
        "\n",
        "    # Если таргет - это число с плавающей точкой (цена), собираем тензор цен\n",
        "    if torch.is_tensor(target) and target.dtype.is_floating_point:\n",
        "        y = torch.stack([b[1] for b in batch], dim=0)  # (B,)\n",
        "        return imgs, y\n",
        "    # Иначе это ID, собираем тензор ID\n",
        "    else:\n",
        "        ids = torch.stack([b[1] for b in batch], dim=0)\n",
        "        return imgs, ids\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
        "\n",
        "class ResNetRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout_rate=0.3, hidden_size=256):\n",
        "        super().__init__()\n",
        "        # Загружаем EfficientNet-B2 с весами, предобученными на ImageNet\n",
        "        backbone = efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Получаем размер эмбеддинга для EfficientNet-B2 (1408)\n",
        "        in_features = backbone.classifier[1].in_features\n",
        "\n",
        "        # Удаляем классификатор и создаем backbone\n",
        "        self.backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
        "\n",
        "        # Добавляем адаптивный пулинг\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Сложная голова для регрессии\n",
        "        self.head = nn.Sequential(\n",
        "            # Первый скрытый слой\n",
        "            nn.Linear(in_features, hidden_size),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Второй скрытый слой\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.BatchNorm1d(hidden_size // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            # Третий скрытый слой\n",
        "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
        "            nn.BatchNorm1d(hidden_size // 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate / 2),\n",
        "\n",
        "            # Четвертый скрытый слой (дополнительный для большей сложности)\n",
        "            nn.Linear(hidden_size // 4, hidden_size // 8),\n",
        "            nn.BatchNorm1d(hidden_size // 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate / 3),\n",
        "\n",
        "            # Выходной слой\n",
        "            nn.Linear(hidden_size // 8, 1)\n",
        "        )\n",
        "\n",
        "        # Инициализация весов головы\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Инициализация весов головы\"\"\"\n",
        "        for m in self.head.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x имеет форму (Batch, N_images, Channels, Height, Width)\n",
        "        B, N, C, H, W = x.shape\n",
        "\n",
        "        # \"Распрямляем\" батч, чтобы обработать все картинки одним прогоном\n",
        "        x = x.view(B*N, C, H, W)\n",
        "\n",
        "        # Получаем эмбеддинги (векторы признаков)\n",
        "        feats = self.backbone(x)          # (B*N, 1408, H', W')\n",
        "        feats = self.avgpool(feats)       # (B*N, 1408, 1, 1)\n",
        "        feats = feats.view(B*N, -1)       # (B*N, 1408)\n",
        "\n",
        "        # Возвращаем эмбеддингам форму, связанную с батчем\n",
        "        feats = feats.view(B, N, -1)      # (B, N, 1408)\n",
        "\n",
        "        # Усредняем эмбеддинги по всем картинкам одного объявления\n",
        "        feats = feats.mean(dim=1)         # (B, 1408)\n",
        "\n",
        "        # Прогоняем усредненный эмбеддинг через сложную \"голову\"\n",
        "        out = self.head(feats)            # (B, 1)\n",
        "\n",
        "        return out.squeeze(1)             # (B,) - возвращаем вектор предсказаний         # (B,) - возвращаем вектор предсказаний"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цикл обучения**\n",
        "\n",
        "Это сердце нашего кода. Функция `run_epoch` описывает логику одного полного прохода по данным (одной эпохи). Мы будем вызывать ее много раз - для обучения на `train` данных и для оценки на `validation` данных."
      ],
      "metadata": {
        "id": "tk60ZDj0JyFE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d7c5f65"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, loader, optimizer=None, device=\"cuda\"):\n",
        "    \"\"\"Прогоняет одну эпоху обучения или валидации.\"\"\"\n",
        "    is_train = optimizer is not None  # Если передан optimizer - это обучение\n",
        "    model.train(is_train) # Переключаем модель в режим train или eval\n",
        "\n",
        "    losses = []\n",
        "    preds_log_all, y_log_all = [], []\n",
        "\n",
        "    # tqdm оборачивает итератор, чтобы показывать красивую полоску прогресса\n",
        "    pbar = tqdm(loader, desc=\"Train\" if is_train else \"Valid\", leave=False)\n",
        "    for imgs, y_log in pbar:\n",
        "        # Переносим данные на GPU\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        y_log = y_log.view(-1).to(device)\n",
        "\n",
        "        # Получаем предсказания модели\n",
        "        preds_log = model(imgs)\n",
        "        # Считаем ошибку. L1Loss (MAE) хорошо работает для регрессии, особенно с логарифмом.\n",
        "        loss = nn.L1Loss()(preds_log, y_log)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad(set_to_none=True) # Обнуляем градиенты\n",
        "            loss.backward()                       # Считаем градиенты\n",
        "            optimizer.step()                      # Обновляем веса модели\n",
        "\n",
        "        # Собираем статистику\n",
        "        losses.append(loss.item())\n",
        "        preds_log_all.append(preds_log.detach().cpu())\n",
        "        y_log_all.append(y_log.detach().cpu())\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.3f}\"}) # Показываем текущую ошибку в прогресс-баре\n",
        "\n",
        "    # Считаем итоговые метрики за всю эпоху\n",
        "    preds_log_all = torch.cat(preds_log_all).numpy()\n",
        "    y_log_all     = torch.cat(y_log_all).numpy()\n",
        "\n",
        "    # Если использовали логарифм, возвращаем предсказания и таргет в исходный масштаб\n",
        "    preds  = np.expm1(preds_log_all)\n",
        "    y_true = np.expm1(y_log_all)\n",
        "\n",
        "    medape = median_absolute_percentage_error(y_true, preds) * 100.0\n",
        "    return float(medape), float(np.mean(losses))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Запускаем нашу пушку!**"
      ],
      "metadata": {
        "id": "ipRX2mVaKAb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0338e8a4"
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "    \"epoch\": [],\n",
        "    \"tr_loss\": [],\n",
        "    \"tr_medape\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_medape\": [],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Память после очистки: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_qRuR-yuXAA",
        "outputId": "11aff663-cdd1-4da0-8b7a-a3963067f6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Память после очистки: 0.33 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab6b8875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "20df227c-3a52-47cb-ae79-6018fec69766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Эпоха 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 102.12 MiB is free. Process 8183 has 14.63 GiB memory in use. Of the allocated memory 14.05 GiB is allocated by PyTorch, and 462.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-151044881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtr_medape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Запускаем эпоху валидации (optimizer=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mval_medape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train loss: {tr_loss:.3f} | medianAPE: {tr_medape:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4179573899.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Получаем предсказания модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpreds_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Считаем ошибку. L1Loss (MAE) хорошо работает для регрессии, особенно с логарифмом.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3422677975.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Получаем эмбеддинги (векторы признаков)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# (B*N, 1408, H', W')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# (B*N, 1408, 1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# (B*N, 1408)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 102.12 MiB is free. Process 8183 has 14.63 GiB memory in use. Of the allocated memory 14.05 GiB is allocated by PyTorch, and 462.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(TRAIN_CSV)\n",
        "trn_df, val_df = train_test_split(df, test_size=VAL_SIZE, random_state=SEED, shuffle=True)\n",
        "\n",
        "train_ds = CarsDataset(trn_df, is_train=True)\n",
        "valid_ds = CarsDataset(val_df, is_train=False)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          pin_memory=True, num_workers=4, drop_last=True,\n",
        "                          collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          pin_memory=True, num_workers=4, drop_last=False,\n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "model = ResNetRegressor().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "best_val_medape = float(\"inf\")\n",
        "\n",
        "# Главный цикл обучения\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"\\nЭпоха {epoch}/{EPOCHS}\")\n",
        "    # Запускаем эпоху обучения\n",
        "    tr_medape, tr_loss = run_epoch(model, train_loader, optimizer, device=device)\n",
        "    # Запускаем эпоху валидации (optimizer=None)\n",
        "    val_medape, val_loss = run_epoch(model, valid_loader, optimizer=None, device=device)\n",
        "\n",
        "    print(f\"Train loss: {tr_loss:.3f} | medianAPE: {tr_medape:.2f}%\")\n",
        "    print(f\"Valid loss: {val_loss:.3f} | medianAPE: {val_medape:.2f}%\")\n",
        "\n",
        "    # Сохраняем историю\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    history[\"tr_loss\"].append(tr_loss)\n",
        "    history[\"tr_medape\"].append(tr_medape)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"val_medape\"].append(val_medape)\n",
        "\n",
        "    # Сохраняем модель (чекпоинт), только если она показала лучший результат на валидации\n",
        "    if val_medape < best_val_medape:\n",
        "        best_val_medape = val_medape\n",
        "        torch.save({\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"val_medape\": val_medape\n",
        "        }, CKPT_PATH)\n",
        "        print(f\"✓ Модель сохранена в эпоху {epoch} -> {CKPT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(f\"Train loss: {tr_loss:.3f} | medianAPE: {tr_medape:.2f}%\")"
      ],
      "metadata": {
        "id": "VfCH_GkmAXIw",
        "outputId": "60b413f0-f03c-4ee7-97eb-27f693caf2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.898 | medianAPE: 96.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ результатов и инференс на тесте"
      ],
      "metadata": {
        "id": "8TH1iCfSKPIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение завершено! Давайте посмотрим на графики, чтобы понять, как вела себя модель, а затем используем лучшую сохраненную версию для предсказаний на тестовых данных."
      ],
      "metadata": {
        "id": "0Nro-g5GKRHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e301c67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "f20f9db2-701f-48c4-b1ca-b255c8c7b263"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Визуализация истории обучения\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history[\"epoch\"], history[\"tr_medape\"], label=\"train medAPE\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_medape\"], label=\"valid medAPE\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Median APE, %\")\n",
        "plt.title(\"Median APE vs Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"medape_vs_epoch_{CKPT_NAME}.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5c37e58"
      },
      "outputs": [],
      "source": [
        "# Сохраняем историю в CSV для дальнейшего анализа\n",
        "\n",
        "csv_name = f\"{CKPT_NAME}.csv\"\n",
        "df_hist = pd.DataFrame(history)\n",
        "df_hist.to_csv(csv_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5874011"
      },
      "outputs": [],
      "source": [
        "# Инференс на тестовых данных\n",
        "\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "test_ds = CarsDataset(test_df, is_train=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         num_workers=8, pin_memory=True, drop_last=False,\n",
        "                         collate_fn=collate_fn)\n",
        "\n",
        "# Загружаем лучшую сохраненную модель\n",
        "ckpt = torch.load(CKPT_PATH, map_location=device)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "model.eval() # Переводим модель в режим предсказания\n",
        "\n",
        "preds_all, ids_all = [], []\n",
        "# torch.no_grad() отключает расчет градиентов, что ускоряет инференс и экономит память\n",
        "with torch.no_grad():\n",
        "    for imgs, ids in tqdm(test_loader, desc=\"Test\", leave=False):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        preds = model(imgs) # Получаем предсказания в лог-масштабе\n",
        "\n",
        "        # Если нужно, возвращаем в исходный масштаб\n",
        "        if USE_LOG_TARGET:\n",
        "            preds = torch.expm1(preds)\n",
        "\n",
        "        preds_all.append(preds.cpu())\n",
        "        ids_all.append(ids.cpu())\n",
        "\n",
        "# Собираем все предсказания и ID в единые массивы\n",
        "preds_all = torch.cat(preds_all).squeeze().numpy()\n",
        "ids_all   = torch.cat(ids_all).squeeze().numpy()\n",
        "\n",
        "# Формирование файла для сабмита\n",
        "submission_df = pd.DataFrame({\n",
        "    \"ID\": ids_all,\n",
        "    \"price_TARGET\": preds_all\n",
        "})\n",
        "\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Убедимся, что наш файл имеет ту же структуру и размер, что и образец\n",
        "# Это простой, но очень полезный санити-чек\n",
        "\n",
        "sample = pd.read_csv(\"sample_submission.csv\")\n",
        "assert list(submission_df.columns) == [\"ID\", \"target\"]\n",
        "assert len(submission_df) == len(sample)\n",
        "\n",
        "print(\"Размер сабмита:\", submission_df.shape)"
      ],
      "metadata": {
        "id": "Bv4Ph_1ELic6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Воу, ну неплохо - ваша CV-моделька зафайнтюнена. Наши поздравления! ✌\n",
        "\n",
        "Куда теперь можно прыгнуть? Вот несколько вариантов:\n",
        "\n",
        "1.  Подружить\" картинки и таблицы (Fusion). Очевидный шаг. Ваша модель по картинке уже умеет генерировать эмбеддинг (вектор признаков). Возьмите этот вектор и \"склейте\" его с признаками из таблицы (`пробег`, `тип кузова`, `цвет` и т.д.), а затем обучите на этой объединенной таблице мощный градиентный бустинг.\n",
        "2.  Больше картинок - больше информации. Разумно не ограничиваем себя.\n",
        "3.  Более мощный старт. Мы использовали легкий `ResNet18`. Попробуйте более современные и мощные архитектуры.\n",
        "4.  Тонкая настройка. Не бойтесь экспериментировать с гиперпараметрами: размером картинки (`IMG_SIZE`), скоростью обучения (`LR`), количеством эпох и, конечно же, набором аугментаций.\n",
        "\n",
        "Машинное обучение - это итеративный процесс. Пробуйте новые идеи, измеряйте результат на валидационной выборке и оставляйте те изменения, которые действительно улучшают вашу метрику."
      ],
      "metadata": {
        "id": "C3DPwzQlMCs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Заключение"
      ],
      "metadata": {
        "id": "onFoQRWeLyUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы вместе прошли неплохой путь от знакомства с цифровой душой фотографии до создания полноценного нейросетевого решения, которое умеет видеть и оценивать автомобили.\n",
        "\n",
        "Что мы сделали в этом ноутбуке:\n",
        "\n",
        "- **Научились говорить на языке CV.** Разобрались, что такое тензор изображения, зачем нужны предобработка и аугментации, и как они реализованы в библиотеке `Albumentations`.\n",
        "- **Освоили Transfer Learning.** Поняли, как взять мощную, предобученную на миллионах картинок модель (`ResNet18`), и быстро адаптировать ее для нашей задачи регрессии.\n",
        "- **Построили CV-пайплайн.** Собрали полный конвейер от чтения \"сырых\" картинок до обучения модели и генерации файла с предсказаниями.\n",
        "\n",
        "Наш бейзлайн, основанный только на картинках, - это отличная и очень важная отправная точка. Но настоящая магия в этой задаче начнется тогда, когда мы научим модель видеть не только изображение, но и всю доступную информацию о машине.\n",
        "\n",
        "Удачи в экспериментах!"
      ],
      "metadata": {
        "id": "_Tmc8mMYLiF-"
      }
    }
  ]
}
