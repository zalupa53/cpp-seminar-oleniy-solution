{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ad4185c59d6674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:05:50.553684Z",
     "start_time": "2025-10-19T14:05:50.449398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных и подготовка временных границ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "print(\"Загрузка данных и подготовка временных границ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a58c13de5d9a3c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:05:51.553726Z",
     "start_time": "2025-10-19T14:05:50.556646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего дней: 47 (0–46)\n",
      "Валидация: дни 40–46 (7 дней)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Загрузка данных\n",
    "train_data = pd.read_parquet('datasets/train_data.pq')\n",
    "sample_sub = pd.read_csv('datasets/sample_submission.csv')\n",
    "\n",
    "# Данные содержат 47 дней: 0–46\n",
    "MAX_DATE = 46\n",
    "VAL_START = 40  # валидация: дни 40–46 (7 дней), как в тесте\n",
    "TEST_START = 47  # в тесте предсказываем \"виртуальные\" дни 47–53, но обучаемся на 0–46\n",
    "\n",
    "user_ids_test = set(sample_sub['user_id'].unique())\n",
    "assert user_ids_test.issubset(set(train_data['user_id'])), \"Все пользователи из теста должны быть в трейне\"\n",
    "\n",
    "print(f\"Всего дней: {MAX_DATE + 1} (0–{MAX_DATE})\")\n",
    "print(f\"Валидация: дни {VAL_START}–{MAX_DATE} (7 дней)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594fc07b56df66d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:05:51.610899Z",
     "start_time": "2025-10-19T14:05:51.604380Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_candidates(train, user_ids, train_days=17, recent_days=3, personal_window_days=10, top_k_candidates=100):\n",
    "    \"\"\"\n",
    "    Генерация кандидатов на основе эвристик.\n",
    "    \"\"\"\n",
    "    max_date = train['date'].max()\n",
    "    train_period = train[train['date'] >= (max_date - train_days + 1)].copy()\n",
    "    recent_cutoff = max_date - recent_days + 1\n",
    "    personal_cutoff = max_date - personal_window_days + 1\n",
    "\n",
    "    recent_data = train_period[train_period['date'] >= recent_cutoff]\n",
    "    personal_data = train_period[train_period['date'] >= personal_cutoff]\n",
    "\n",
    "    global_top = train_period['item_id'].value_counts().head(top_k_candidates).index.values\n",
    "    recent_top = recent_data['item_id'].value_counts().head(top_k_candidates).index.values\n",
    "\n",
    "    user_recent_items = (\n",
    "        recent_data\n",
    "        .sort_values(['user_id', 'date'])\n",
    "        .groupby('user_id')['item_id']\n",
    "        .agg(lambda x: x.drop_duplicates().tail(5)[::-1].tolist())\n",
    "    )\n",
    "    user_personal_top = (\n",
    "        personal_data\n",
    "        .groupby('user_id')['item_id']\n",
    "        .value_counts()\n",
    "        .groupby('user_id')\n",
    "        .head(10)\n",
    "        .reset_index(name='count')\n",
    "        .groupby('user_id')['item_id']\n",
    "        .apply(list)\n",
    "    )\n",
    "\n",
    "    candidates = []\n",
    "    for user_id in tqdm(user_ids, desc=\"Генерация кандидатов\"):\n",
    "        seen = set()\n",
    "        cand = []\n",
    "\n",
    "        if user_id in user_recent_items.index:\n",
    "            for item in user_recent_items[user_id]:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'recent'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        if user_id in user_personal_top.index:\n",
    "            for item in user_personal_top[user_id]:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'personal'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        for item in recent_top:\n",
    "            if len(cand) >= top_k_candidates: break\n",
    "            if item not in seen:\n",
    "                cand.append((user_id, item, 'trend'))\n",
    "                seen.add(item)\n",
    "\n",
    "        for item in global_top:\n",
    "            if len(cand) >= top_k_candidates: break\n",
    "            if item not in seen:\n",
    "                cand.append((user_id, item, 'global'))\n",
    "                seen.add(item)\n",
    "\n",
    "        while len(cand) < top_k_candidates and len(seen) < len(global_top):\n",
    "            for item in global_top:\n",
    "                if len(cand) >= top_k_candidates: break\n",
    "                if item not in seen:\n",
    "                    cand.append((user_id, item, 'fallback'))\n",
    "                    seen.add(item)\n",
    "\n",
    "        candidates.extend(cand[:top_k_candidates])\n",
    "\n",
    "    return pd.DataFrame(candidates, columns=['user_id', 'item_id', 'candidate_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a1e641617ca371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:05:51.668293Z",
     "start_time": "2025-10-19T14:05:51.657609Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_features(df, full_train, max_date_for_features):\n",
    "    \"\"\"\n",
    "    Создание признаков на основе full_train до дня max_date_for_features (включительно).\n",
    "    \"\"\"\n",
    "    print(\"Создание признаков...\")\n",
    "\n",
    "    # Признаки по пользователю\n",
    "    user_stats = full_train.groupby('user_id')['date'].agg(\n",
    "        user_total_clicks='count',\n",
    "        user_last_click_day='max',\n",
    "        user_first_click_day='min'\n",
    "    ).reset_index()\n",
    "    user_stats['user_active_days'] = user_stats['user_last_click_day'] - user_stats['user_first_click_day'] + 1\n",
    "    user_stats['user_recency'] = max_date_for_features - user_stats['user_last_click_day']\n",
    "\n",
    "    # Признаки по товару\n",
    "    item_stats = full_train.groupby('item_id')['date'].agg(\n",
    "        item_total_clicks='count',\n",
    "        item_last_click_day='max',\n",
    "        item_first_click_day='min'\n",
    "    ).reset_index()\n",
    "    item_stats['item_recency'] = max_date_for_features - item_stats['item_last_click_day']\n",
    "\n",
    "    for days in [1, 3, 7, 14]:\n",
    "        cutoff = max_date_for_features - days + 1\n",
    "        pop = full_train[full_train['date'] >= cutoff].groupby('item_id').size().rename(f'item_pop_{days}d')\n",
    "        item_stats = item_stats.merge(pop, on='item_id', how='left')\n",
    "\n",
    "    # Признаки пары\n",
    "    user_item_stats = full_train.groupby(['user_id', 'item_id'])['date'].agg(\n",
    "        ui_clicks='count',\n",
    "        ui_last_click='max',\n",
    "        ui_first_click='min'\n",
    "    ).reset_index()\n",
    "    user_item_stats['ui_recency'] = max_date_for_features - user_item_stats['ui_last_click']\n",
    "    user_item_stats['ui_frequency'] = user_item_stats['ui_clicks'] / (user_item_stats['ui_last_click'] - user_item_stats['ui_first_click'] + 1)\n",
    "\n",
    "    # Объединение\n",
    "    df = df.merge(user_stats, on='user_id', how='left')\n",
    "    df = df.merge(item_stats, on='item_id', how='left')\n",
    "    df = df.merge(user_item_stats, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "    # Заполнение пропусков\n",
    "    df['ui_clicks'] = df['ui_clicks'].fillna(0)\n",
    "    df['ui_recency'] = df['ui_recency'].fillna(999)\n",
    "    df['ui_frequency'] = df['ui_frequency'].fillna(0)\n",
    "    for col in df.columns:\n",
    "        if 'pop_' in col:\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09f1947ebf2a6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:05:51.719872Z",
     "start_time": "2025-10-19T14:05:51.713038Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_map_at_k(actuals_dict, preds_df, k=20):\n",
    "    \"\"\"\n",
    "    Вычисление mAP@k.\n",
    "    actuals_dict: dict {user_id: set(item_ids)}\n",
    "    preds_df: DataFrame с колонками ['user_id', 'item_id'], отсортирован по релевантности (лучшие первые)\n",
    "    \"\"\"\n",
    "    print(\"Вычисление mAP@20...\")\n",
    "    aps = []\n",
    "    for user_id, true_items in tqdm(actuals_dict.items(), desc=\"Подсчёт AP@20\"):\n",
    "        pred_items = preds_df[preds_df['user_id'] == user_id]['item_id'].values[:k]\n",
    "        if len(pred_items) == 0:\n",
    "            aps.append(0.0)\n",
    "            continue\n",
    "\n",
    "        hits = 0\n",
    "        sum_precisions = 0.0\n",
    "        for i, item in enumerate(pred_items):\n",
    "            if item in true_items:\n",
    "                hits += 1\n",
    "                sum_precisions += hits / (i + 1)\n",
    "\n",
    "        ap = sum_precisions / min(len(true_items), k)\n",
    "        aps.append(ap)\n",
    "\n",
    "    return np.mean(aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501d37045a04237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === ЭТАП 1: ВАЛИДАЦИЯ ===\n",
    "print(\"ЭТАП 1: ВАЛИДАЦИЯ\")\n",
    "print(\"Разделение данных на train_hist (0–39) и val_true (40–46)...\")\n",
    "\n",
    "train_hist = train_data[train_data['date'] < VAL_START].copy()  # дни 0–39\n",
    "val_true = train_data[train_data['date'] >= VAL_START].copy()   # дни 40–46\n",
    "\n",
    "user_ids_val = sorted(val_true['user_id'].unique())\n",
    "print(f\"Пользователей в валидации: {len(user_ids_val)}\")\n",
    "\n",
    "# Генерация кандидатов\n",
    "candidates_val = generate_candidates(\n",
    "    train=train_hist,\n",
    "    user_ids=user_ids_val,\n",
    "    train_days=17,\n",
    "    recent_days=3,\n",
    "    personal_window_days=10,\n",
    "    top_k_candidates=100\n",
    ")\n",
    "\n",
    "# Признаки (обучаемся до дня 39 → max_date_for_features = 39)\n",
    "candidates_val = create_features(candidates_val, train_hist, max_date_for_features=VAL_START - 1)\n",
    "\n",
    "# Метки: был ли клик в VAL периоде?\n",
    "val_pairs = val_true[['user_id', 'item_id']].drop_duplicates()\n",
    "val_pairs['target'] = 1\n",
    "candidates_val = candidates_val.merge(val_pairs, on=['user_id', 'item_id'], how='left')\n",
    "candidates_val['target'] = candidates_val['target'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Датасет валидации: {candidates_val.shape}, позитивов: {candidates_val['target'].sum()}\")\n",
    "\n",
    "# Обучение модели\n",
    "feature_cols = [col for col in candidates_val.columns if col not in ['user_id', 'item_id', 'candidate_source', 'target']]\n",
    "\n",
    "print(\"Обучение CatBoost на валидационном сете...\")\n",
    "model_val = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    task_type='GPU',\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "model_val.fit(candidates_val[feature_cols], candidates_val['target'], verbose=False)\n",
    "\n",
    "# Предсказание\n",
    "candidates_val['pred'] = model_val.predict_proba(candidates_val[feature_cols])[:, 1]\n",
    "\n",
    "# Формирование рекомендаций (топ-20 на пользователя)\n",
    "val_preds = (\n",
    "    candidates_val\n",
    "    .sort_values(['user_id', 'pred'], ascending=[True, False])\n",
    "    .groupby('user_id')\n",
    "    .head(20)\n",
    "    [['user_id', 'item_id']]\n",
    ")\n",
    "\n",
    "# Гарантия 20 рекомендаций\n",
    "global_top_20_val = train_hist['item_id'].value_counts().head(20).index.tolist()\n",
    "all_users_val = set(user_ids_val)\n",
    "pred_users_val = set(val_preds['user_id'])\n",
    "missing_users_val = all_users_val - pred_users_val\n",
    "\n",
    "if missing_users_val:\n",
    "    extra = []\n",
    "    for uid in missing_users_val:\n",
    "        for item in global_top_20_val[:20]:\n",
    "            extra.append({'user_id': uid, 'item_id': item})\n",
    "    extra_df = pd.DataFrame(extra)\n",
    "    val_preds = pd.concat([val_preds, extra_df], ignore_index=True)\n",
    "\n",
    "val_preds = val_preds.groupby('user_id').head(20).reset_index(drop=True)\n",
    "\n",
    "# Подготовка истинных значений для mAP\n",
    "val_actuals = val_true.groupby('user_id')['item_id'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9f01419de87c460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:14:29.049153Z",
     "start_time": "2025-10-19T14:13:38.206679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вычисление mAP@20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Подсчёт AP@20: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 592309/592309 [00:50<00:00, 11654.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Валидационный mAP@20: 0.000512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Вычисление mAP@20\n",
    "map20_val = compute_map_at_k(val_actuals, val_preds[:100_000], k=20)\n",
    "print(f\"\\n✅ Валидационный mAP@20: {map20_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2c75c210361ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:31:57.999023Z",
     "start_time": "2025-10-19T14:31:09.037505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ЭТАП 2: ОБУЧЕНИЕ НА ПОЛНЫХ ДАННЫХ И ПРЕДСКАЗАНИЕ ДЛЯ ТЕСТА\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация кандидатов: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 293230/293230 [00:03<00:00, 75754.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание признаков...\n",
      "\n",
      "✅ Финальный сабмишен сохранён: submission_catboost_final.csv\n",
      "Валидационный mAP@20: 0.000512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === ЭТАП 2: ОБУЧЕНИЕ НА ПОЛНЫХ ДАННЫХ И ПРЕДСКАЗАНИЕ ДЛЯ ТЕСТА ===\n",
    "print(\"\\nЭТАП 2: ОБУЧЕНИЕ НА ПОЛНЫХ ДАННЫХ И ПРЕДСКАЗАНИЕ ДЛЯ ТЕСТА\")\n",
    "\n",
    "user_ids_test = sample_sub['user_id'].unique()\n",
    "\n",
    "# Генерация кандидатов на полных данных (0–46)\n",
    "candidates_test = generate_candidates(\n",
    "    train=train_data,\n",
    "    user_ids=user_ids_test,\n",
    "    train_days=17,\n",
    "    recent_days=3,\n",
    "    personal_window_days=10,\n",
    "    top_k_candidates=100\n",
    ")\n",
    "\n",
    "# Признаки: обучаемся до дня 46 → max_date_for_features = 46\n",
    "candidates_test = create_features(candidates_test, train_data, max_date_for_features=MAX_DATE)\n",
    "\n",
    "# Нет меток — просто предсказание\n",
    "candidates_test['pred'] = model_val.predict_proba(candidates_test[feature_cols])[:, 1]\n",
    "\n",
    "# Топ-20 на пользователя\n",
    "submission = (\n",
    "    candidates_test\n",
    "    .sort_values(['user_id', 'pred'], ascending=[True, False])\n",
    "    .groupby('user_id')\n",
    "    .head(20)\n",
    "    [['user_id', 'item_id']]\n",
    ")\n",
    "\n",
    "# Гарантия 20 рекомендаций\n",
    "global_top_20_test = train_data['item_id'].value_counts().head(20).index.tolist()\n",
    "all_users_test = set(user_ids_test)\n",
    "pred_users_test = set(submission['user_id'])\n",
    "missing_users_test = all_users_test - pred_users_test\n",
    "\n",
    "if missing_users_test:\n",
    "    extra = []\n",
    "    for uid in missing_users_test:\n",
    "        for item in global_top_20_test[:20]:\n",
    "            extra.append({'user_id': uid, 'item_id': item})\n",
    "    extra_df = pd.DataFrame(extra)\n",
    "    submission = pd.concat([submission, extra_df], ignore_index=True)\n",
    "\n",
    "submission = submission.groupby('user_id').head(20).reset_index(drop=True)\n",
    "\n",
    "# Финальная проверка\n",
    "assert len(submission) == len(user_ids_test) * 20, f\"Ожидалось {len(user_ids_test)*20}, получено {len(submission)}\"\n",
    "\n",
    "# Сохранение\n",
    "submission.to_csv('submission_catboost_final.csv', index=False)\n",
    "print(f\"\\n✅ Финальный сабмишен сохранён: submission_catboost_final.csv\")\n",
    "print(f\"Валидационный mAP@20: {map20_val:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
