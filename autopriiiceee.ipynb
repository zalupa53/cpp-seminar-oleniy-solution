{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13206775,"sourceType":"datasetVersion","datasetId":8370364}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e9a17671","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport os\nfrom PIL import Image\nfrom transformers import AutoImageProcessor, AutoModel\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport glob\nfrom tqdm import tqdm\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:10:49.946371Z","iopub.execute_input":"2025-11-19T01:10:49.946676Z","iopub.status.idle":"2025-11-19T01:11:00.068257Z","shell.execute_reply.started":"2025-11-19T01:10:49.946657Z","shell.execute_reply":"2025-11-19T01:11:00.067383Z"}},"outputs":[{"name":"stderr","text":"2025-11-19 01:10:55.137461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763514655.162171     251 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763514655.169278     251 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"id":"2488c4cb","cell_type":"code","source":"train = pd.read_parquet(\"/kaggle/input/train_dataset.parquet\")\ntest = pd.read_parquet(\"/kaggle/input/test_dataset.parquet\")\ntrain['target'] = np.log(train['price_TARGET'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:00.069095Z","iopub.execute_input":"2025-11-19T01:11:00.069650Z","iopub.status.idle":"2025-11-19T01:11:00.640773Z","shell.execute_reply.started":"2025-11-19T01:11:00.069625Z","shell.execute_reply":"2025-11-19T01:11:00.639937Z"}},"outputs":[],"execution_count":2},{"id":"f6468142-bda9-4c97-ab06-db4f7d4c18d6","cell_type":"code","source":"train['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:00.642873Z","iopub.execute_input":"2025-11-19T01:11:00.643133Z","iopub.status.idle":"2025-11-19T01:11:00.651644Z","shell.execute_reply.started":"2025-11-19T01:11:00.643113Z","shell.execute_reply":"2025-11-19T01:11:00.650937Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0        10.839581\n1        12.180755\n2        15.796650\n3        13.880362\n4        10.896739\n           ...    \n69995    13.691080\n69996    13.208541\n69997    12.581079\n69998    12.587928\n69999    13.921671\nName: target, Length: 70000, dtype: float64"},"metadata":{}}],"execution_count":3},{"id":"078f7ca6","cell_type":"code","source":"len(os.listdir(\"/kaggle/input/AvitoAuto/АвтоПрайс/test_images\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:00.652317Z","iopub.execute_input":"2025-11-19T01:11:00.652533Z","iopub.status.idle":"2025-11-19T01:11:00.697021Z","shell.execute_reply.started":"2025-11-19T01:11:00.652516Z","shell.execute_reply":"2025-11-19T01:11:00.696375Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"98075"},"metadata":{}}],"execution_count":4},{"id":"1aed6994-afd3-49f2-84ca-bd48ca39bd0e","cell_type":"code","source":"len(os.listdir(\"/kaggle/input/AvitoAuto/АвтоПрайс/train_images\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:07.175291Z","iopub.execute_input":"2025-11-19T01:11:07.175529Z","iopub.status.idle":"2025-11-19T01:11:09.185319Z","shell.execute_reply.started":"2025-11-19T01:11:07.175512Z","shell.execute_reply":"2025-11-19T01:11:09.184702Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"273873"},"metadata":{}}],"execution_count":6},{"id":"257769ea-e01e-4042-a943-b8eed4d6f373","cell_type":"markdown","source":"# EMBEDDINGS","metadata":{}},{"id":"a633609a-76b3-4869-b22d-f6255dafb858","cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\", use_fast=True)\nvit_model = AutoModel.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\ndel vit_model.pooler\nvit_model.pooler = torch.nn.Identity()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvit_model.to(device)\nvit_model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5dc39a20-40a7-4008-99ca-325d632dfb2b","cell_type":"code","source":"train_image_dir = '/kaggle/input/AvitoAuto/АвтоПрайс/train_images'\ntest_image_dir = '/kaggle/input/AvitoAuto/АвтоПрайс/test_images'\n\nprint(f\"Train images dir exists: {os.path.exists(train_image_dir)}\")\nprint(f\"Test images dir exists: {os.path.exists(test_image_dir)}\")\n\n# Проверим какие файлы есть в директориях\ntrain_files = glob.glob(os.path.join(train_image_dir, \"*.jpg\"))\ntest_files = glob.glob(os.path.join(test_image_dir, \"*.jpg\"))\nprint(f\"Found {len(train_files)} train images, {len(test_files)} test images\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0aa5bd5b-3b8a-4b2a-8aa1-ef77ee7996df","cell_type":"code","source":"class CarImageDataset(Dataset):\n    def __init__(self, folder, train=True):\n        self.folder = folder\n        self.image_paths = []\n        self.ID2Images = {}\n        self.train = train\n\n        for img in sorted(os.listdir(folder)):\n            path = os.path.join(folder, img)\n            ID = img.split(\"_\")[0]\n            self.image_paths.append(path)\n            self.ID2Images.setdefault(int(ID), [])\n            self.ID2Images[int(ID)].append(path)\n\n        self.ids = sorted(self.ID2Images.keys())\n    \n    def __len__(self):\n        return len(self.ids)\n    \n    def __getitem__(self, idx):\n        ID = self.ids[idx]\n        image_paths = self.ID2Images[ID]\n        \n        images = [Image.open(img).convert(\"RGB\") for img in image_paths]\n        processed = processor(images, return_tensors=\"pt\")\n        processed = {k: v.to(device) for k, v in processed.items()}\n\n        with torch.inference_mode():\n            outputs = vit_model(**processed)\n            cls_embed = outputs.last_hidden_state[:, 0, :]\n\n        if self.train:\n            target = train.loc[train[train.ID == ID].index[0], \"price_TARGET\"]\n            return ID, torch.mean(cls_embed, dim=0)\n        else:\n            return ID, torch.mean(cls_embed, dim=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"728c3b89-f96e-45fa-9b76-60a0933b851e","cell_type":"code","source":"dataset = CarImageDataset(train_image_dir, train=True)\ndata_test = CarImageDataset(test_image_dir, train=False)\ntrain_loader = DataLoader(dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(data_test, batch_size=32, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d03d0e6b-e096-4694-b995-ec7028c93d38","cell_type":"code","source":"mapper = {}\n\nfor batch in tqdm(train_loader):\n    X, y = batch\n    for i in range(len(X)):\n        ind = int(X[i])\n        val = y[i].detach().cpu().numpy()\n        mapper[ind] = val","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f916b49e-5bd6-4aa0-af8f-92d6c4607dc0","cell_type":"code","source":"emb_cols = [f\"emb_{i}\" for i in range(192)]\nvectors = train['ID'].map(mapper).tolist()\nvectors_df = pd.DataFrame(vectors, columns=emb_cols, index=train.index)\ntrain[emb_cols] = vectors_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bb2f2c1e-f3e1-465e-b6c8-627f8d629dc8","cell_type":"markdown","source":"# Finetune","metadata":{}},{"id":"d2709ae6-997d-4e52-b9f2-a45d5b67e29d","cell_type":"code","source":"processor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\", use_fast=True)\nvit_model = AutoModel.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nvit_model.to(device)\nvit_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:09.187940Z","iopub.execute_input":"2025-11-19T01:11:09.188185Z","iopub.status.idle":"2025-11-19T01:11:11.965770Z","shell.execute_reply.started":"2025-11-19T01:11:09.188159Z","shell.execute_reply":"2025-11-19T01:11:11.965074Z"}},"outputs":[{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"ViTModel(\n  (embeddings): ViTEmbeddings(\n    (patch_embeddings): ViTPatchEmbeddings(\n      (projection): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): ViTEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x ViTLayer(\n        (attention): ViTAttention(\n          (attention): ViTSelfAttention(\n            (query): Linear(in_features=192, out_features=192, bias=True)\n            (key): Linear(in_features=192, out_features=192, bias=True)\n            (value): Linear(in_features=192, out_features=192, bias=True)\n          )\n          (output): ViTSelfOutput(\n            (dense): Linear(in_features=192, out_features=192, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (intermediate): ViTIntermediate(\n          (dense): Linear(in_features=192, out_features=768, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): ViTOutput(\n          (dense): Linear(in_features=768, out_features=192, bias=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (layernorm_before): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n        (layernorm_after): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n  (layernorm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n  (pooler): ViTPooler(\n    (dense): Linear(in_features=192, out_features=192, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":7},{"id":"79f7bcaf-4f6c-4d19-b65d-76d1dbb1c4c2","cell_type":"code","source":"class CarImageDataset(Dataset):\n    def __init__(self, folder, df, processor, train=True):\n        self.folder = folder\n        self.train = train\n        self.processor = processor\n        self.samples = [] \n\n        # Создаем словарь {ID: target} для быстрого поиска\n        id_to_target = {}\n        if self.train and df is not None:\n            id_to_target = dict(zip(df['ID'], df['price_TARGET']))\n\n        # Сканируем папку\n        valid_extensions = ('.jpg', '.jpeg', '.png')\n        for img in sorted(os.listdir(folder)):\n            if not img.lower().endswith(valid_extensions):\n                continue\n\n            path = os.path.join(folder, img)\n            try:\n                # Предполагаем формат имени файла \"ID_номер.jpg\"\n                file_id = int(img.split(\"_\")[0])\n            except ValueError:\n                continue\n\n            if self.train:\n                # Добавляем только если ID есть в train датафрейме\n                if file_id in id_to_target:\n                    target = id_to_target[file_id]\n                    self.samples.append((path, target))\n            else:\n                self.samples.append(path)\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        if self.train:\n            path, target = self.samples[idx]\n        else:\n            path = self.samples[idx]\n            target = 0.0 # Заглушка\n        \n        image = Image.open(path).convert(\"RGB\")\n        \n        # Превращаем картинку в тензор\n        processed = self.processor(image, return_tensors=\"pt\")\n        # Убираем лишнюю размерность батча [1, 3, 224, 224] -> [3, 224, 224]\n        pixel_values = processed['pixel_values'][0]\n\n        if self.train:\n            return pixel_values, torch.tensor(target, dtype=torch.float32)\n        else:\n            return pixel_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:11.967756Z","iopub.execute_input":"2025-11-19T01:11:11.967962Z","iopub.status.idle":"2025-11-19T01:11:11.975492Z","shell.execute_reply.started":"2025-11-19T01:11:11.967945Z","shell.execute_reply":"2025-11-19T01:11:11.974740Z"}},"outputs":[],"execution_count":8},{"id":"efc94e56-9ed3-4d78-8f4f-c131fcc18f46","cell_type":"code","source":"class ViTForRegression(nn.Module):\n    def __init__(self, base_model):\n        super(ViTForRegression, self).__init__()\n        self.base_model = base_model\n        \n        # Размер скрытого слоя у tiny vit обычно 192\n        hidden_size = base_model.config.hidden_size \n        \n        # Линейный слой: превращает вектор 192 в 1 число (цену)\n        self.regressor = nn.Linear(hidden_size, 1) \n\n    def forward(self, pixel_values):\n        # Прогоняем через ViT\n        outputs = self.base_model(pixel_values=pixel_values)\n        \n        # Берем last_hidden_state: [Batch, Seq_Len, Hidden]\n        # Нам нужен только CLS токен (индекс 0 по Seq_Len)\n        cls_token = outputs.last_hidden_state[:, 0, :] \n        \n        # Прогоняем через регрессор\n        prediction = self.regressor(cls_token)\n        \n        # Возвращаем [Batch], убираем лишнюю размерность [Batch, 1] -> [Batch]\n        return prediction.squeeze(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:11:12.815538Z","iopub.execute_input":"2025-11-19T01:11:12.815881Z","iopub.status.idle":"2025-11-19T01:11:12.820810Z","shell.execute_reply.started":"2025-11-19T01:11:12.815847Z","shell.execute_reply":"2025-11-19T01:11:12.820154Z"}},"outputs":[],"execution_count":9},{"id":"b8d64e3f-cf4a-42cc-a6f1-edffb0a017e1","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoImageProcessor, AutoModel\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# --- 0. Подготовка данных (Split) ---\n# Делим датафрейм train на обучающую (85%) и валидационную (15%) выборки\n# train_df используется для обучения, val_df - для проверки\ntrain_df, val_df = train_test_split(train, test_size=0.15, random_state=42)\n\nprint(f\"Train samples: {len(train_df)}, Validation samples: {len(val_df)}\")\n\n# --- 1. Инициализация ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprocessor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\", use_fast=True)\nbase_vit = AutoModel.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\n\nmodel = ViTForRegression(base_vit)\nmodel.to(device)\n\n# --- 2. Создание DataLoader'ов ---\n# Для валидации тоже ставим train=True, так как нам нужны таргеты для подсчета ошибки\ntrain_dataset = CarImageDataset(folder=\"/kaggle/input/AvitoAuto/АвтоПрайс/train_images\", df=train_df, processor=processor, train=True)\nval_dataset = CarImageDataset(folder=\"/kaggle/input/AvitoAuto/АвтоПрайс/train_images\", df=val_df, processor=processor, train=True)\n\nbatch_size = 32 \ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n# --- 3. Настройки обучения ---\ncriterion = nn.MSELoss()\n# L1 Loss нужен только для метрики (чтобы видеть ошибку в рублях/долларах), оптимизируем всё равно MSE\nmetric_l1 = nn.L1Loss() \n\noptimizer = optim.AdamW(model.parameters(), lr=5e-5)\n\n# Scheduler: Плавно снижает LR от 5e-5 до 0 в течение всех эпох\nnum_epochs = 10 # Увеличь количество эпох, 1 маловато для шедулера\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n\n# --- 4. Цикл обучения ---\nbest_val_loss = float('inf') # Для сохранения лучшей модели\n\nfor epoch in range(num_epochs):\n    # === TRAIN LOOP ===\n    model.train()\n    train_loss = 0.0\n    \n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n    \n    for images, targets in progress_bar:\n        images = images.to(device)\n        targets = targets.to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(images)\n        loss = criterion(outputs, targets)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        progress_bar.set_postfix({'loss': loss.item()})\n    \n    # Шаг шедулера в конце эпохи\n    scheduler.step()\n    \n    avg_train_loss = train_loss / len(train_loader)\n\n    # === VALIDATION LOOP ===\n    model.eval() # Выключаем Dropout и Batchnorm update\n    val_loss_mse = 0.0\n    val_loss_mae = 0.0\n    \n    # Используем inference_mode для ускорения и экономии памяти\n    with torch.inference_mode():\n        for images, targets in val_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            outputs = model(images)\n            \n            # Считаем MSE для Лосса\n            loss = criterion(outputs, targets)\n            val_loss_mse += loss.item()\n            \n            # Считаем L1 (MAE) для понимания ошибки в абсолютных величинах\n            mae = metric_l1(outputs, targets)\n            val_loss_mae += mae.item()\n\n    avg_val_mse = val_loss_mse / len(val_loader)\n    avg_val_mae = val_loss_mae / len(val_loader)\n    \n    print(f\"Epoch {epoch+1}: Train MSE: {avg_train_loss:.4f} | Val MSE: {avg_val_mse:.4f} | Val MAE: {avg_val_mae:.2f}\")\n    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n\n    # Сохраняем лучшую модель (по MSE)\n    if avg_val_mse < best_val_loss:\n        print(f\"Validation loss improved ({best_val_loss:.4f} -> {avg_val_mse:.4f}). Saving model...\")\n        best_val_loss = avg_val_mse\n        torch.save(model.state_dict(), \"best_vit_price_model.pth\")\n\nprint(\"Training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T01:12:11.848764Z","iopub.execute_input":"2025-11-19T01:12:11.849368Z","execution_failed":"2025-11-19T01:12:30.715Z"}},"outputs":[{"name":"stdout","text":"Train samples: 59500, Validation samples: 10500\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/10 [Train]:   2%|▏         | 111/7276 [00:13<13:39,  8.75it/s, loss=1.6e+12] ","output_type":"stream"}],"execution_count":null},{"id":"d65d11d9-d97e-4c68-b50c-3bab8b062edc","cell_type":"code","source":"model.load_state_dict(state_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"24ee31ae-2de3-48c7-9766-b06973c3c691","cell_type":"markdown","source":"# PREDICT","metadata":{}},{"id":"b021c29c","cell_type":"code","source":"cat_features = ['equipment', 'body_type', 'drive_type', 'engine_type', 'doors_number', 'color', 'pts', 'diski', 'audiosistema', 'electropodemniki', 'fary', 'salon', 'upravlenie_klimatom',\n                'usilitel_rul', 'steering_wheel', 'crashes_count', 'owners_count']\nnumeric_features = ['mileage', 'latitude', 'longitude'] + np.array(emb_cols).tolist()\n\nlisted_features = ['aktivnaya_bezopasnost_mult', 'audiosistema_mult', 'shini_i_diski_mult', 'electroprivod_mult', 'fary_mult', 'multimedia_navigacia_mult', 'obogrev_mult', 'pamyat_nastroek_mult', 'podushki_bezopasnosti_mult',\n                   'pomosh_pri_vozhdenii_mult', 'protivoygonnaya_sistema_mult', 'salon_mult', 'upravlenie_klimatom_mult']\n\ntarget = ['price_TARGET']\nID = ['ID']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"577bda8a","cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"043e4e75","cell_type":"code","source":"import pandas as pd\n\n# Собираем все уникальные метки для train и test\nlabels = {col: set().union(*train[col]) for col in listed_features}\ntest_labels = {col: set().union(*test[col]) for col in listed_features}\n\n# One-hot для train\nfor col in listed_features:\n    # Разворачиваем список в строки\n    exploded = train[[col]].explode(col)\n    # Получаем one-hot кодировку\n    dummies = pd.get_dummies(exploded[col], prefix=col)\n    # Складываем обратно по индексам\n    dummies = dummies.groupby(exploded.index).max()\n    # Добавляем в train\n    train = train.join(dummies)\n\n# One-hot для test\nfor col in listed_features:\n    exploded = test[[col]].explode(col)\n    dummies = pd.get_dummies(exploded[col], prefix=col)\n    dummies = dummies.groupby(exploded.index).max()\n    test = test.join(dummies)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e8c88071","cell_type":"code","source":"for i, lbs in enumerate(labels):\n    print(lbs, labels[lbs] == test_labels[lbs])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"002c30f1","cell_type":"code","source":"for col in test.columns:\n    if col not in target and col not in listed_features and col not in numeric_features and col not in cat_features and col not in ID:\n        cat_features.append(col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"09698947","cell_type":"markdown","source":"## CATBOOST","metadata":{}},{"id":"28b952b9-6733-4532-90e4-cfae6c7fdd8e","cell_type":"code","source":"!pip install -U scikit-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"48cc69e6","cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6892bcd4-b97f-4207-8c3c-053531add226","cell_type":"code","source":"!pip install -U \"scikit-learn<1.5\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3e22aed6-c41c-4e7a-95ff-52b972745057","cell_type":"code","source":"!pip install -U catboost","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"eec9f593","cell_type":"code","source":"from catboost import CatBoostRegressor\nimport numpy as np\n\ntest[cat_features] = test[cat_features].fillna(\"NaN\")\ntrain[cat_features] = train[cat_features].fillna(\"NaN\")\n\ntrain['target'] = np.log(train['price_TARGET'])\n\nclass MedianAPE:\n    \n    @staticmethod\n    def get_median_ape(y_true, y_pred, eps=1e-8):\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n    \n    def is_max_optimal(self):\n        return False  # чем меньше MdAPE, тем лучше\n    \n    def evaluate(self, approxes, target, weight):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n        y_true = np.array(target)\n        y_pred = np.array(approxes[0])\n        score = self.get_median_ape(y_true, y_pred)\n        return score, 1  # (значение метрики, вес)\n    \n    def get_final_error(self, error, weight):\n        return error\n\n\nX = train[cat_features + numeric_features]\ny = train['target']\n\nindices = np.arange(len(train))\nnp.random.seed(52)\nnp.random.shuffle(indices)\n\nsplit = int(0.9 * len(indices))\ntrain_idx, val_idx = indices[:split], indices[split:]\n\nX_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\ny_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=52, shuffle=True)\n\nmodel = CatBoostRegressor(\n    iterations=2500,\n    learning_rate=0.03,\n    depth=10,\n    cat_features=cat_features,\n    loss_function=\"RMSE\",\n    eval_metric=\"RMSE\",\n    verbose=100,\n    random_seed=42,\n    task_type=\"GPU\"\n)\n\nmodel.fit(X=X_train, y=y_train, eval_set=(X_val, y_val),\n          cat_features=cat_features, use_best_model=True)\n\n\ndef median_APE(y_true, y_pred, eps=1e-8):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n\ny_pred = np.exp(model.predict(X_val))\ny_val = train.loc[X_val.index, \"price_TARGET\"]\nscore = median_APE(y_val, y_pred)\nprint(f\"Median_APE: {score}\\n\" +\n      f\"LB: {1 / (1 + score)}\\n\" +\n      f\"MAE: {mean_absolute_error(y_val, y_pred)}\\n\" +\n      f\"Mean_APE: {mean_absolute_percentage_error(y_val, y_pred)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dbfcd3c8","cell_type":"code","source":"submission = pd.DataFrame({\"ID\": test[\"ID\"],\n              \"target\": np.exp(model.predict(test[cat_features + numeric_features]))})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"704d6155","cell_type":"code","source":"submission.to_csv(\"baseline.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fe006f29","cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8b219212","cell_type":"markdown","source":"# OPTUNA","metadata":{}},{"id":"e277fb2d","cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\nimport numpy as np\nimport optuna\nfrom optuna.samplers import RandomSampler\n\n# Предобработка данных\ntest[cat_features] = test[cat_features].fillna(\"NaN\")\ntrain[cat_features] = train[cat_features].fillna(\"NaN\")\ntrain['target'] = np.log(train['price_TARGET'])\n\n# Метрика MedianAPE\nclass MedianAPE:\n    @staticmethod\n    def get_median_ape(y_true, y_pred, eps=1e-8):\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n    \n    def is_max_optimal(self):\n        return False\n    \n    def evaluate(self, approxes, target, weight):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n        y_true = np.array(target)\n        y_pred = np.array(approxes[0])\n        score = self.get_median_ape(y_true, y_pred)\n        return score, 1\n    \n    def get_final_error(self, error, weight):\n        return error\n\ndef median_APE(y_true, y_pred, eps=1e-8):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    return np.median(np.abs(y_pred - y_true) / np.clip(np.abs(y_true), eps, None))\n\n# Разделение данных\nX = train[cat_features + numeric_features]\ny = train['target']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=52, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"461ba385","cell_type":"code","source":"# Функция для оптимизации\ndef objective(trial):\n    params = {\n        'iterations': trial.suggest_int('iterations', 1000, 7500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n        'depth': trial.suggest_int('depth', 4, 11),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n        'random_strength': trial.suggest_float('random_strength', 0.1, 2),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 250),\n        'loss_function': 'RMSE',\n        'eval_metric': MedianAPE(),\n        'cat_features': cat_features,\n        'verbose': False,\n        'random_seed': 42,\n        'task_type': 'GPU',\n        # \"early_stopping_rounds\": 250\n    }\n    \n    model = CatBoostRegressor(**params)\n    \n    try:\n        model.fit(\n            X=X_train, y=y_train,\n            eval_set=(X_val, y_val),\n            early_stopping_rounds=100,\n            verbose=False\n        )\n        \n        # Предсказание и оценка\n        y_pred = np.exp(model.predict(X_val))\n        y_true = train.loc[X_val.index, \"price_TARGET\"]\n        score = median_APE(y_true, y_pred)\n        \n    except Exception as e:\n        print(f\"Ошибка при обучении: {e}\")\n        score = float('inf')\n        \n    return score\n\n# Исследование\nstudy = optuna.create_study(\n    direction='minimize',\n    sampler=RandomSampler(seed=16)\n)\nstudy.optimize(objective, n_trials=600)\n\n# Лучшие параметры\nprint(\"Лучшие параметры:\")\nfor key, value in study.best_params.items():\n    print(f\"{key}: {value}\")\nprint(f\"Лучший Median_APE: {study.best_value}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"af5ed1ad","cell_type":"code","source":"study.best_params","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"baf21a02","cell_type":"code","source":"pars = {'iterations': 4773,\n 'learning_rate': 0.023540714865270384,\n 'depth': 11,\n 'l2_leaf_reg': 4.339528598041656,\n 'random_strength': 1.4767698885793084,\n 'bagging_temperature': 0.5228168517505888,\n 'border_count': 186,\n 'grow_policy': 'Depthwise',\n 'min_data_in_leaf': 76}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b5005554","cell_type":"code","source":"pars_redacted = {'iterations': 1242,\n 'learning_rate': 0.023540714865270384,\n 'depth': 11,\n 'l2_leaf_reg': 4.339528598041656,\n 'random_strength': 1.4767698885793084,\n 'bagging_temperature': 0.5228168517505888,\n 'border_count': 186,\n 'grow_policy': 'Depthwise',\n 'min_data_in_leaf': 76}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7f92fe95","cell_type":"code","source":"# Финальное обучение с лучшими параметрами\nbest_model = CatBoostRegressor(\n    **pars,\n    cat_features=cat_features,\n    loss_function=\"RMSE\",\n    eval_metric=MedianAPE(),\n    verbose=100,\n    random_seed=42,\n    task_type=\"GPU\"\n)\n\nbest_model.fit(\n    X=X_train, y=y_train,\n    eval_set=(X_val, y_val),\n    use_best_model=True,\n    early_stopping_rounds=250\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"26718c2e","cell_type":"code","source":"# Финальная оценка\ny_pred = np.exp(best_model.predict(X_val))\ny_true = train.loc[X_val.index, \"price_TARGET\"]\nfinal_score = median_APE(y_true, y_pred)\n\nprint(f\"\\nФинальный Median_APE: {final_score}\")\nprint(f\"LB score: {1 / (1 + final_score)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7299bb60","cell_type":"code","source":"submission = pd.DataFrame({\"ID\": test[\"ID\"],\n              \"target\": np.exp(best_model.predict(test[cat_features + numeric_features]))})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a5ee8691","cell_type":"code","source":"submission.to_csv(\"opt.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9f5e800","cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}