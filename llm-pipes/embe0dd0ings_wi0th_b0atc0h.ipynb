{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1eb8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6d21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings_in_batches(\n",
    "    input_file, \n",
    "    output_file, \n",
    "    text_column, \n",
    "    model_name='all-MiniLM-L6-v2', \n",
    "    batch_size=64\n",
    "):\n",
    "    \"\"\"\n",
    "    Читает CSV, генерирует эмбеддинги батчами и сохраняет результат.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Определение устройства (GPU или CPU)\n",
    "    device ='mps'# 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "\n",
    "    # 2. Загрузка модели\n",
    "    print(f\"Загрузка модели {model_name}...\")\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    # 3. Чтение данных\n",
    "    print(\"Чтение CSV файла...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Проверка на пустые значения в колонке с текстом\n",
    "    if df[text_column].isnull().any():\n",
    "        print(f\"Внимание: найдены пустые значения в колонке '{text_column}'. Заменяем на пустую строку.\")\n",
    "        df[text_column] = df[text_column].fillna(\"\")\n",
    "\n",
    "    texts = df[text_column].tolist()\n",
    "    total_rows = len(texts)\n",
    "    \n",
    "    # 4. Генерация эмбеддингов батчами\n",
    "    all_embeddings = []\n",
    "    \n",
    "    print(f\"Начинаем генерацию эмбеддингов (всего строк: {total_rows}, размер батча: {batch_size})...\")\n",
    "    \n",
    "    # Цикл по батчам с прогресс-баром\n",
    "    for i in tqdm(range(0, total_rows, batch_size)):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        \n",
    "        # Генерируем эмбеддинги для текущего батча\n",
    "        # convert_to_numpy=True возвращает numpy массивы\n",
    "        embeddings = model.encode(batch_texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "        \n",
    "        # Добавляем в общий список (можно сразу писать в файл, если данных ОЧЕНЬ много)\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    # 5. Добавление колонки в DataFrame\n",
    "    df['embedding'] = list(all_embeddings)\n",
    "\n",
    "    # 6. Сохранение\n",
    "    # Рекомендую сохранять в Parquet или Pickle, так как CSV превратит массивы в строки \"[0.1, 0.2...]\"\n",
    "    if output_file.endswith('.csv'):\n",
    "        print(\"Сохранение в CSV (вектора будут строками)...\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "    elif output_file.endswith('.parquet'):\n",
    "        print(\"Сохранение в Parquet (рекомендуется)...\")\n",
    "        df.to_parquet(output_file, index=False)\n",
    "    elif output_file.endswith('.pkl'):\n",
    "        print(\"Сохранение в Pickle...\")\n",
    "        df.to_pickle(output_file)\n",
    "        \n",
    "    print(\"Готово!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff296c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Укажите свои пути и названия колонок\n",
    "create_embeddings_in_batches(\n",
    "    input_file='input_texts.csv',   # Ваш исходный файл\n",
    "    output_file='output_with_emb.parquet', # Куда сохранить (лучше parquet)\n",
    "    text_column='text',             # Имя колонки с текстом в CSV\n",
    "    batch_size=128                  # Размер пачки (уменьшите, если не хватает памяти)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e256971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создаём тестовые данные...\n",
      "Создан файл input_texts.csv с 205 строками\n",
      "   id                                               text category\n",
      "0   0  Это тестовый текст номер 0. Он содержит различ...     test\n",
      "1   1  Это тестовый текст номер 1. Он содержит различ...     test\n",
      "2   2  Это тестовый текст номер 2. Он содержит различ...     test\n",
      "3   3  Это тестовый текст номер 3. Он содержит различ...     test\n",
      "4   4  Это тестовый текст номер 4. Он содержит различ...     test\n"
     ]
    }
   ],
   "source": [
    "# Генерация тестовых данных\n",
    "print(\"Создаём тестовые данные...\")\n",
    "\n",
    "# Создаём датасет с 200 примерами текстов\n",
    "test_texts = [\n",
    "    f\"Это тестовый текст номер {i}. Он содержит различную информацию для демонстрации работы эмбеддингов.\" \n",
    "    for i in range(200)\n",
    "]\n",
    "\n",
    "# Добавляем разнообразные тексты\n",
    "test_texts.extend([\n",
    "    \"Машинное обучение - это раздел искусственного интеллекта.\",\n",
    "    \"Python - один из самых популярных языков программирования.\",\n",
    "    \"Нейронные сети используются для решения сложных задач.\",\n",
    "    \"Обработка естественного языка помогает компьютерам понимать текст.\",\n",
    "    \"Трансформеры произвели революцию в NLP.\",\n",
    "])\n",
    "\n",
    "# Создаём DataFrame\n",
    "test_df = pd.DataFrame({\n",
    "    'id': range(len(test_texts)),\n",
    "    'text': test_texts,\n",
    "    'category': ['test'] * len(test_texts)\n",
    "})\n",
    "\n",
    "# Сохраняем в CSV\n",
    "test_df.to_csv('input_texts.csv', index=False)\n",
    "print(f\"Создан файл input_texts.csv с {len(test_texts)} строками\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2dd2e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется устройство: mps\n",
      "Загрузка модели all-MiniLM-L6-v2...\n",
      "Чтение CSV файла...\n",
      "Начинаем генерацию эмбеддингов (всего строк: 205, размер батча: 64)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение в Parquet (рекомендуется)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово!\n"
     ]
    }
   ],
   "source": [
    "# Теперь запускаем функцию генерации эмбеддингов\n",
    "create_embeddings_in_batches(\n",
    "    input_file='input_texts.csv',\n",
    "    output_file='output_with_emb.parquet',\n",
    "    text_column='text',\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18013b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Проверка результата ===\n",
      "Количество строк: 205\n",
      "Колонки: ['id', 'text', 'category', 'embedding']\n",
      "\n",
      "Пример первой строки:\n",
      "id                                                          0\n",
      "text        Это тестовый текст номер 0. Он содержит различ...\n",
      "category                                                 test\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Размер эмбеддинга: 384\n",
      "Первые 10 значений эмбеддинга: [ 0.04614211  0.06408302 -0.01851688 -0.00331769 -0.07265981  0.0204317\n",
      "  0.08442818  0.09363926 -0.02222545 -0.00988434]\n"
     ]
    }
   ],
   "source": [
    "# Проверяем результат\n",
    "print(\"\\n=== Проверка результата ===\")\n",
    "result_df = pd.read_parquet('output_with_emb.parquet')\n",
    "\n",
    "print(f\"Количество строк: {len(result_df)}\")\n",
    "print(f\"Колонки: {result_df.columns.tolist()}\")\n",
    "print(f\"\\nПример первой строки:\")\n",
    "print(result_df.iloc[0][['id', 'text', 'category']])\n",
    "print(f\"\\nРазмер эмбеддинга: {len(result_df.iloc[0]['embedding'])}\")\n",
    "print(f\"Первые 10 значений эмбеддинга: {result_df.iloc[0]['embedding'][:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
